diff --git a/ChangeLog.backported b/ChangeLog.backported
new file mode 100644
index 0000000..b6519d0
--- /dev/null
+++ b/ChangeLog.backported
@@ -0,0 +1,39 @@
+http://gcc.gnu.org/viewcvs?root=gcc&view=rev&rev=191571
+2012-09-17  Jakub Jelinek  <jakub@redhat.com>
+
+    PR tree-optimization/54563
+    * tree-ssa-math-opts.c (execute_cse_sincos): Call
+    gimple_purge_dead_eh_edges if last call has been changed.
+
+    * g++.dg/torture/pr54563.C: New test.
+
+http://gcc.gnu.org/viewcvs?view=revision&revision=193554
+2012-11-16  Jakub Jelinek  <jakub@redhat.com>
+    PR target/54073
+    * config/i386/i386.md (mov<mode>cc): Use comparison_operator
+    instead of ordered_comparison_operator resp.
+    ix86_fp_comparison_operator predicates.
+    * config/i386/i386.c (ix86_expand_fp_movcc): Reject TImode
+    or for -m32 DImode comparisons.
+
+http://gcc.gnu.org/viewcvs?view=revision&revision=193825
+2012-11-26  Diego Novillo  <dnovillo@google.com>
+
+    * gimplify.c: Work around for PR 55245.
+
+http://gcc.gnu.org/viewcvs?view=revision&revision=186451
+2012-04-14  Tom de Vries  <tom@codesourcery.com>
+    * cfgcleanup.c (try_optimize_cfg): Replace call to delete_insn_chain by
+    call to delete_insn.  Remove code to reorder BASIC_BLOCK note and
+    DELETED_LABEL note, and move it to ...
+    * cfgrtl.c (delete_insn): ... here.  Change return type to void.
+    (delete_insn_and_edges): Likewise.
+    (delete_insn_chain): Handle new return type of delete_insn.  Delete
+    chain backwards rather than forwards.
+    * rtl.h (delete_insn, delete_insn_and_edges): Change return type to
+    void.
+    * cfglayout.c (fixup_reorder_chain): Delete unused label.
+
+2013-01-03  Jason Merrill  <jason@redhat.com>
+    PR c++/55856
+    * semantics.c (build_data_member_initialization): Handle DECL_EXPR.
diff --git a/gcc/ChangeLog.cfx b/gcc/ChangeLog.cfx
new file mode 100644
index 0000000..a3778ad
--- /dev/null
+++ b/gcc/ChangeLog.cfx
@@ -0,0 +1,1011 @@
+This file documents backports from trunk only
+
+2013-07-02  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.md (arm_andsi3_insn): Add alternatives for 16-bit
+        encoding.
+        (iorsi3_insn): Likewise.
+        (arm_xorsi3): Likewise.
+
+2013-07-01  Sofiane Naci  <sofiane.naci@arm.com>
+
+        * arm.md (attribute "wtype"): Delete.  Move attribute values from here
+        to ...
+        (attribute "type"): ... here, and prefix with "wmmx_".
+        (attribute "core_cycles"): Update for attribute changes.
+        * iwmmxt.md (tbcstv8qi): Update for attribute changes.
+        (tbcstv4hi): Likewise.
+        (tbcstv2si): Likewise.
+        (iwmmxt_iordi3): Likewise.
+        (iwmmxt_xordi3): Likewise.
+        (iwmmxt_anddi3): Likewise.
+        (iwmmxt_nanddi3): Likewise.
+        (iwmmxt_arm_movdi): Likewise.
+        (iwmmxt_movsi_insn): Likewise.
+        (mov<mode>_internal): Likewise.
+        (and<mode>3_iwmmxt): Likewise.
+        (ior<mode>3_iwmmxt): Likewise.
+        (xor<mode>3_iwmmxt): Likewise.
+        (add<mode>3_iwmmxt): Likewise.
+        (ssaddv8qi3): Likewise.
+        (ssaddv4hi3): Likewise.
+        (ssaddv2si3): Likewise.
+        (usaddv8qi3): Likewise.
+        (usaddv4hi3): Likewise.
+        (usaddv2si3): Likewise.
+        (sub<mode>3_iwmmxt): Likewise.
+        (sssubv8qi3): Likewise.
+        (sssubv4hi3): Likewise.
+        (sssubv2si3): Likewise.
+        (ussubv8qi3): Likewise.
+        (ussubv4hi3): Likewise.
+        (ussubv2si3): Likewise.
+        (mulv4hi3_iwmmxt): Likewise.
+        (smulv4hi3_highpart): Likewise.
+        (umulv4hi3_highpart): Likewise.
+        (iwmmxt_wmacs): Likewise.
+        (iwmmxt_wmacsz): Likewise.
+        (iwmmxt_wmacu): Likewise.
+        (iwmmxt_wmacuz): Likewise.
+        (iwmmxt_clrdi): Likewise.
+        (iwmmxt_clrv8qi): Likewise.
+        (iwmmxt_clr4hi): Likewise.
+        (iwmmxt_clr2si): Likewise.
+        (iwmmxt_uavgrndv8qi3): Likewise.
+        (iwmmxt_uavgrndv4hi3): Likewise.
+        (iwmmxt_uavgv8qi3): Likewise.
+        (iwmmxt_uavgv4hi3): Likewise.
+        (iwmmxt_tinsrb): Likewise.
+        (iwmmxt_tinsrh): Likewise.
+        (iwmmxt_tinsrw): Likewise.
+        (iwmmxt_textrmub): Likewise.
+        (iwmmxt_textrmsb): Likewise.
+        (iwmmxt_textrmuh): Likewise.
+        (iwmmxt_textrmsh): Likewise.
+        (iwmmxt_textrmw): Likewise.
+        (iwmxxt_wshufh): Likewise.
+        (eqv8qi3): Likewise.
+        (eqv4hi3): Likewise.
+        (eqv2si3): Likewise.
+        (gtuv8qi3): Likewise.
+        (gtuv4hi3): Likewise.
+        (gtuv2si3): Likewise.
+        (gtv8qi3): Likewise.
+        (gtv4hi3): Likewise.
+        (gtv2si3): Likewise.
+        (smax<mode>3_iwmmxt): Likewise.
+        (umax<mode>3_iwmmxt): Likewise.
+        (smin<mode>3_iwmmxt): Likewise.
+        (umin<mode>3_iwmmxt): Likewise.
+        (iwmmxt_wpackhss): Likewise.
+        (iwmmxt_wpackwss): Likewise.
+        (iwmmxt_wpackdss): Likewise.
+        (iwmmxt_wpackhus): Likewise.
+        (iwmmxt_wpackwus): Likewise.
+        (iwmmxt_wpackdus): Likewise.
+        (iwmmxt_wunpckihb): Likewise.
+        (iwmmxt_wunpckihh): Likewise.
+        (iwmmxt_wunpckihw): Likewise.
+        (iwmmxt_wunpckilb): Likewise.
+        (iwmmxt_wunpckilh): Likewise.
+        (iwmmxt_wunpckilw): Likewise.
+        (iwmmxt_wunpckehub): Likewise.
+        (iwmmxt_wunpckehuh): Likewise.
+        (iwmmxt_wunpckehuw): Likewise.
+        (iwmmxt_wunpckehsb): Likewise.
+        (iwmmxt_wunpckehsh): Likewise.
+        (iwmmxt_wunpckehsw): Likewise.
+        (iwmmxt_wunpckelub): Likewise.
+        (iwmmxt_wunpckeluh): Likewise.
+        (iwmmxt_wunpckeluw): Likewise.
+        (iwmmxt_wunpckelsb): Likewise.
+        (iwmmxt_wunpckelsh): Likewise.
+        (iwmmxt_wunpckelsw): Likewise.
+        (ror<mode>3): Likewise.
+        (ashr<mode>3_iwmmxt): Likewise.
+        (lshr<mode>3_iwmmxt): Likewise.
+        (ashl<mode>3_iwmmxt): Likewise.
+        (ror<mode>3_di): Likewise.
+        (ashr<mode>3_di): Likewise.
+        (lshr<mode>3_di): Likewise.
+        (ashl<mode>3_di): Likewise.
+        (iwmmxt_wmadds): Likewise.
+        (iwmmxt_wmaddu): Likewise.
+        (iwmmxt_tmia): Likewise.
+        (iwmmxt_tmiaph): Likewise.
+        (iwmmxt_tmiabb): Likewise.
+        (iwmmxt_tmiatb): Likewise.
+        (iwmmxt_tmiabt): Likewise.
+        (iwmmxt_tmiatt): Likewise.
+        (iwmmxt_tmovmskb): Likewise.
+        (iwmmxt_tmovmskh): Likewise.
+        (iwmmxt_tmovmskw): Likewise.
+        (iwmmxt_waccb): Likewise.
+        (iwmmxt_wacch): Likewise.
+        (iwmmxt_waccw): Likewise.
+        (iwmmxt_waligni): Likewise.
+        (iwmmxt_walignr): Likewise.
+        (iwmmxt_walignr0): Likewise.
+        (iwmmxt_walignr1): Likewise.
+        (iwmmxt_walignr2): Likewise.
+        (iwmmxt_walignr3): Likewise.
+        (iwmmxt_wsadb): Likewise.
+        (iwmmxt_wsadh): Likewise.
+        (iwmmxt_wsadbz): Likewise.
+        (iwmmxt_wsadhz): Likewise.
+        * iwmmxt2.md (iwmmxt_wabs<mode>3): Update for attribute changes.
+        (iwmmxt_wabsdiffb): Likewise.
+        (iwmmxt_wabsdiffh): Likewise.
+        (iwmmxt_wabsdiffw): Likewise.
+        (iwmmxt_waddsubhx): Likewise
+        (iwmmxt_wsubaddhx): Likewise.
+        (addc<mode>3): Likewise.
+        (iwmmxt_avg4): Likewise.
+        (iwmmxt_avg4r): Likewise.
+        (iwmmxt_wmaddsx): Likewise.
+        (iwmmxt_wmaddux): Likewise.
+        (iwmmxt_wmaddsn): Likewise.
+        (iwmmxt_wmaddun): Likewise.
+        (iwmmxt_wmulwsm): Likewise.
+        (iwmmxt_wmulwum): Likewise.
+        (iwmmxt_wmulsmr): Likewise.
+        (iwmmxt_wmulumr): Likewise.
+        (iwmmxt_wmulwsmr): Likewise.
+        (iwmmxt_wmulwumr): Likewise.
+        (iwmmxt_wmulwl): Likewise.
+        (iwmmxt_wqmulm): Likewise.
+        (iwmmxt_wqmulwm): Likewise.
+        (iwmmxt_wqmulmr): Likewise.
+        (iwmmxt_wqmulwmr): Likewise.
+        (iwmmxt_waddbhusm): Likewise.
+        (iwmmxt_waddbhusl): Likewise.
+        (iwmmxt_wqmiabb): Likewise.
+        (iwmmxt_wqmiabt): Likewise.
+        (iwmmxt_wqmiatb): Likewise.
+        (iwmmxt_wqmiatt): Likewise.
+        (iwmmxt_wqmiabbn): Likewise.
+        (iwmmxt_wqmiabtn): Likewise.
+        (iwmmxt_wqmiatbn): Likewise.
+        (iwmmxt_wqmiattn): Likewise.
+        (iwmmxt_wmiabb): Likewise.
+        (iwmmxt_wmiabt): Likewise.
+        (iwmmxt_wmiatb): Likewise.
+        (iwmmxt_wmiatt): Likewise.
+        (iwmmxt_wmiabbn): Likewise.
+        (iwmmxt_wmiabtn): Likewise.
+        (iwmmxt_wmiatbn): Likewise.
+        (iwmmxt_wmiattn): Likewise.
+        (iwmmxt_wmiawbb): Likewise.
+        (iwmmxt_wmiawbt): Likewise.
+        (iwmmxt_wmiawtb): Likewise.
+        (iwmmxt_wmiawtt): Likewise.
+        (iwmmxt_wmiawbbn): Likewise.
+        (iwmmxt_wmiawbtn): Likewise.
+        (iwmmxt_wmiawtbn): Likewise.
+        (iwmmxt_wmiawttn): Likewise.
+        (iwmmxt_wmerge): Likewise.
+        (iwmmxt_tandc<mode>3): Likewise.
+        (iwmmxt_torc<mode>3): Likewise.
+        (iwmmxt_torvsc<mode>3): Likewise.
+        (iwmmxt_textrc<mode>3): Likewise.
+        * marvell-f-iwmmxt.md (wmmxt_shift): Update for attribute changes.
+        (wmmxt_pack): Likewise.
+        (wmmxt_mult_c1): Likewise.
+        (wmmxt_mult_c2): Likewise.
+        (wmmxt_alu_c1): Likewise.
+        (wmmxt_alu_c2): Likewise.
+        (wmmxt_alu_c3): Likewise.
+        (wmmxt_transfer_c1): Likewise.
+        (wmmxt_transfer_c2): Likewise.
+        (wmmxt_transfer_c3): Likewise.
+        (marvell_f_iwmmxt_wstr): Likewise.
+        (marvell_f_iwmmxt_wldr): Likewise.
+
+2013-06-28  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/constraints.md (Ts): New constraint.
+        * config/arm/arm.md (arm_movqi_insn): Add alternatives for
+        16-bit encodings.
+        (compare_scc): Use "Ts" constraint for operand 0.
+        (ior_scc_scc): Likewise.
+        (and_scc_scc): Likewise.
+        (and_scc_scc_nodom): Likewise.
+        (ior_scc_scc_cmp): Likewise for operand 7.
+        (and_scc_scc_cmp): Likewise.
+        * config/arm/thumb2.md (thumb2_movsi_insn):
+        Add alternatives for 16-bit encodings.
+        (thumb2_movhi_insn): Likewise.
+        (thumb2_movsicc_insn): Likewise.
+        (thumb2_and_scc): Take 'and' outside cond_exec.  Use "Ts" constraint.
+        (thumb2_negscc): Use "Ts" constraint.
+        Move mvn instruction outside cond_exec block.
+        * config/arm/vfp.md (thumb2_movsi_vfp): Add alternatives
+        for 16-bit encodings.
+
+2013-06-28  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.md (arm_mulsi3_v6): Add alternative for 16-bit
+        encoding.
+        (mulsi3addsi_v6): Disable predicable variant for arm_restrict_it.
+        (mulsi3subsi): Likewise.
+        (mulsidi3adddi): Likewise.
+        (mulsidi3_v6): Likewise.
+        (umulsidi3_v6): Likewise.
+        (umulsidi3adddi_v6): Likewise.
+        (smulsi3_highpart_v6): Likewise.
+        (umulsi3_highpart_v6): Likewise.
+        (mulhisi3tb): Likewise.
+        (mulhisi3bt): Likewise.
+        (mulhisi3tt): Likewise.
+        (maddhisi4): Likewise.
+        (maddhisi4tb): Likewise.
+        (maddhisi4tt): Likewise.
+        (maddhidi4): Likewise.
+        (maddhidi4tb): Likewise.
+        (maddhidi4tt): Likewise.
+        (zeroextractsi_compare0_scratch): Likewise.
+        (insv_zero): Likewise.
+        (insv_t2): Likewise.
+        (anddi_notzesidi_di): Likewise.
+        (anddi_notsesidi_di): Likewise.
+        (andsi_notsi_si): Likewise.
+        (iordi_zesidi_di): Likewise.
+        (xordi_zesidi_di): Likewise.
+        (andsi_iorsi3_notsi): Likewise.
+        (smax_0): Likewise.
+        (smax_m1): Likewise.
+        (smin_0): Likewise.
+        (not_shiftsi): Likewise.
+        (unaligned_loadsi): Likewise.
+        (unaligned_loadhis): Likewise.
+        (unaligned_loadhiu): Likewise.
+        (unaligned_storesi): Likewise.
+        (unaligned_storehi): Likewise.
+        (extv_reg): Likewise.
+        (extzv_t2): Likewise.
+        (divsi3): Likewise.
+        (udivsi3): Likewise.
+        (arm_zero_extendhisi2addsi): Likewise.
+        (arm_zero_extendqisi2addsi): Likewise.
+        (compareqi_eq0): Likewise.
+        (arm_extendhisi2_v6): Likewise.
+        (arm_extendqisi2addsi): Likewise.
+        (arm_movt): Likewise.
+        (thumb2_ldrd): Likewise.
+        (thumb2_ldrd_base): Likewise.
+        (thumb2_ldrd_base_neg): Likewise.
+        (thumb2_strd): Likewise.
+        (thumb2_strd_base): Likewise.
+        (thumb2_strd_base_neg): Likewise.
+        (arm_negsi2): Add alternative for 16-bit encoding.
+        (arm_one_cmplsi2): Likewise.
+
+2013-06-28  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/predicates.md (arm_cond_move_operator): New predicate.
+        * config/arm/arm.md (movsfcc): Use arm_cond_move_operator predicate.
+        (movdfcc): Likewise.
+        * config/arm/vfp.md (*thumb2_movsf_vfp):
+        Disable predication for arm_restrict_it.
+        (*thumb2_movsfcc_vfp): Disable for arm_restrict_it.
+        (*thumb2_movdfcc_vfp): Likewise.
+        (*abssf2_vfp, *absdf2_vfp, *negsf2_vfp, *negdf2_vfp,*addsf3_vfp,
+        *adddf3_vfp, *subsf3_vfp, *subdf3_vfpc, *divsf3_vfp,*divdf3_vfp,
+        *mulsf3_vfp, *muldf3_vfp, *mulsf3negsf_vfp, *muldf3negdf_vfp,
+        *mulsf3addsf_vfp, *muldf3adddf_vfp, *mulsf3subsf_vfp,
+        *muldf3subdf_vfp, *mulsf3negsfaddsf_vfp, *fmuldf3negdfadddf_vfp,
+        *mulsf3negsfsubsf_vfp, *muldf3negdfsubdf_vfp, *fma<SDF:mode>4,
+        *fmsub<SDF:mode>4, *fnmsub<SDF:mode>4, *fnmadd<SDF:mode>4,
+        *extendsfdf2_vfp, *truncdfsf2_vfp, *extendhfsf2, *truncsfhf2,
+        *truncsisf2_vfp, *truncsidf2_vfp, fixuns_truncsfsi2, fixuns_truncdfsi2,
+        *floatsisf2_vfp, *floatsidf2_vfp, floatunssisf2, floatunssidf2,
+        *sqrtsf2_vfp, *sqrtdf2_vfp, *cmpsf_vfp, *cmpsf_trap_vfp, *cmpdf_vfp,
+        *cmpdf_trap_vfp, <vrint_pattern><SDF:mode>2):
+        Disable predication for arm_restrict_it.
+
+2013-06-26  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.h (MAX_CONDITIONAL_EXECUTE): Define macro.
+        * config/arm/arm-protos.h (arm_max_conditional_execute): New
+        declaration.
+        (tune_params): Update comment.
+        * config/arm/arm.c (arm_cortex_a15_tune): Set max_cond_insns to 2.
+        (arm_max_conditional_execute): New function.
+        (thumb2_final_prescan_insn): Use max_insn_skipped and
+        MAX_INSN_PER_IT_BLOCK to compute maximum instructions in a block.
+
+2013-06-19  Sofiane Naci  <sofiane.naci@arm.com>
+
+        * config/arm/vfp.md: Move VFP instruction classification documentation
+        to ...
+        * config/arm/arm.md: ... here.  Update instruction classification
+        documentation.
+
+2013-06-19  Richard Earnshaw  <rearnsha@arm.com>
+
+        arm.md (split for eq(reg, 0)): Add variants for ARMv5 and Thumb2.
+        (peepholes for eq(reg, not-0)): Ensure condition register is dead after
+        pattern.  Use more efficient sequences on ARMv5 and Thumb2.
+
+2013-06-18  Julian Brown  <julian@codesourcery.com>
+
+        * config/arm/arm.c (neon_vector_mem_operand): Add strict argument.
+        Permit virtual register pre-reload if !strict.
+        (coproc_secondary_reload_class): Adjust for neon_vector_mem_operand
+        change.
+        * config/arm/arm-protos.h (neon_vector_mem_operand): Adjust
+        prototype.
+        * config/arm/neon.md (movmisalign<mode>): Use
+        neon_perm_struct_or_reg_operand instead of
+        neon_struct_or_register_operand.
+        (*movmisalign<mode>_neon_load, *movmisalign<mode>_neon_store): Use
+        neon_permissive_struct_operand instead of neon_struct_operand.
+        * config/arm/constraints.md (Un, Um, Us): Adjust calls to
+        neon_vector_mem_operand.
+        * config/arm/predicates.md (neon_struct_operand): Adjust call to
+        neon_vector_mem_operand.
+        (neon_permissive_struct_operand): New.
+        (neon_struct_or_register_operand): Rename to...
+        (neon_perm_struct_or_reg_operand): This. Adjust call to
+        neon_vector_mem_operand.
+
+2013-06-18  Sofiane Naci  <sofiane.naci@arm.com>
+
+        * config/arm/arm.md (attribute "insn"): Move multiplication and division
+        attributes to...
+        (attribute "type"): ... here.  Remove mult.
+        (attribute "mul32"): New attribute.
+        (attribute "mul64"): Add umaal.
+        (*arm_mulsi3): Update attributes.
+        (*arm_mulsi3_v6): Likewise.
+        (*thumb_mulsi3): Likewise.
+        (*thumb_mulsi3_v6): Likewise.
+        (*mulsi3_compare0): Likewise.
+        (*mulsi3_compare0_v6): Likewise.
+        (*mulsi_compare0_scratch): Likewise.
+        (*mulsi_compare0_scratch_v6): Likewise.
+        (*mulsi3addsi): Likewise.
+        (*mulsi3addsi_v6): Likewise.
+        (*mulsi3addsi_compare0): Likewise.
+        (*mulsi3addsi_compare0_v6): Likewise.
+        (*mulsi3addsi_compare0_scratch): Likewise.
+        (*mulsi3addsi_compare0_scratch_v6): Likewise.
+        (*mulsi3subsi): Likewise.
+        (*mulsidi3adddi): Likewise.
+        (*mulsi3addsi_v6): Likewise.
+        (*mulsidi3adddi_v6): Likewise.
+        (*mulsidi3_nov6): Likewise.
+        (*mulsidi3_v6): Likewise.
+        (*umulsidi3_nov6): Likewise.
+        (*umulsidi3_v6): Likewise.
+        (*umulsidi3adddi): Likewise.
+        (*umulsidi3adddi_v6): Likewise.
+        (*smulsi3_highpart_nov6): Likewise.
+        (*smulsi3_highpart_v6): Likewise.
+        (*umulsi3_highpart_nov6): Likewise.
+        (*umulsi3_highpart_v6): Likewise.
+        (mulhisi3): Likewise.
+        (*mulhisi3tb): Likewise.
+        (*mulhisi3bt): Likewise.
+        (*mulhisi3tt): Likewise.
+        (maddhisi4): Likewise.
+        (*maddhisi4tb): Likewise.
+        (*maddhisi4tt): Likewise.
+        (maddhidi4): Likewise.
+        (*maddhidi4tb): Likewise.
+        (*maddhidi4tt): Likewise.
+        (divsi3): Likewise.
+        (udivsi3): Likewise.
+        * config/arm/thumb2.md (thumb2_mulsi_short): Update attributes.
+        (thumb2_mulsi_short_compare0): Likewise.
+        (thumb2_mulsi_short_compare0_scratch): Likewise.
+        * config/arm/arm1020e.md (1020mult1): Update attribute change.
+        (1020mult2): Likewise.
+        (1020mult3): Likewise.
+        (1020mult4): Likewise.
+        (1020mult5): Likewise.
+        (1020mult6): Likewise.
+        * config/arm/cortex-a15.md (cortex_a15_mult32): Update attribute change.
+        (cortex_a15_mult64): Likewise.
+        (cortex_a15_sdiv): Likewise.
+        (cortex_a15_udiv): Likewise.
+        * config/arm/arm1026ejs.md (mult1): Update attribute change.
+        (mult2): Likewise.
+        (mult3): Likewise.
+        (mult4): Likewise.
+        (mult5): Likewise.
+        (mult6): Likewise.
+        * config/arm/marvell-pj4.md (pj4_ir_mul): Update attribute change.
+        (pj4_ir_div): Likewise.
+        * config/arm/arm1136jfs.md (11_mult1): Update attribute change.
+        (11_mult2): Likewise.
+        (11_mult3): Likewise.
+        (11_mult4): Likewise.
+        (11_mult5): Likewise.
+        (11_mult6): Likewise.
+        (11_mult7): Likewise.
+        * config/arm/cortex-a8.md (cortex_a8_mul): Update attribute change.
+        (cortex_a8_mla): Likewise.
+        (cortex_a8_mull): Likewise.
+        (cortex_a8_smulwy): Likewise.
+        (cortex_a8_smlald): Likewise.
+        * config/arm/cortex-m4.md (cortex_m4_alu): Update attribute change.
+        * config/arm/cortex-r4.md (cortex_r4_mul_4): Update attribute change.
+        (cortex_r4_mul_3): Likewise.
+        (cortex_r4_mla_4): Likewise.
+        (cortex_r4_mla_3): Likewise.
+        (cortex_r4_smlald): Likewise.
+        (cortex_r4_mull): Likewise.
+        (cortex_r4_sdiv): Likewise.
+        (cortex_r4_udiv): Likewise.
+        * config/arm/cortex-a7.md (cortex_a7_mul): Update attribute change.
+        (cortex_a7_idiv): Likewise.
+        * config/arm/arm926ejs.md (9_mult1): Update attribute change.
+        (9_mult2): Likewise.
+        (9_mult3): Likewise.
+        (9_mult4): Likewise.
+        (9_mult5): Likewise.
+        (9_mult6): Likewise.
+        * config/arm/cortex-a53.md (cortex_a53_mul): Update attribute change.
+        (cortex_a53_sdiv): Likewise.
+        (cortex_a53_udiv): Likewise.
+        * config/arm/fa726te.md (726te_mult_op): Update attribute change.
+        * config/arm/fmp626.md (mp626_mult1): Update attribute change.
+        (mp626_mult2): Likewise.
+        (mp626_mult3): Likewise.
+        (mp626_mult4): Likewise.
+        * config/arm/fa526.md (526_mult1): Update attribute change.
+        (526_mult2): Likewise.
+        * config/arm/arm-generic.md (mult): Update attribute change.
+        (mult_ldsched_strongarm): Likewise.
+        (mult_ldsched): Likewise.
+        (multi_cycle): Likewise.
+        * config/arm/cortex-a5.md (cortex_a5_mul): Update attribute change.
+        * config/arm/fa606te.md (606te_mult1): Update attribute change.
+        (606te_mult2): Likewise.
+        (606te_mult3): Likewise.
+        (606te_mult4): Likewise.
+        * config/arm/cortex-a9.md (cortex_a9_mult16): Update attribute change.
+        (cortex_a9_mac16): Likewise.
+        (cortex_a9_multiply): Likewise.
+        (cortex_a9_mac): Likewise.
+        (cortex_a9_multiply_long): Likewise.
+        (cortex_a9_mac): Likewise.
+        (cortex_a9_multiply_long): Likewise.
+        * config/arm/fa626te.md (626te_mult1): Update attribute change.
+        (626te_mult2): Likewise.
+        (626te_mult3): Likewise.
+        (626te_mult4): Likewise.
+
+2013-06-07  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        PR target/56315
+        * config/arm/arm.md (*xordi3_insn): Change to insn_and_split.
+        (xordi3): Change operand 2 constraint to arm_xordi_operand.
+        * config/arm/arm.c (const_ok_for_dimode_op): Handle XOR.
+        * config/arm/constraints.md (Dg): New constraint.
+        * config/arm/neon.md (xordi3_neon): Remove.
+        (neon_veor<mode>): Generate xordi3 instead of xordi3_neon.
+        * config/arm/predicates.md (arm_xordi_operand): New predicate.
+
+2013-06-07  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.md (anddi3_insn): Remove duplicate alternatives.
+        Clean up alternatives.
+
+2013-06-07  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/constraints.md (Df): New constraint.
+        * config/arm/arm.md (iordi3_insn): Use Df constraint instead of De.
+        Correct length attribute for last two alternatives.
+
+2013-06-06  Eric Botcazou  <ebotcazou@adacore.com>
+
+        * config/arm/arm.c (arm_r3_live_at_start_p): New predicate.
+        (arm_compute_static_chain_stack_bytes): Use it.  Tidy up.
+        (arm_expand_prologue): Likewise.
+
+2013-06-06  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm-fixed.md (add<mode>3,usadd<mode>3,ssadd<mode>3,
+        sub<mode>3, ussub<mode>3, sssub<mode>3, arm_ssatsihi_shift,
+        arm_usatsihi): Adjust alternatives for arm_restrict_it.
+
+2013-06-06  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm-ldmstm.ml: Set "predicable_short_it" to "no"
+        where appropriate.
+        * config/arm/ldmstm.md: Regenerate.
+
+2013-06-06  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/sync.md (atomic_loaddi_1):
+        Disable predication for arm_restrict_it.
+        (arm_load_exclusive<mode>): Likewise.
+        (arm_load_exclusivesi): Likewise.
+        (arm_load_exclusivedi): Likewise.
+        (arm_load_acquire_exclusive<mode>): Likewise.
+        (arm_load_acquire_exclusivesi): Likewise.
+        (arm_load_acquire_exclusivedi): Likewise.
+        (arm_store_exclusive<mode>): Likewise.
+        (arm_store_exclusive<mode>): Likewise.
+        (arm_store_release_exclusivedi): Likewise.
+        (arm_store_release_exclusive<mode>): Likewise.
+
+2013-06-05  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.c (MAX_INSN_PER_IT_BLOCK): New macro.
+        (arm_option_override): Override arm_restrict_it where appropriate.
+        (thumb2_final_prescan_insn): Use MAX_INSN_PER_IT_BLOCK.
+        * config/arm/arm.opt (mrestrict-it): New command-line option.
+        * doc/invoke.texi: Document -mrestrict-it.
+
+2013-05-31  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        PR target/56315
+        * config/arm/arm.c (const_ok_for_dimode_op): Handle IOR.
+        * config/arm/arm.md (*iordi3_insn): Change to insn_and_split.
+        * config/arm/neon.md (iordi3_neon): Remove.
+        (neon_vorr<mode>): Generate iordi3 instead of iordi3_neon.
+        * config/arm/predicates.md (imm_for_neon_logic_operand):
+        Move to earlier in the file.
+        (neon_logic_op2): Likewise.
+        (arm_iordi_operand_neon): New predicate.
+
+2013-05-30  Bernd Schmidt  <bernds@codesourcery.com>
+            Zhenqiang Chen  <zhenqiang.chen@linaro.org>
+
+        * config/arm/arm-protos.h: Add and update function protos.
+        * config/arm/arm.c (use_simple_return_p): New added.
+        (thumb2_expand_return): Check simple_return flag.
+        * config/arm/arm.md: Add simple_return and conditional simple_return.
+        * config/arm/iterators.md: Add iterator for return and simple_return.
+
+2013-05-30  Zhenqiang Chen  <zhenqiang.chen@linaro.org>
+
+        * config/arm/arm.c (arm_add_cfa_adjust_cfa_note): New added.
+        (arm_emit_multi_reg_pop): Add REG_CFA_ADJUST_CFA notes.
+        (arm_emit_vfp_multi_reg_pop): Likewise.
+        (thumb2_emit_ldrd_pop): Likewise.
+        (arm_expand_epilogue): Add misc REG_CFA notes.
+        (arm_unwind_emit): Skip REG_CFA_ADJUST_CFA and REG_CFA_RESTORE.
+
+2013-05-29  Lawrence Crowl  <crowl@google.com>
+
+        * config/arm/t-arm: Update for below.
+
+        * config/arm/arm.c (arm_libcall_uses_aapcs_base::libcall_htab):
+        Change type to hash_table.  Update dependent calls and types.
+
+        * config/i386/t-cygming: Update for below.
+
+        * config/i386/t-interix: Update for below.
+
+        * config/i386/winnt.c (i386_pe_section_type_flags::htab):
+        Change type to hash_table.  Update dependent calls and types.
+        (i386_find_on_wrapper_list::wrappers): Likewise.
+
+        * config/ia64/t-ia64: Update for below.
+
+        * config/ia64/ia64.c (bundle_state_table):
+        Change type to hash_table.  Update dependent calls and types.
+
+        * config/mips/mips.c (mips_reorg_process_insns::htab):
+        Change type to hash_table.  Update dependent calls and types.
+
+        * config/sol2.c (solaris_comdat_htab):
+        Change type to hash_table.  Update dependent calls and types.
+
+        * config/t-sol2: Update for above.
+
+2013-05-23  Christian Bruel  <christian.bruel@st.com>
+
+        PR debug/57351
+        * config/arm/arm.c (arm_dwarf_register_span): Do not use dbx number.
+
+2013-05-22  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>
+
+        PR target/19599
+        PR target/57340
+        * config/arm/arm.c (any_sibcall_uses_r3): Rename to ..
+        (any_sibcall_could_use_r3): this and handle indirect calls.
+        (arm_get_frame_offsets): Rename use of any_sibcall_uses_r3.
+
+2013-05-16  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>
+
+        PR target/19599
+        * config/arm/arm.c (arm_function_ok_for_sibcall): Add check
+        for NULL decl.
+
+2013-05-16  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm-protos.h (gen_movmem_ldrd_strd): New declaration.
+        * config/arm/arm.c (next_consecutive_mem): New function.
+        (gen_movmem_ldrd_strd): Likewise.
+        * config/arm/arm.md (movmemqi): Update condition and code.
+        (unaligned_loaddi, unaligned_storedi): New patterns.
+
+2013-05-15  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>
+
+        PR target/19599
+        * config/arm/predicates.md (call_insn_operand): New predicate.
+        * config/arm/constraints.md ("Cs", "Ss"):  New constraints.
+        * config/arm/arm.md (*call_insn, *call_value_insn): Match only
+        if insn is not a tail call.
+        (*sibcall_insn, *sibcall_value_insn): Adjust for tailcalling through
+        registers.
+        * config/arm/arm.h (enum reg_class): New caller save register class.
+        (REG_CLASS_NAMES): Likewise.
+        (REG_CLASS_CONTENTS): Likewise.
+        * config/arm/arm.c (arm_function_ok_for_sibcall): Allow tailcalling
+        without decls.
+
+2013-05-14  Chung-Lin Tang  <cltang@codesourcery.com>
+
+        PR target/42017
+        * config/arm/arm.h (EPILOGUE_USES): Only return true
+        for LR_REGNUM after epilogue_completed.
+
+2013-05-07  Christophe Lyon  <christophe.lyon@linaro.org>
+
+**** cfx-note: adapted for the AOSP default addition of -fpic for the ASAN_CC1_SPEC definition
+        * config/arm/arm.c (arm_asan_shadow_offset): New function.
+        (TARGET_ASAN_SHADOW_OFFSET): Define.
+        * config/arm/linux-eabi.h (ASAN_CC1_SPEC): Define.
+        (LINUX_OR_ANDROID_CC): Add ASAN_CC1_SPEC.
+
+2013-05-01  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/thumb2.md (thumb2_smaxsi3,thumb2_sminsi3): Convert
+        define_insn to define_insn_and_split.
+        (thumb32_umaxsi3,thumb2_uminsi3): Likewise.
+        (thumb2_negdi2,thumb2_abssi2,thumb2_neg_abssi2): Likewise.
+        (thumb2_mov_scc,thumb2_mov_negscc,thumb2_mov_notscc): Likewise.
+        (thumb2_movsicc_insn,thumb2_and_scc,thumb2_ior_scc): Likewise.
+        (thumb2_negscc): Likewise.
+
+2013-04-30  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/thumb2.md (thumb2_incscc, thumb2_decscc): Delete.
+
+2013-04-30  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/thumb2.md: Remove trailing whitespaces.
+
+2013-04-29  Mike Frysinger  <vapier@gentoo.org>
+
+        * config/arm/bpabi.h (EABI_LINK_SPEC): Define.
+        (BPABI_LINK_SPEC): Use new EABI_LINK_SPEC.
+        * config/arm/linux-eabi.h (LINK_SPEC): Replace BE8_LINK_SPEC
+        with EABI_LINK_SPEC.
+
+2013-04-29  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.md (store_minmaxsi): Use only when
+        optimize_insn_for_size_p.
+
+2013-04-26  Jakub Jelinek  <jakub@redhat.com>
+
+        * Makefile.in (toplev.o): Depend on diagnostic-color.h.
+        * diagnostic-color.c (should_colorize): Remove _WIN32 version.
+        (colorize_init): Add argument to _WIN32 version.
+        * toplev.c: Include diagnostic-color.h.
+        (process_options): Default to -fdiagnostics-color=auto if
+        GCC_COLORS env var is in the environment.
+        * common.opt (fdiagnostics-color=): Add Var and Init.
+        * doc/invoke.texi (-fdiagnostics-color=): Document that if
+        GCC_COLORS env var is in the environment, the default is auto
+        rather than never.
+
+        * diagnostic.h (file_name_as_prefix): Add context argument.
+        * diagnostic.c (file_name_as_prefix): Likewise.  Colorize
+        the string as locus.
+        * langhooks.c (lhd_print_error_function): Adjust caller.
+
+2013-04-19  Greta Yorsh  <Greta.Yorsh@arm.com>
+        * config/arm/arm.c (load_multiple_sequence, ldm_stm_operation_p): Fix
+        spelling in two comments.
+
+2013-04-19  Terry Guo  <terry.guo@arm.com>
+
+        * config/arm/cortex-m4-fpu.md (cortex_m4_v): Delete cpu unit.
+        Replace with ...
+        (cortex_m4_v_a,  cortex_m4_v_b): ... new cpu units.
+        (cortex_m4_v, cortex_m4_exa_va, cortex_m4_exb_vb): New reservations.
+        (cortex_m4_fmacs): Use new reservations.
+        (cortex_m4_f_load, cortex_m4_f_store): Likewise.
+
+2013-04-17  Greta Yorsh  <Greta.Yorsh at arm.com>
+
+        * config/arm/arm.md (movsicc_insn): Convert define_insn into
+        define_insn_and_split.
+        (and_scc,ior_scc,negscc): Likewise.
+        (cmpsi2_addneg, subsi3_compare): Convert to named patterns.
+
+2013-04-17  Greta Yorsh  <Greta.Yorsh at arm.com>
+
+        * config/arm/arm.c (use_return_insn): Return 0 for targets that
+        can benefit from using a sequence of LDRD instructions in epilogue
+        instead of a single LDM instruction.
+
+2013-04-17  Terry Guo  <terry.guo@arm.com>
+
+        * config/arm/cortex-m4.md: Add a new bypass.
+
+2013-04-16  Greta Yorsh  <Greta.Yorsh at arm.com>
+
+        * config/arm/arm.c (emit_multi_reg_push): New declaration
+        for an existing function.
+        (arm_emit_strd_push): New function.
+        (arm_expand_prologue): Used here.
+        (arm_emit_ldrd_pop): New function.
+        (arm_expand_epilogue): Used here.
+        (arm_get_frame_offsets): Update condition.
+        (arm_emit_multi_reg_pop): Add a special case for load of a single
+        register with writeback.
+
+2013-04-15  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.c (const_ok_for_dimode_op): Handle AND case.
+        * config/arm/arm.md (*anddi3_insn): Change to insn_and_split.
+        * config/arm/constraints.md (De): New constraint.
+        * config/arm/neon.md (anddi3_neon): Delete.
+        (neon_vand<mode>): Expand to standard anddi3 pattern.
+        * config/arm/predicates.md (imm_for_neon_inv_logic_operand):
+        Move earlier in the file.
+        (neon_inv_logic_op2): Likewise.
+        (arm_anddi_operand_neon): New predicate.
+
+2013-04-15  Joey Ye  <joey.ye@arm.com>
+
+        * config/arm/arm.c (thumb_far_jump_used_p): Fix typo in comments.
+
+2013-04-15  Joey Ye  <joey.ye@arm.com>
+
+        * config/arm/arm.c (thumb1_final_prescan_insn): Assert lr save
+        for real far jump.
+        (thumb_far_jump_used_p): Count instruction size and set
+        far_jump_used.
+
+2013-04-12  Manuel López-Ibáñez  <manu@gcc.gnu.org>
+            Jakub Jelinek  <jakub@redhat.com>
+
+        * opts.c: Include diagnostic-color.h.
+        (common_handle_option): Handle OPT_fdiagnostics_color_.
+        * Makefile.in (OBJS-libcommon): Add diagnostic-color.o.
+        (diagnostic.o, opts.o, pretty-print.o): Depend on diagnostic-color.h.
+        (diagnostic-color.o): New.
+        * common.opt (fdiagnostics-color, fdiagnostics-color=): New options.
+        (diagnostic_color_rule): New enum.
+        * dwarf2out.c (gen_producer_string): Don't print -fdiagnostics-color*.
+        * langhooks.c (lhd_print_error_function): Add %r "locus" and %R around
+        the location string.
+        * diagnostic.def: Add 3rd argument to DEFINE_DIAGNOSTIC_KIND macros,
+        either NULL, or color kind.
+        * diagnostic-color.c: New file.
+        * diagnostic-color.h: New file.
+        * diagnostic-core.h (DEFINE_DIAGNOSTIC_KIND): Adjust macro for 3
+        arguments.
+        * doc/invoke.texi (-fdiagnostics-color): Document.
+        * pretty-print.h (pp_show_color): Define.
+        (struct pretty_print_info): Add show_color field.
+        * diagnostic.c: Include diagnostic-color.h.
+        (diagnostic_build_prefix): Adjust for 3 argument DEFINE_DIAGNOSTIC_KIND
+        macros.  Colorize error:, warning: etc. strings and also the location
+        string.
+        (diagnostic_show_locus): Colorize the caret line.
+        * pretty-print.c: Include diagnostic-color.h.
+        (pp_base_format): Handle %r and %R format specifiers.  Colorize strings
+        inside of %< %> quotes or quoted through q format modifier.
+
+2013-04-12  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md (mov_scc,mov_negscc,mov_notscc): Convert
+        define_insn into define_insn_and_split and emit movsicc patterns.
+
+2013-04-12  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.c (gen_operands_ldrd_strd): Initialize "base".
+
+2013-04-09  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.md (minmax_arithsi_non_canon): New pattern.
+
+2013-04-08  Xinyu Qi  <xyqi@marvell.com>
+
+        PR target/54338
+        * config/arm/arm.h (REG_CLASS_CONTENTS): Include IWMMXT_GR_REGS
+        in ALL_REGS.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/constraints.md (q): New constraint.
+        * config/arm/ldrdstrd.md: New file.
+        * config/arm/arm.md (ldrdstrd.md) New include.
+        (arm_movdi): Use "q" instead of "r" constraint
+        for double-word memory access.
+        (movdf_soft_insn): Likewise.
+        * config/arm/vfp.md (movdi_vfp): Likewise.
+        * config/arm/t-arm (MD_INCLUDES): Add ldrdstrd.md.
+        * config/arm/arm-protos.h (gen_operands_ldrd_strd): New declara$
+        * config/arm/arm.c (gen_operands_ldrd_strd): New function.
+        (mem_ok_for_ldrd_strd): Likewise.
+        (output_move_double): Update assertion.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md: Comment on splitting Thumb1 patterns.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md (arm_smax_insn): Convert define_insn into
+        define_insn_and_split.
+        (arm_smin_insn,arm_umaxsi3,arm_uminsi3): Likewise.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md (arm_ashldi3_1bit): Convert define_insn into
+        define_insn_and_split.
+        (arm_ashrdi3_1bit,arm_lshrdi3_1bit): Likewise.
+        (shiftsi3_compare): New pattern.
+        (rrx): New pattern.
+        * config/arm/unspecs.md (UNSPEC_RRX): New.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md (negdi_extendsidi): New pattern.
+        (negdi_zero_extendsidi): Likewise.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md (andsi_iorsi3_notsi): Convert define_insn into
+        define_insn_and_split.
+        (arm_negdi2,arm_abssi2,arm_neg_abssi2): Likewise.
+        (arm_cmpdi_insn,arm_cmpdi_unsigned): Likewise.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md (arm_subdi3): Convert define_insn into
+        define_insn_and_split.
+        (subdi_di_zesidi,subdi_di_sesidi): Likewise.
+        (subdi_zesidi_di,subdi_sesidi_di,subdi_zesidi_zesidi): Likewise.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md (subsi3_carryin): New pattern.
+        (subsi3_carryin_const): Likewise.
+        (subsi3_carryin_compare,subsi3_carryin_compare_const): Likewise.
+        (subsi3_carryin_shift,rsbsi3_carryin_shift): Likewise.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md (incscc,arm_incscc,decscc,arm_decscc): Delete.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * config/arm/arm.md (addsi3_carryin_<optab>): Set attribute predicable.
+        (addsi3_carryin_alt2_<optab>,addsi3_carryin_shift_<optab>): Likewise.
+
+2013-04-05  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.c (arm_expand_builtin): Change fcode
+        type to unsigned int.
+
+2013-04-04  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm-protos.h (arm_builtin_vectorized_function):
+        New function prototype.
+        * config/arm/arm.c (TARGET_VECTORIZE_BUILTINS): Define.
+        (TARGET_VECTORIZE_BUILTIN_VECTORIZED_FUNCTION): Likewise.
+        (arm_builtin_vectorized_function): New function.
+
+2013-04-04  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm_neon_builtins.def: New file.
+        * config/arm/arm.c (neon_builtin_data): Move contents to
+        arm_neon_builtins.def.
+        (enum arm_builtins): Include neon builtin definitions.
+        (ARM_BUILTIN_NEON_BASE): Move from enum to macro.
+        * config/arm/t-arm (arm.o): Add dependency on
+        arm_neon_builtins.def.
+
+2013-04-03  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        PR target/56809
+        * config/arm/arm.c (is_jump_table): Use next_active_insn instead of
+        next_real_insn.
+        (thumb1_output_casesi): Likewise.
+        (thumb2_output_casesi): Likewise.
+
+2013-04-02  Ian Caulfield  <ian.caulfield@arm.com>
+            Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>
+
+        * config/arm/arm-arches.def (armv8-a): Default to cortex-a53.
+        * config/arm/t-arm (MD_INCLUDES): Depend on cortex-a53.md.
+        * config/arm/cortex-a53.md: New file.
+        * config/arm/bpabi.h (BE8_LINK_SPEC): Handle cortex-a53.
+        * config/arm/arm.md (generic_sched, generic_vfp): Handle cortex-a53.
+        * config/arm/arm.c (arm_issue_rate): Likewise.
+        * config/arm/arm-tune.md: Regenerate
+        * config/arm/arm-tables.opt: Regenerate.
+        * config/arm/arm-cores.def: Add cortex-a53.
+
+2013-04-02  Zhenqiang Chen  <zhenqiang.chen@arm.com>
+
+        * config/arm/uclinux-elf.h: Add %L to LINK_GCC_C_SEQUENCE_SPEC for
+        non-static link.
+
+2013-03-27  Bin Cheng  <bin.cheng@arm.com>
+
+        PR target/56102
+        * config/arm/arm.c (thumb1_rtx_costs, thumb1_size_rtx_costs): Fix
+        rtx costs for SET/ASHIFT/ASHIFTRT/LSHIFTRT/ROTATERT patterns with
+        mult-word mode.
+
+2013-03-27  Terry Guo  <terry.guo@arm.com>
+
+        * config/arm/arm-cores.def: Added core cortex-r7.
+        * config/arm/arm-tune.md: Regenerated.
+        * config/arm/arm-tables.opt: Regenerated.
+        * doc/invoke.texi: Added entry for core cortex-r7.
+
+2013-03-26  Xinyu Qi  <xyqi@marvell.com>
+
+        * config/arm/arm.h (FIRST_IWMMXT_GR_REGNUM): Add comment.
+        * config/arm/iwmmxt.md (WCGR0): Update.
+        (WCGR1, WCGR2, WCGR3): Likewise.
+
+2013-03-25  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.md (f_sels, f_seld): New types.
+        (*cmov<mode>): New pattern.
+        * config/arm/predicates.md (arm_vsel_comparison_operator): New
+        predicate.
+
+2013-03-25  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * config/arm/arm.c (arm_emit_load_exclusive): Add acq parameter.
+        Emit load-acquire versions when acq is true.
+        (arm_emit_store_exclusive): Add rel parameter.
+        Emit store-release versions when rel is true.
+        (arm_split_compare_and_swap): Use acquire-release instructions
+        instead.
+        of barriers when appropriate.
+        (arm_split_atomic_op): Likewise.
+        * config/arm/arm.h (TARGET_HAVE_LDACQ): New macro.
+        * config/arm/unspecs.md (VUNSPEC_LAX): New unspec.
+        (VUNSPEC_SLX): Likewise.
+        (VUNSPEC_LDA): Likewise.
+        (VUNSPEC_STL): Likewise.
+        * config/arm/sync.md (atomic_load<mode>): New pattern.
+        (atomic_store<mode>): Likewise.
+        (arm_load_acquire_exclusive<mode>): Likewise.
+        (arm_load_acquire_exclusivesi): Likewise.
+        (arm_load_acquire_exclusivedi): Likewise.
+        (arm_store_release_exclusive<mode>): Likewise.
+
+2013-03-21  Christophe Lyon  <christophe.lyon@linaro.org>
+
+        * config/arm/arm-protos.h (tune_params): Add
+        prefer_neon_for_64bits field.
+        * config/arm/arm.c (prefer_neon_for_64bits): New variable.
+        (arm_slowmul_tune): Default prefer_neon_for_64bits to false.
+        (arm_fastmul_tune, arm_strongarm_tune, arm_xscale_tune): Ditto.
+        (arm_9e_tune, arm_v6t2_tune, arm_cortex_tune): Ditto.
+        (arm_cortex_a15_tune, arm_cortex_a5_tune): Ditto.
+        (arm_cortex_a9_tune, arm_v6m_tune, arm_fa726te_tune): Ditto.
+        (arm_option_override): Handle -mneon-for-64bits new option.
+        * config/arm/arm.h (TARGET_PREFER_NEON_64BITS): New macro.
+        (prefer_neon_for_64bits): Declare new variable.
+        * config/arm/arm.md (arch): Rename neon_onlya8 and neon_nota8 to
+        avoid_neon_for_64bits and neon_for_64bits. Remove onlya8 and
+        nota8.
+        (arch_enabled): Handle new arch types. Remove support for onlya8
+        and nota8.
+        (one_cmpldi2): Use new arch names.
+        * config/arm/arm.opt (mneon-for-64bits): Add option.
+        * config/arm/neon.md (adddi3_neon, subdi3_neon, iordi3_neon)
+        (anddi3_neon, xordi3_neon, ashldi3_neon, <shift>di3_neon): Use
+        neon_for_64bits instead of nota8 and avoid_neon_for_64bits instead
+        of onlya8.
+        * doc/invoke.texi (-mneon-for-64bits): Document.
diff --git a/gcc/Makefile.in b/gcc/Makefile.in
index aad927c..045de75 100644
--- a/gcc/Makefile.in
+++ b/gcc/Makefile.in
@@ -1463,7 +1463,7 @@ OBJS = \
 
 # Objects in libcommon.a, potentially used by all host binaries and with
 # no target dependencies.
-OBJS-libcommon = diagnostic.o pretty-print.o intl.o input.o version.o
+OBJS-libcommon = diagnostic.o diagnostic-color.o pretty-print.o intl.o input.o version.o
 
 # Objects in libcommon-target.a, used by drivers and by the core
 # compiler and containing target-dependent code.
@@ -2659,11 +2659,12 @@ fold-const.o : fold-const.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \
    $(GIMPLE_H) realmpfr.h $(TREE_FLOW_H)
 diagnostic.o : diagnostic.c $(CONFIG_H) $(SYSTEM_H) coretypes.h \
    version.h $(DEMANGLE_H) $(INPUT_H) intl.h $(BACKTRACE_H) $(DIAGNOSTIC_H) \
-   diagnostic.def
+   diagnostic.def diagnostic-color.h
+diagnostic-color.o : diagnostic-color.c $(CONFIG_H) $(SYSTEM_H) diagnostic-color.h
 opts.o : opts.c $(OPTS_H) $(OPTIONS_H) $(DIAGNOSTIC_CORE_H) $(CONFIG_H) $(SYSTEM_H) \
    coretypes.h dumpfile.h $(TM_H) \
    $(DIAGNOSTIC_H) insn-attr-common.h intl.h $(COMMON_TARGET_H) \
-   $(FLAGS_H) $(PARAMS_H) opts-diagnostic.h
+   $(FLAGS_H) $(PARAMS_H) opts-diagnostic.h diagnostic-color.h
 opts-global.o : opts-global.c $(CONFIG_H) $(SYSTEM_H) coretypes.h \
    $(DIAGNOSTIC_H) $(OPTS_H) $(FLAGS_H) $(GGC_H) $(TREE_H) langhooks.h \
    $(TM_H) $(RTL_H) $(DBGCNT_H) debug.h $(LTO_STREAMER_H) output.h \
@@ -2700,7 +2701,7 @@ toplev.o : toplev.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(TREE_H) \
    $(OPTS_H) params.def tree-mudflap.h $(TREE_PASS_H) $(GIMPLE_H) \
    tree-ssa-alias.h $(PLUGIN_H) realmpfr.h tree-diagnostic.h \
    $(TREE_PRETTY_PRINT_H) opts-diagnostic.h $(COMMON_TARGET_H) \
-   tsan.h
+   tsan.h diagnostic-color.h
 
 hwint.o : hwint.c $(CONFIG_H) $(SYSTEM_H) $(DIAGNOSTIC_CORE_H)
 
@@ -3409,7 +3410,8 @@ params.o : params.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(COMMON_TARGET_H) \
    $(PARAMS_H) $(DIAGNOSTIC_CORE_H)
 pointer-set.o: pointer-set.c pointer-set.h $(CONFIG_H) $(SYSTEM_H)
 hooks.o: hooks.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(HOOKS_H)
-pretty-print.o: $(CONFIG_H) $(SYSTEM_H) coretypes.h intl.h $(PRETTY_PRINT_H)
+pretty-print.o: $(CONFIG_H) $(SYSTEM_H) coretypes.h intl.h $(PRETTY_PRINT_H) \
+   diagnostic-color.h
 errors.o : errors.c $(CONFIG_H) $(SYSTEM_H) errors.h
 dbgcnt.o: dbgcnt.c $(CONFIG_H) $(SYSTEM_H) coretypes.h dumpfile.h \
     $(DIAGNOSTIC_CORE_H) $(DBGCNT_H)
diff --git a/gcc/c-family/ChangeLog.cfx b/gcc/c-family/ChangeLog.cfx
new file mode 100644
index 0000000..f328573
--- /dev/null
+++ b/gcc/c-family/ChangeLog.cfx
@@ -0,0 +1,6 @@
+2013-04-12  Jakub Jelinek  <jakub@redhat.com>
+
+        * c-format.c (gcc_diag_char_table, gcc_tdiag_char_table,
+        gcc_cdiag_char_table, gcc_cxxdiag_char_table): Add %r and %R format
+        specifiers.
+
diff --git a/gcc/c-family/c-format.c b/gcc/c-family/c-format.c
index 8f1ffed..c11d93a 100644
--- a/gcc/c-family/c-format.c
+++ b/gcc/c-family/c-format.c
@@ -654,9 +654,10 @@ static const format_char_info gcc_diag_char_table[] =
   /* Custom conversion specifiers.  */
 
   /* These will require a "tree" at runtime.  */
-  { "K", 0, STD_C89, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "q",    "",   NULL },
+  { "K",   0, STD_C89, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "q",    "",   NULL },
 
-  { "<>'", 0, STD_C89, NOARGUMENTS, "",      "",   NULL },
+  { "r",   1, STD_C89, { T89_C,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "",    "cR",   NULL },
+  { "<>'R",0, STD_C89, NOARGUMENTS, "",      "",   NULL },
   { "m",   0, STD_C89, NOARGUMENTS, "q",     "",   NULL },
   { NULL,  0, STD_C89, NOLENGTHS, NULL, NULL, NULL }
 };
@@ -676,9 +677,10 @@ static const format_char_info gcc_tdiag_char_table[] =
   /* These will require a "tree" at runtime.  */
   { "DFKTEV", 0, STD_C89, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "q+", "",   NULL },
 
-  { "v", 0,STD_C89, { T89_I,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "q#",  "",   NULL },
+  { "v",   0, STD_C89, { T89_I,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "q#",  "",   NULL },
 
-  { "<>'", 0, STD_C89, NOARGUMENTS, "",      "",   NULL },
+  { "r",   1, STD_C89, { T89_C,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "",    "cR",   NULL },
+  { "<>'R",0, STD_C89, NOARGUMENTS, "",      "",   NULL },
   { "m",   0, STD_C89, NOARGUMENTS, "q",     "",   NULL },
   { NULL,  0, STD_C89, NOLENGTHS, NULL, NULL, NULL }
 };
@@ -698,9 +700,10 @@ static const format_char_info gcc_cdiag_char_table[] =
   /* These will require a "tree" at runtime.  */
   { "DEFKTV", 0, STD_C89, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "q+", "",   NULL },
 
-  { "v", 0,STD_C89, { T89_I,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "q#",  "",   NULL },
+  { "v",   0, STD_C89, { T89_I,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "q#",  "",   NULL },
 
-  { "<>'", 0, STD_C89, NOARGUMENTS, "",      "",   NULL },
+  { "r",   1, STD_C89, { T89_C,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "",    "cR",   NULL },
+  { "<>'R",0, STD_C89, NOARGUMENTS, "",      "",   NULL },
   { "m",   0, STD_C89, NOARGUMENTS, "q",     "",   NULL },
   { NULL,  0, STD_C89, NOLENGTHS, NULL, NULL, NULL }
 };
@@ -725,7 +728,8 @@ static const format_char_info gcc_cxxdiag_char_table[] =
   /* These accept either an 'int' or an 'enum tree_code' (which is handled as an 'int'.)  */
   { "CLOPQ",0,STD_C89, { T89_I,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "q",  "",   NULL },
 
-  { "<>'", 0, STD_C89, NOARGUMENTS, "",      "",   NULL },
+  { "r",   1, STD_C89, { T89_C,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "",    "cR",   NULL },
+  { "<>'R",0, STD_C89, NOARGUMENTS, "",      "",   NULL },
   { "m",   0, STD_C89, NOARGUMENTS, "q",     "",   NULL },
   { NULL,  0, STD_C89, NOLENGTHS, NULL, NULL, NULL }
 };
diff --git a/gcc/collect2.c b/gcc/collect2.c
index 8284a2e..bbd815c 100644
--- a/gcc/collect2.c
+++ b/gcc/collect2.c
@@ -841,6 +841,7 @@ main (int argc, char **argv)
       USE_PLUGIN_LD,
       USE_GOLD_LD,
       USE_BFD_LD,
+      USE_MCLD_LD,
       USE_LD_MAX
     } selected_linker = USE_DEFAULT_LD;
   static const char *const ld_suffixes[USE_LD_MAX] =
@@ -849,6 +850,7 @@ main (int argc, char **argv)
       PLUGIN_LD_SUFFIX,
       "ld.gold",
       "ld.bfd"
+      "ld.mcld"
     };
   static const char *const real_ld_suffix = "real-ld";
   static const char *const collect_ld_suffix = "collect-ld";
@@ -1018,6 +1020,8 @@ main (int argc, char **argv)
 	  selected_linker = USE_BFD_LD;
 	else if (strcmp (argv[i], "-fuse-ld=gold") == 0)
 	  selected_linker = USE_GOLD_LD;
+	else if (strcmp (argv[i], "-fuse-ld=mcld") == 0)
+	  selected_linker = USE_MCLD_LD;
 
 #ifdef COLLECT_EXPORT_LIST
 	/* These flags are position independent, although their order
@@ -1286,7 +1290,7 @@ main (int argc, char **argv)
 	      else if (!use_collect_ld
 		       && strncmp (arg, "-fuse-ld=", 9) == 0)
 		{
-		  /* Do not pass -fuse-ld={bfd|gold} to the linker. */
+		  /* Do not pass -fuse-ld={bfd|gold|mcld} to the linker. */
 		  ld1--;
 		  ld2--;
 		}
diff --git a/gcc/common.opt b/gcc/common.opt
index bdbd3b6..919ebe3 100644
--- a/gcc/common.opt
+++ b/gcc/common.opt
@@ -1023,6 +1023,30 @@ fdiagnostics-show-caret
 Common Var(flag_diagnostics_show_caret) Init(1)
 Show the source line with a caret indicating the column
 
+fdiagnostics-color
+Common Alias(fdiagnostics-color=,always,never)
+;
+
+fdiagnostics-color=
+Common Joined RejectNegative Var(flag_diagnostics_show_color) Enum(diagnostic_color_rule) Init(DIAGNOSTICS_COLOR_NO)
+-fdiagnostics-color=[never|always|auto]	Colorize diagnostics
+
+; Required for these enum values.
+SourceInclude
+diagnostic-color.h
+
+Enum
+Name(diagnostic_color_rule) Type(int)
+
+EnumValue
+Enum(diagnostic_color_rule) String(never) Value(DIAGNOSTICS_COLOR_NO)
+
+EnumValue
+Enum(diagnostic_color_rule) String(always) Value(DIAGNOSTICS_COLOR_YES)
+
+EnumValue
+Enum(diagnostic_color_rule) String(auto) Value(DIAGNOSTICS_COLOR_AUTO)
+
 fdiagnostics-show-option
 Common Var(flag_diagnostics_show_option) Init(1)
 Amend appropriate diagnostic messages with the command line option that controls them
diff --git a/gcc/config.gcc b/gcc/config.gcc
index a927964..048702a 100644
--- a/gcc/config.gcc
+++ b/gcc/config.gcc
@@ -1829,6 +1829,12 @@ mips*-*-linux*)				# Linux MIPS, either endian.
         mipsisa32*)
 		tm_defines="${tm_defines} MIPS_ISA_DEFAULT=32"
         esac
+	case ${target} in
+	*android*)
+		# Default to little-endian for MIPS Android
+		# tm_defines="${tm_defines} TARGET_ENDIAN_DEFAULT=0"
+		tmake_file="$tmake_file mips/t-linux-android"
+        esac
 	test x$with_llsc != x || with_llsc=yes
 	;;
 mips*-mti-elf*)
diff --git a/gcc/config/arm/arm-arches.def b/gcc/config/arm/arm-arches.def
index 6131630..fcf3401 100644
--- a/gcc/config/arm/arm-arches.def
+++ b/gcc/config/arm/arm-arches.def
@@ -53,6 +53,6 @@ ARM_ARCH("armv7-a", cortexa8,	7A,  FL_CO_PROC |	      FL_FOR_ARCH7A)
 ARM_ARCH("armv7-r", cortexr4,	7R,  FL_CO_PROC |	      FL_FOR_ARCH7R)
 ARM_ARCH("armv7-m", cortexm3,	7M,  FL_CO_PROC |	      FL_FOR_ARCH7M)
 ARM_ARCH("armv7e-m", cortexm4,  7EM, FL_CO_PROC |	      FL_FOR_ARCH7EM)
-ARM_ARCH("armv8-a", cortexa15,  8A,  FL_CO_PROC |             FL_FOR_ARCH8A)
+ARM_ARCH("armv8-a", cortexa53,  8A,  FL_CO_PROC |             FL_FOR_ARCH8A)
 ARM_ARCH("iwmmxt",  iwmmxt,     5TE, FL_LDSCHED | FL_STRONG | FL_FOR_ARCH5TE | FL_XSCALE | FL_IWMMXT)
 ARM_ARCH("iwmmxt2", iwmmxt2,    5TE, FL_LDSCHED | FL_STRONG | FL_FOR_ARCH5TE | FL_XSCALE | FL_IWMMXT | FL_IWMMXT2)
diff --git a/gcc/config/arm/arm-cores.def b/gcc/config/arm/arm-cores.def
index a4cb7c6..3d59fa6 100644
--- a/gcc/config/arm/arm-cores.def
+++ b/gcc/config/arm/arm-cores.def
@@ -129,9 +129,11 @@ ARM_CORE("cortex-a7",	  cortexa7,	7A,				 FL_LDSCHED | FL_THUMB_DIV | FL_ARM_DIV
 ARM_CORE("cortex-a8",	  cortexa8,	7A,				 FL_LDSCHED, cortex)
 ARM_CORE("cortex-a9",	  cortexa9,	7A,				 FL_LDSCHED, cortex_a9)
 ARM_CORE("cortex-a15",	  cortexa15,	7A,				 FL_LDSCHED | FL_THUMB_DIV | FL_ARM_DIV, cortex_a15)
+ARM_CORE("cortex-a53",	  cortexa53,	8A,				 FL_LDSCHED, cortex_a5)
 ARM_CORE("cortex-r4",	  cortexr4,	7R,				 FL_LDSCHED, cortex)
 ARM_CORE("cortex-r4f",	  cortexr4f,	7R,				 FL_LDSCHED, cortex)
 ARM_CORE("cortex-r5",	  cortexr5,	7R,				 FL_LDSCHED | FL_ARM_DIV, cortex)
+ARM_CORE("cortex-r7",	  cortexr7,	7R,				 FL_LDSCHED | FL_ARM_DIV, cortex)
 ARM_CORE("cortex-m4",	  cortexm4,	7EM,				 FL_LDSCHED, cortex)
 ARM_CORE("cortex-m3",	  cortexm3,	7M,				 FL_LDSCHED, cortex)
 ARM_CORE("cortex-m1",	  cortexm1,	6M,				 FL_LDSCHED, v6m)
diff --git a/gcc/config/arm/arm-fixed.md b/gcc/config/arm/arm-fixed.md
index 10da396..12bbbaf 100644
--- a/gcc/config/arm/arm-fixed.md
+++ b/gcc/config/arm/arm-fixed.md
@@ -19,12 +19,13 @@
 ;; This file contains ARM instructions that support fixed-point operations.
 
 (define_insn "add<mode>3"
-  [(set (match_operand:FIXED 0 "s_register_operand" "=r")
-	(plus:FIXED (match_operand:FIXED 1 "s_register_operand" "r")
-		    (match_operand:FIXED 2 "s_register_operand" "r")))]
+  [(set (match_operand:FIXED 0 "s_register_operand" "=l,r")
+	(plus:FIXED (match_operand:FIXED 1 "s_register_operand" "l,r")
+		    (match_operand:FIXED 2 "s_register_operand" "l,r")))]
   "TARGET_32BIT"
   "add%?\\t%0, %1, %2"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "yes,no")])
 
 (define_insn "add<mode>3"
   [(set (match_operand:ADDSUB 0 "s_register_operand" "=r")
@@ -32,7 +33,8 @@
 		     (match_operand:ADDSUB 2 "s_register_operand" "r")))]
   "TARGET_INT_SIMD"
   "sadd<qaddsub_suf>%?\\t%0, %1, %2"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "usadd<mode>3"
   [(set (match_operand:UQADDSUB 0 "s_register_operand" "=r")
@@ -40,7 +42,8 @@
 			  (match_operand:UQADDSUB 2 "s_register_operand" "r")))]
   "TARGET_INT_SIMD"
   "uqadd<qaddsub_suf>%?\\t%0, %1, %2"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "ssadd<mode>3"
   [(set (match_operand:QADDSUB 0 "s_register_operand" "=r")
@@ -48,15 +51,17 @@
 			 (match_operand:QADDSUB 2 "s_register_operand" "r")))]
   "TARGET_INT_SIMD"
   "qadd<qaddsub_suf>%?\\t%0, %1, %2"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "sub<mode>3"
-  [(set (match_operand:FIXED 0 "s_register_operand" "=r")
-	(minus:FIXED (match_operand:FIXED 1 "s_register_operand" "r")
-		     (match_operand:FIXED 2 "s_register_operand" "r")))]
+  [(set (match_operand:FIXED 0 "s_register_operand" "=l,r")
+	(minus:FIXED (match_operand:FIXED 1 "s_register_operand" "l,r")
+		     (match_operand:FIXED 2 "s_register_operand" "l,r")))]
   "TARGET_32BIT"
   "sub%?\\t%0, %1, %2"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "yes,no")])
 
 (define_insn "sub<mode>3"
   [(set (match_operand:ADDSUB 0 "s_register_operand" "=r")
@@ -64,7 +69,8 @@
 		      (match_operand:ADDSUB 2 "s_register_operand" "r")))]
   "TARGET_INT_SIMD"
   "ssub<qaddsub_suf>%?\\t%0, %1, %2"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "ussub<mode>3"
   [(set (match_operand:UQADDSUB 0 "s_register_operand" "=r")
@@ -73,7 +79,8 @@
 	  (match_operand:UQADDSUB 2 "s_register_operand" "r")))]
   "TARGET_INT_SIMD"
   "uqsub<qaddsub_suf>%?\\t%0, %1, %2"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "sssub<mode>3"
   [(set (match_operand:QADDSUB 0 "s_register_operand" "=r")
@@ -81,7 +88,8 @@
 			  (match_operand:QADDSUB 2 "s_register_operand" "r")))]
   "TARGET_INT_SIMD"
   "qsub<qaddsub_suf>%?\\t%0, %1, %2"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 ;; Fractional multiplies.
 
@@ -374,6 +382,7 @@
   "TARGET_32BIT && arm_arch6"
   "ssat%?\\t%0, #16, %2%S1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "insn" "sat")
    (set_attr "shift" "1")
    (set_attr "type" "alu_shift")])
@@ -384,4 +393,5 @@
   "TARGET_INT_SIMD"
   "usat%?\\t%0, #16, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "insn" "sat")])
diff --git a/gcc/config/arm/arm-generic.md b/gcc/config/arm/arm-generic.md
index 9705f75..8a33350 100644
--- a/gcc/config/arm/arm-generic.md
+++ b/gcc/config/arm/arm-generic.md
@@ -114,7 +114,9 @@
 
 (define_insn_reservation "mult" 16
   (and (eq_attr "generic_sched" "yes")
-       (and (eq_attr "ldsched" "no") (eq_attr "type" "mult")))
+       (and (eq_attr "ldsched" "no")
+	    (ior (eq_attr "mul32" "yes")
+		 (eq_attr "mul64" "yes"))))
   "core*16")
 
 (define_insn_reservation "mult_ldsched_strongarm" 3
@@ -122,7 +124,8 @@
        (and (eq_attr "ldsched" "yes") 
 	    (and (eq_attr "tune"
 		  "strongarm,strongarm110,strongarm1100,strongarm1110")
-	         (eq_attr "type" "mult"))))
+		 (ior (eq_attr "mul32" "yes")
+		      (eq_attr "mul64" "yes")))))
   "core*2")
 
 (define_insn_reservation "mult_ldsched" 4
@@ -130,13 +133,17 @@
        (and (eq_attr "ldsched" "yes") 
 	    (and (eq_attr "tune"
 		  "!strongarm,strongarm110,strongarm1100,strongarm1110")
-	         (eq_attr "type" "mult"))))
+	         (ior (eq_attr "mul32" "yes")
+		      (eq_attr "mul64" "yes")))))
   "core*4")
 
 (define_insn_reservation "multi_cycle" 32
   (and (eq_attr "generic_sched" "yes")
        (and (eq_attr "core_cycles" "multi")
-            (eq_attr "type" "!mult,load_byte,load1,load2,load3,load4,store1,store2,store3,store4")))
+            (and (eq_attr "type" "!load_byte,load1,load2,load3,load4,\
+                                  store1,store2,store3,store4")
+		 (not (ior (eq_attr "mul32" "yes")
+			   (eq_attr "mul64" "yes"))))))
   "core*32")
 
 (define_insn_reservation "single_cycle" 1
diff --git a/gcc/config/arm/arm-ldmstm.ml b/gcc/config/arm/arm-ldmstm.ml
index 2bc9702..e615437 100644
--- a/gcc/config/arm/arm-ldmstm.ml
+++ b/gcc/config/arm/arm-ldmstm.ml
@@ -146,12 +146,15 @@ let can_thumb addrmode update is_store =
   | IA, true, true -> true
   | _ -> false
 
+exception InvalidAddrMode of string;;
+
 let target addrmode thumb =
   match addrmode, thumb with
     IA, true -> "TARGET_THUMB1"
   | IA, false -> "TARGET_32BIT"
   | DB, false -> "TARGET_32BIT"
   | _, false -> "TARGET_ARM"
+  | _, _ -> raise (InvalidAddrMode "ERROR: Invalid Addressing mode for Thumb1.")
 
 let write_pattern_1 name ls addrmode nregs write_set_fn update thumb =
   let astr = string_of_addrmode addrmode in
@@ -181,8 +184,10 @@ let write_pattern_1 name ls addrmode nregs write_set_fn update thumb =
   done;
   Printf.printf "}\"\n";
   Printf.printf "  [(set_attr \"type\" \"%s%d\")" ls nregs;
-  begin if not thumb then
+  if not thumb then begin
     Printf.printf "\n   (set_attr \"predicable\" \"yes\")";
+    if addrmode == IA || addrmode == DB then
+      Printf.printf "\n   (set_attr \"predicable_short_it\" \"no\")";
   end;
   Printf.printf "])\n\n"
 
diff --git a/gcc/config/arm/arm-protos.h b/gcc/config/arm/arm-protos.h
index ffa00c0..ef94bbc 100644
--- a/gcc/config/arm/arm-protos.h
+++ b/gcc/config/arm/arm-protos.h
@@ -24,12 +24,13 @@
 
 extern enum unwind_info_type arm_except_unwind_info (struct gcc_options *);
 extern int use_return_insn (int, rtx);
+extern bool use_simple_return_p (void);
 extern enum reg_class arm_regno_class (int);
 extern void arm_load_pic_register (unsigned long);
 extern int arm_volatile_func (void);
 extern void arm_expand_prologue (void);
 extern void arm_expand_epilogue (bool);
-extern void thumb2_expand_return (void);
+extern void thumb2_expand_return (bool);
 extern const char *arm_strip_name_encoding (const char *);
 extern void arm_asm_output_labelref (FILE *, const char *);
 extern void thumb2_asm_output_opcode (FILE *);
@@ -78,6 +79,7 @@ extern char *neon_output_shift_immediate (const char *, char, rtx *,
 extern void neon_pairwise_reduce (rtx, rtx, enum machine_mode,
 				  rtx (*) (rtx, rtx, rtx));
 extern rtx neon_make_constant (rtx);
+extern tree arm_builtin_vectorized_function (tree, tree, tree);
 extern void neon_expand_vector_init (rtx, rtx);
 extern void neon_lane_bounds (rtx, HOST_WIDE_INT, HOST_WIDE_INT);
 extern void neon_const_bounds (rtx, HOST_WIDE_INT, HOST_WIDE_INT);
@@ -93,7 +95,7 @@ extern enum reg_class coproc_secondary_reload_class (enum machine_mode, rtx,
 extern bool arm_tls_referenced_p (rtx);
 
 extern int arm_coproc_mem_operand (rtx, bool);
-extern int neon_vector_mem_operand (rtx, int);
+extern int neon_vector_mem_operand (rtx, int, bool);
 extern int neon_struct_mem_operand (rtx);
 extern int arm_no_early_store_addr_dep (rtx, rtx);
 extern int arm_early_store_addr_dep (rtx, rtx);
@@ -117,7 +119,9 @@ extern rtx arm_gen_load_multiple (int *, int, rtx, int, rtx, HOST_WIDE_INT *);
 extern rtx arm_gen_store_multiple (int *, int, rtx, int, rtx, HOST_WIDE_INT *);
 extern bool offset_ok_for_ldrd_strd (HOST_WIDE_INT);
 extern bool operands_ok_ldrd_strd (rtx, rtx, rtx, HOST_WIDE_INT, bool, bool);
+extern bool gen_operands_ldrd_strd (rtx *, bool, bool, bool);
 extern int arm_gen_movmemqi (rtx *);
+extern bool gen_movmem_ldrd_strd (rtx *);
 extern enum machine_mode arm_select_cc_mode (RTX_CODE, rtx, rtx);
 extern enum machine_mode arm_select_dominance_cc_mode (rtx, rtx,
 						       HOST_WIDE_INT);
@@ -224,6 +228,8 @@ extern const char *arm_mangle_type (const_tree);
 
 extern void arm_order_regs_for_local_alloc (void);
 
+extern int arm_max_conditional_execute ();
+
 /* Vectorizer cost model implementation.  */
 struct cpu_vec_costs {
   const int scalar_stmt_cost;   /* Cost of any scalar operation, excluding
@@ -253,8 +259,7 @@ struct tune_params
   bool (*rtx_costs) (rtx, RTX_CODE, RTX_CODE, int *, bool);
   bool (*sched_adjust_cost) (rtx, rtx, rtx, int *);
   int constant_limit;
-  /* Maximum number of instructions to conditionalise in
-     arm_final_prescan_insn.  */
+  /* Maximum number of instructions to conditionalise.  */
   int max_insns_skipped;
   int num_prefetch_slots;
   int l1_cache_size;
@@ -269,6 +274,8 @@ struct tune_params
   bool logical_op_non_short_circuit[2];
   /* Vectorizer costs.  */
   const struct cpu_vec_costs* vec_costs;
+  /* Prefer Neon for 64-bit bitops.  */
+  bool prefer_neon_for_64bits;
 };
 
 extern const struct tune_params *current_tune;
diff --git a/gcc/config/arm/arm-tables.opt b/gcc/config/arm/arm-tables.opt
index 06a529d..bf20695 100644
--- a/gcc/config/arm/arm-tables.opt
+++ b/gcc/config/arm/arm-tables.opt
@@ -250,6 +250,9 @@ EnumValue
 Enum(processor_type) String(cortex-a15) Value(cortexa15)
 
 EnumValue
+Enum(processor_type) String(cortex-a53) Value(cortexa53)
+
+EnumValue
 Enum(processor_type) String(cortex-r4) Value(cortexr4)
 
 EnumValue
@@ -259,6 +262,9 @@ EnumValue
 Enum(processor_type) String(cortex-r5) Value(cortexr5)
 
 EnumValue
+Enum(processor_type) String(cortex-r7) Value(cortexr7)
+
+EnumValue
 Enum(processor_type) String(cortex-m4) Value(cortexm4)
 
 EnumValue
diff --git a/gcc/config/arm/arm-tune.md b/gcc/config/arm/arm-tune.md
index 26c2e1f..e4da098 100644
--- a/gcc/config/arm/arm-tune.md
+++ b/gcc/config/arm/arm-tune.md
@@ -1,5 +1,5 @@
 ;; -*- buffer-read-only: t -*-
 ;; Generated automatically by gentune.sh from arm-cores.def
 (define_attr "tune"
-	"arm2,arm250,arm3,arm6,arm60,arm600,arm610,arm620,arm7,arm7d,arm7di,arm70,arm700,arm700i,arm710,arm720,arm710c,arm7100,arm7500,arm7500fe,arm7m,arm7dm,arm7dmi,arm8,arm810,strongarm,strongarm110,strongarm1100,strongarm1110,fa526,fa626,arm7tdmi,arm7tdmis,arm710t,arm720t,arm740t,arm9,arm9tdmi,arm920,arm920t,arm922t,arm940t,ep9312,arm10tdmi,arm1020t,arm9e,arm946es,arm966es,arm968es,arm10e,arm1020e,arm1022e,xscale,iwmmxt,iwmmxt2,fa606te,fa626te,fmp626,fa726te,arm926ejs,arm1026ejs,arm1136js,arm1136jfs,arm1176jzs,arm1176jzfs,mpcorenovfp,mpcore,arm1156t2s,arm1156t2fs,genericv7a,cortexa5,cortexa7,cortexa8,cortexa9,cortexa15,cortexr4,cortexr4f,cortexr5,cortexm4,cortexm3,cortexm1,cortexm0,cortexm0plus,marvell_pj4"
+	"arm2,arm250,arm3,arm6,arm60,arm600,arm610,arm620,arm7,arm7d,arm7di,arm70,arm700,arm700i,arm710,arm720,arm710c,arm7100,arm7500,arm7500fe,arm7m,arm7dm,arm7dmi,arm8,arm810,strongarm,strongarm110,strongarm1100,strongarm1110,fa526,fa626,arm7tdmi,arm7tdmis,arm710t,arm720t,arm740t,arm9,arm9tdmi,arm920,arm920t,arm922t,arm940t,ep9312,arm10tdmi,arm1020t,arm9e,arm946es,arm966es,arm968es,arm10e,arm1020e,arm1022e,xscale,iwmmxt,iwmmxt2,fa606te,fa626te,fmp626,fa726te,arm926ejs,arm1026ejs,arm1136js,arm1136jfs,arm1176jzs,arm1176jzfs,mpcorenovfp,mpcore,arm1156t2s,arm1156t2fs,genericv7a,cortexa5,cortexa7,cortexa8,cortexa9,cortexa15,cortexa53,cortexr4,cortexr4f,cortexr5,cortexr7,cortexm4,cortexm3,cortexm1,cortexm0,cortexm0plus,marvell_pj4"
 	(const (symbol_ref "((enum attr_tune) arm_tune)")))
diff --git a/gcc/config/arm/arm.c b/gcc/config/arm/arm.c
index edf850d..bd39cc9 100644
--- a/gcc/config/arm/arm.c
+++ b/gcc/config/arm/arm.c
@@ -23,6 +23,7 @@
 #include "config.h"
 #include "system.h"
 #include "coretypes.h"
+#include "hash-table.h"
 #include "tm.h"
 #include "rtl.h"
 #include "tree.h"
@@ -173,6 +174,7 @@ static rtx arm_expand_builtin (tree, rtx, rtx, enum machine_mode, int);
 static tree arm_builtin_decl (unsigned, bool);
 static void emit_constant_insn (rtx cond, rtx pattern);
 static rtx emit_set_insn (rtx, rtx);
+static rtx emit_multi_reg_push (unsigned long);
 static int arm_arg_partial_bytes (cumulative_args_t, enum machine_mode,
 				  tree, bool);
 static rtx arm_function_arg (cumulative_args_t, enum machine_mode,
@@ -280,6 +282,7 @@ static unsigned arm_add_stmt_cost (void *data, int count,
 
 static void arm_canonicalize_comparison (int *code, rtx *op0, rtx *op1,
 					 bool op0_preserve_value);
+static unsigned HOST_WIDE_INT arm_asan_shadow_offset (void);
 
 /* Table of machine attributes.  */
 static const struct attribute_spec arm_attribute_table[] =
@@ -620,6 +623,13 @@ static const struct attribute_spec arm_attribute_table[] =
 #undef TARGET_CLASS_LIKELY_SPILLED_P
 #define TARGET_CLASS_LIKELY_SPILLED_P arm_class_likely_spilled_p
 
+#undef TARGET_VECTORIZE_BUILTINS
+#define TARGET_VECTORIZE_BUILTINS
+
+#undef TARGET_VECTORIZE_BUILTIN_VECTORIZED_FUNCTION
+#define TARGET_VECTORIZE_BUILTIN_VECTORIZED_FUNCTION \
+  arm_builtin_vectorized_function
+
 #undef TARGET_VECTOR_ALIGNMENT
 #define TARGET_VECTOR_ALIGNMENT arm_vector_alignment
 
@@ -649,6 +659,13 @@ static const struct attribute_spec arm_attribute_table[] =
 #define TARGET_CANONICALIZE_COMPARISON \
   arm_canonicalize_comparison
 
+#undef TARGET_ASAN_SHADOW_OFFSET
+#define TARGET_ASAN_SHADOW_OFFSET arm_asan_shadow_offset
+
+#undef MAX_INSN_PER_IT_BLOCK
+#define MAX_INSN_PER_IT_BLOCK (arm_restrict_it ? 1 : 4)
+
+
 struct gcc_target targetm = TARGET_INITIALIZER;
 
 /* Obstack for minipool constant handling.  */
@@ -839,6 +856,10 @@ int arm_arch_thumb2;
 int arm_arch_arm_hwdiv;
 int arm_arch_thumb_hwdiv;
 
+/* Nonzero if we should use Neon to handle 64-bits operations rather
+   than core registers.  */
+int prefer_neon_for_64bits = 0;
+
 /* In case of a PRE_INC, POST_INC, PRE_DEC, POST_DEC memory reference,
    we must report the mode of the memory reference from
    TARGET_PRINT_OPERAND to TARGET_PRINT_OPERAND_ADDRESS.  */
@@ -936,6 +957,7 @@ const struct tune_params arm_slowmul_tune =
   false,					/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 const struct tune_params arm_fastmul_tune =
@@ -950,6 +972,7 @@ const struct tune_params arm_fastmul_tune =
   false,					/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 /* StrongARM has early execution of branches, so a sequence that is worth
@@ -967,6 +990,7 @@ const struct tune_params arm_strongarm_tune =
   false,					/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 const struct tune_params arm_xscale_tune =
@@ -981,6 +1005,7 @@ const struct tune_params arm_xscale_tune =
   false,					/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 const struct tune_params arm_9e_tune =
@@ -995,6 +1020,7 @@ const struct tune_params arm_9e_tune =
   false,					/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 const struct tune_params arm_v6t2_tune =
@@ -1009,6 +1035,7 @@ const struct tune_params arm_v6t2_tune =
   false,					/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 /* Generic Cortex tuning.  Use more specific tunings if appropriate.  */
@@ -1024,6 +1051,7 @@ const struct tune_params arm_cortex_tune =
   false,					/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 const struct tune_params arm_cortex_a15_tune =
@@ -1031,13 +1059,14 @@ const struct tune_params arm_cortex_a15_tune =
   arm_9e_rtx_costs,
   NULL,
   1,						/* Constant limit.  */
-  5,						/* Max cond insns.  */
+  2,						/* Max cond insns.  */
   ARM_PREFETCH_NOT_BENEFICIAL,
   false,					/* Prefer constant pool.  */
   arm_default_branch_cost,
   true,						/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 /* Branches can be dual-issued on Cortex-A5, so conditional execution is
@@ -1055,6 +1084,7 @@ const struct tune_params arm_cortex_a5_tune =
   false,					/* Prefer LDRD/STRD.  */
   {false, false},				/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 const struct tune_params arm_cortex_a9_tune =
@@ -1069,6 +1099,7 @@ const struct tune_params arm_cortex_a9_tune =
   false,					/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 /* The arm_v6m_tune is duplicated from arm_cortex_tune, rather than
@@ -1085,6 +1116,7 @@ const struct tune_params arm_v6m_tune =
   false,					/* Prefer LDRD/STRD.  */
   {false, false},				/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 const struct tune_params arm_fa726te_tune =
@@ -1099,6 +1131,7 @@ const struct tune_params arm_fa726te_tune =
   false,					/* Prefer LDRD/STRD.  */
   {true, true},					/* Prefer non short circuit.  */
   &arm_default_vec_cost,                        /* Vectorizer costs.  */
+  false                                         /* Prefer Neon for 64-bits bitops.  */
 };
 
 
@@ -1842,6 +1875,11 @@ arm_option_override (void)
   arm_arch_thumb_hwdiv = (insn_flags & FL_THUMB_DIV) != 0;
   arm_arch_arm_hwdiv = (insn_flags & FL_ARM_DIV) != 0;
   arm_tune_cortex_a9 = (arm_tune == cortexa9) != 0;
+  if (arm_restrict_it == 2)
+    arm_restrict_it = arm_arch8 && TARGET_THUMB2;
+
+  if (!TARGET_THUMB2)
+    arm_restrict_it = 0;
 
   /* If we are not using the default (ARM mode) section anchor offset
      ranges, then set the correct ranges now.  */
@@ -2129,11 +2167,25 @@ arm_option_override (void)
                            global_options.x_param_values,
                            global_options_set.x_param_values);
 
+  /* Use Neon to perform 64-bits operations rather than core
+     registers.  */
+  prefer_neon_for_64bits = current_tune->prefer_neon_for_64bits;
+  if (use_neon_for_64bits == 1)
+     prefer_neon_for_64bits = true;
+
   /* Use the alternative scheduling-pressure algorithm by default.  */
   maybe_set_param_value (PARAM_SCHED_PRESSURE_ALGORITHM, 2,
                          global_options.x_param_values,
                          global_options_set.x_param_values);
 
+  /* Disable shrink-wrap when optimizing function for size, since it tends to
+     generate additional returns.  */
+  if (optimize_function_for_size_p (cfun) && TARGET_THUMB2)
+    flag_shrink_wrap = false;
+  /* TBD: Dwarf info for apcs frame is not handled yet.  */
+  if (TARGET_APCS_FRAME)
+    flag_shrink_wrap = false;
+
   /* Register global variables with the garbage collector.  */
   arm_add_gc_roots ();
 }
@@ -2382,6 +2434,10 @@ use_return_insn (int iscond, rtx sibling)
   if (IS_INTERRUPT (func_type) && (frame_pointer_needed || TARGET_THUMB))
     return 0;
 
+  if (TARGET_LDRD && current_tune->prefer_ldrd_strd
+      && !optimize_function_for_size_p (cfun))
+    return 0;
+
   offsets = arm_get_frame_offsets ();
   stack_adjust = offsets->outgoing_args - offsets->saved_regs;
 
@@ -2479,6 +2535,18 @@ use_return_insn (int iscond, rtx sibling)
   return 1;
 }
 
+/* Return TRUE if we should try to use a simple_return insn, i.e. perform
+   shrink-wrapping if possible.  This is the case if we need to emit a
+   prologue, which we can test by looking at the offsets.  */
+bool
+use_simple_return_p (void)
+{
+  arm_stack_offsets *offsets;
+
+  offsets = arm_get_frame_offsets ();
+  return offsets->outgoing_args != 0;
+}
+
 /* Return TRUE if int I is a valid immediate ARM constant.  */
 
 int
@@ -2617,6 +2685,11 @@ const_ok_for_dimode_op (HOST_WIDE_INT i, enum rtx_code code)
 
   switch (code)
     {
+    case AND:
+    case IOR:
+    case XOR:
+      return (const_ok_for_op (hi_val, code) || hi_val == 0xFFFFFFFF)
+              && (const_ok_for_op (lo_val, code) || lo_val == 0xFFFFFFFF);
     case PLUS:
       return arm_not_operand (hi, SImode) && arm_add_operand (lo, SImode);
 
@@ -3775,36 +3848,48 @@ arm_function_value(const_tree type, const_tree func,
   return arm_libcall_value_1 (mode);
 }
 
-static int
-libcall_eq (const void *p1, const void *p2)
+/* libcall hashtable helpers.  */
+
+struct libcall_hasher : typed_noop_remove <rtx_def>
 {
-  return rtx_equal_p ((const_rtx) p1, (const_rtx) p2);
+  typedef rtx_def value_type;
+  typedef rtx_def compare_type;
+  static inline hashval_t hash (const value_type *);
+  static inline bool equal (const value_type *, const compare_type *);
+  static inline void remove (value_type *);
+};
+
+inline bool
+libcall_hasher::equal (const value_type *p1, const compare_type *p2)
+{
+  return rtx_equal_p (p1, p2);
 }
 
-static hashval_t
-libcall_hash (const void *p1)
+inline hashval_t
+libcall_hasher::hash (const value_type *p1)
 {
-  return hash_rtx ((const_rtx) p1, VOIDmode, NULL, NULL, FALSE);
+  return hash_rtx (p1, VOIDmode, NULL, NULL, FALSE);
 }
 
+typedef hash_table <libcall_hasher> libcall_table_type;
+
 static void
-add_libcall (htab_t htab, rtx libcall)
+add_libcall (libcall_table_type htab, rtx libcall)
 {
-  *htab_find_slot (htab, libcall, INSERT) = libcall;
+  *htab.find_slot (libcall, INSERT) = libcall;
 }
 
 static bool
 arm_libcall_uses_aapcs_base (const_rtx libcall)
 {
   static bool init_done = false;
-  static htab_t libcall_htab;
+  static libcall_table_type libcall_htab;
 
   if (!init_done)
     {
       init_done = true;
 
-      libcall_htab = htab_create (31, libcall_hash, libcall_eq,
-				  NULL);
+      libcall_htab.create (31);
       add_libcall (libcall_htab,
 		   convert_optab_libfunc (sfloat_optab, SFmode, SImode));
       add_libcall (libcall_htab,
@@ -3863,7 +3948,7 @@ arm_libcall_uses_aapcs_base (const_rtx libcall)
 							DFmode));
     }
 
-  return libcall && htab_find (libcall_htab, libcall) != NULL;
+  return libcall && libcall_htab.find (libcall) != NULL;
 }
 
 static rtx
@@ -5335,9 +5420,8 @@ arm_function_ok_for_sibcall (tree decl, tree exp)
   if (cfun->machine->sibcall_blocked)
     return false;
 
-  /* Never tailcall something for which we have no decl, or if we
-     are generating code for Thumb-1.  */
-  if (decl == NULL || TARGET_THUMB1)
+  /* Never tailcall something if we are generating code for Thumb-1.  */
+  if (TARGET_THUMB1)
     return false;
 
   /* The PIC register is live on entry to VxWorks PLT entries, so we
@@ -5347,13 +5431,14 @@ arm_function_ok_for_sibcall (tree decl, tree exp)
 
   /* Cannot tail-call to long calls, since these are out of range of
      a branch instruction.  */
-  if (arm_is_long_call_p (decl))
+  if (decl && arm_is_long_call_p (decl))
     return false;
 
   /* If we are interworking and the function is not declared static
      then we can't tail-call it unless we know that it exists in this
      compilation unit (since it might be a Thumb routine).  */
-  if (TARGET_INTERWORK && TREE_PUBLIC (decl) && !TREE_ASM_WRITTEN (decl))
+  if (TARGET_INTERWORK && decl && TREE_PUBLIC (decl)
+      && !TREE_ASM_WRITTEN (decl))
     return false;
 
   func_type = arm_current_func_type ();
@@ -5385,6 +5470,7 @@ arm_function_ok_for_sibcall (tree decl, tree exp)
      sibling calls.  */
   if (TARGET_AAPCS_BASED
       && arm_abi == ARM_ABI_AAPCS
+      && decl
       && DECL_WEAK (decl))
     return false;
 
@@ -6355,7 +6441,8 @@ arm_preferred_reload_class (rtx x ATTRIBUTE_UNUSED, reg_class_t rclass)
       if (rclass == GENERAL_REGS
 	  || rclass == HI_REGS
 	  || rclass == NO_REGS
-	  || rclass == STACK_REG)
+	  || rclass == STACK_REG
+	  || rclass == CORE_REGS)
 	return LO_REGS;
       else
 	return rclass;
@@ -7777,7 +7864,7 @@ arm_rtx_costs_1 (rtx x, enum rtx_code outer, int* total, bool speed)
 	  && GET_CODE (SET_SRC (x)) == VEC_SELECT)
 	{
 	  *total = rtx_cost (SET_DEST (x), code, 0, speed);
-	  if (!neon_vector_mem_operand (SET_DEST (x), 2))
+	  if (!neon_vector_mem_operand (SET_DEST (x), 2, true))
 	    *total += COSTS_N_INSNS (1);
 	  return true;
 	}
@@ -7788,7 +7875,7 @@ arm_rtx_costs_1 (rtx x, enum rtx_code outer, int* total, bool speed)
 	{
 	  rtx mem = XEXP (XEXP (SET_SRC (x), 0), 0);
 	  *total = rtx_cost (mem, code, 0, speed);
-	  if (!neon_vector_mem_operand (mem, 2))
+	  if (!neon_vector_mem_operand (mem, 2, true))
 	    *total += COSTS_N_INSNS (1);
 	  return true;
 	}
@@ -9059,6 +9146,12 @@ arm_adjust_cost (rtx insn, rtx link, rtx dep, int cost)
   return cost;
 }
 
+int
+arm_max_conditional_execute (void)
+{
+  return max_insns_skipped;
+}
+
 static int
 arm_default_branch_cost (bool speed_p, bool predictable_p ATTRIBUTE_UNUSED)
 {
@@ -9960,7 +10053,7 @@ arm_coproc_mem_operand (rtx op, bool wb)
     2 - Element/structure loads (vld1)
  */
 int
-neon_vector_mem_operand (rtx op, int type)
+neon_vector_mem_operand (rtx op, int type, bool strict)
 {
   rtx ind;
 
@@ -9972,7 +10065,7 @@ neon_vector_mem_operand (rtx op, int type)
 	  || reg_mentioned_p (virtual_outgoing_args_rtx, op)
 	  || reg_mentioned_p (virtual_stack_dynamic_rtx, op)
 	  || reg_mentioned_p (virtual_stack_vars_rtx, op)))
-    return FALSE;
+    return !strict;
 
   /* Constants are converted into offsets from labels.  */
   if (!MEM_P (op))
@@ -10082,7 +10175,7 @@ coproc_secondary_reload_class (enum machine_mode mode, rtx x, bool wb)
     {
       if (!TARGET_NEON_FP16)
 	return GENERAL_REGS;
-      if (s_register_operand (x, mode) || neon_vector_mem_operand (x, 2))
+      if (s_register_operand (x, mode) || neon_vector_mem_operand (x, 2, true))
 	return NO_REGS;
       return GENERAL_REGS;
     }
@@ -10454,7 +10547,7 @@ ldm_stm_operation_p (rtx op, bool load, enum machine_mode mode,
 
   /* Don't allow SP to be loaded unless it is also the base register. It
      guarantees that SP is reset correctly when an LDM instruction
-     is interruptted. Otherwise, we might end up with a corrupt stack.  */
+     is interrupted. Otherwise, we might end up with a corrupt stack.  */
   if (load && (REGNO (reg) == SP_REGNUM) && (REGNO (addr) != SP_REGNUM))
     return false;
 
@@ -11814,6 +11907,134 @@ arm_gen_movmemqi (rtx *operands)
   return 1;
 }
 
+/* Helper for gen_movmem_ldrd_strd. Increase the address of memory rtx
+by mode size.  */
+inline static rtx
+next_consecutive_mem (rtx mem)
+{
+  enum machine_mode mode = GET_MODE (mem);
+  HOST_WIDE_INT offset = GET_MODE_SIZE (mode);
+  rtx addr = plus_constant (Pmode, XEXP (mem, 0), offset);
+
+  return adjust_automodify_address (mem, mode, addr, offset);
+}
+
+/* Copy using LDRD/STRD instructions whenever possible.
+   Returns true upon success. */
+bool
+gen_movmem_ldrd_strd (rtx *operands)
+{
+  unsigned HOST_WIDE_INT len;
+  HOST_WIDE_INT align;
+  rtx src, dst, base;
+  rtx reg0;
+  bool src_aligned, dst_aligned;
+  bool src_volatile, dst_volatile;
+
+  gcc_assert (CONST_INT_P (operands[2]));
+  gcc_assert (CONST_INT_P (operands[3]));
+
+  len = UINTVAL (operands[2]);
+  if (len > 64)
+    return false;
+
+  /* Maximum alignment we can assume for both src and dst buffers.  */
+  align = INTVAL (operands[3]);
+
+  if ((!unaligned_access) && (len >= 4) && ((align & 3) != 0))
+    return false;
+
+  /* Place src and dst addresses in registers
+     and update the corresponding mem rtx.  */
+  dst = operands[0];
+  dst_volatile = MEM_VOLATILE_P (dst);
+  dst_aligned = MEM_ALIGN (dst) >= BITS_PER_WORD;
+  base = copy_to_mode_reg (SImode, XEXP (dst, 0));
+  dst = adjust_automodify_address (dst, VOIDmode, base, 0);
+
+  src = operands[1];
+  src_volatile = MEM_VOLATILE_P (src);
+  src_aligned = MEM_ALIGN (src) >= BITS_PER_WORD;
+  base = copy_to_mode_reg (SImode, XEXP (src, 0));
+  src = adjust_automodify_address (src, VOIDmode, base, 0);
+
+  if (!unaligned_access && !(src_aligned && dst_aligned))
+    return false;
+
+  if (src_volatile || dst_volatile)
+    return false;
+
+  /* If we cannot generate any LDRD/STRD, try to generate LDM/STM.  */
+  if (!(dst_aligned || src_aligned))
+    return arm_gen_movmemqi (operands);
+
+  src = adjust_address (src, DImode, 0);
+  dst = adjust_address (dst, DImode, 0);
+  while (len >= 8)
+    {
+      len -= 8;
+      reg0 = gen_reg_rtx (DImode);
+      if (src_aligned)
+        emit_move_insn (reg0, src);
+      else
+        emit_insn (gen_unaligned_loaddi (reg0, src));
+
+      if (dst_aligned)
+        emit_move_insn (dst, reg0);
+      else
+        emit_insn (gen_unaligned_storedi (dst, reg0));
+
+      src = next_consecutive_mem (src);
+      dst = next_consecutive_mem (dst);
+    }
+
+  gcc_assert (len < 8);
+  if (len >= 4)
+    {
+      /* More than a word but less than a double-word to copy.  Copy a word.  */
+      reg0 = gen_reg_rtx (SImode);
+      src = adjust_address (src, SImode, 0);
+      dst = adjust_address (dst, SImode, 0);
+      if (src_aligned)
+        emit_move_insn (reg0, src);
+      else
+        emit_insn (gen_unaligned_loadsi (reg0, src));
+
+      if (dst_aligned)
+        emit_move_insn (dst, reg0);
+      else
+        emit_insn (gen_unaligned_storesi (dst, reg0));
+
+      src = next_consecutive_mem (src);
+      dst = next_consecutive_mem (dst);
+      len -= 4;
+    }
+
+  if (len == 0)
+    return true;
+
+  /* Copy the remaining bytes.  */
+  if (len >= 2)
+    {
+      dst = adjust_address (dst, HImode, 0);
+      src = adjust_address (src, HImode, 0);
+      reg0 = gen_reg_rtx (SImode);
+      emit_insn (gen_unaligned_loadhiu (reg0, src));
+      emit_insn (gen_unaligned_storehi (dst, gen_lowpart (HImode, reg0)));
+      src = next_consecutive_mem (src);
+      dst = next_consecutive_mem (dst);
+      if (len == 2)
+        return true;
+    }
+
+  dst = adjust_address (dst, QImode, 0);
+  src = adjust_address (src, QImode, 0);
+  reg0 = gen_reg_rtx (QImode);
+  emit_move_insn (reg0, src);
+  emit_move_insn (dst, reg0);
+  return true;
+}
+
 /* Select a dominance comparison mode if possible for a test of the general
    form (OP (COND_OR (X) (Y)) (const_int 0)).  We support three forms.
    COND_OR == DOM_CC_X_AND_Y => (X && Y)
@@ -12614,6 +12835,277 @@ operands_ok_ldrd_strd (rtx rt, rtx rt2, rtx rn, HOST_WIDE_INT offset,
   return true;
 }
 
+/* Helper for gen_operands_ldrd_strd.  Returns true iff the memory
+   operand ADDR is an immediate offset from the base register and is
+   not volatile, in which case it sets BASE and OFFSET
+   accordingly.  */
+bool
+mem_ok_for_ldrd_strd (rtx addr, rtx *base, rtx *offset)
+{
+  /* TODO: Handle more general memory operand patterns, such as
+     PRE_DEC and PRE_INC.  */
+
+  /* Convert a subreg of mem into mem itself.  */
+  if (GET_CODE (addr) == SUBREG)
+    addr = alter_subreg (&addr, true);
+
+  gcc_assert (MEM_P (addr));
+
+  /* Don't modify volatile memory accesses.  */
+  if (MEM_VOLATILE_P (addr))
+    return false;
+
+  *offset = const0_rtx;
+
+  addr = XEXP (addr, 0);
+  if (REG_P (addr))
+    {
+      *base = addr;
+      return true;
+    }
+  else if (GET_CODE (addr) == PLUS || GET_CODE (addr) == MINUS)
+    {
+      *base = XEXP (addr, 0);
+      *offset = XEXP (addr, 1);
+      return (REG_P (*base) && CONST_INT_P (*offset));
+    }
+
+  return false;
+}
+
+#define SWAP_RTX(x,y) do { rtx tmp = x; x = y; y = tmp; } while (0)
+
+/* Called from a peephole2 to replace two word-size accesses with a
+   single LDRD/STRD instruction.  Returns true iff we can generate a
+   new instruction sequence.  That is, both accesses use the same base
+   register and the gap between constant offsets is 4.  This function
+   may reorder its operands to match ldrd/strd RTL templates.
+   OPERANDS are the operands found by the peephole matcher;
+   OPERANDS[0,1] are register operands, and OPERANDS[2,3] are the
+   corresponding memory operands.  LOAD indicaates whether the access
+   is load or store.  CONST_STORE indicates a store of constant
+   integer values held in OPERANDS[4,5] and assumes that the pattern
+   is of length 4 insn, for the purpose of checking dead registers.
+   COMMUTE indicates that register operands may be reordered.  */
+bool
+gen_operands_ldrd_strd (rtx *operands, bool load,
+                        bool const_store, bool commute)
+{
+  int nops = 2;
+  HOST_WIDE_INT offsets[2], offset;
+  rtx base = NULL_RTX;
+  rtx cur_base, cur_offset, tmp;
+  int i, gap;
+  HARD_REG_SET regset;
+
+  gcc_assert (!const_store || !load);
+  /* Check that the memory references are immediate offsets from the
+     same base register.  Extract the base register, the destination
+     registers, and the corresponding memory offsets.  */
+  for (i = 0; i < nops; i++)
+    {
+      if (!mem_ok_for_ldrd_strd (operands[nops+i], &cur_base, &cur_offset))
+        return false;
+
+      if (i == 0)
+        base = cur_base;
+      else if (REGNO (base) != REGNO (cur_base))
+        return false;
+
+      offsets[i] = INTVAL (cur_offset);
+      if (GET_CODE (operands[i]) == SUBREG)
+        {
+          tmp = SUBREG_REG (operands[i]);
+          gcc_assert (GET_MODE (operands[i]) == GET_MODE (tmp));
+          operands[i] = tmp;
+        }
+    }
+
+  /* Make sure there is no dependency between the individual loads.  */
+  if (load && REGNO (operands[0]) == REGNO (base))
+    return false; /* RAW */
+
+  if (load && REGNO (operands[0]) == REGNO (operands[1]))
+    return false; /* WAW */
+
+  /* If the same input register is used in both stores
+     when storing different constants, try to find a free register.
+     For example, the code
+        mov r0, 0
+        str r0, [r2]
+        mov r0, 1
+        str r0, [r2, #4]
+     can be transformed into
+        mov r1, 0
+        strd r1, r0, [r2]
+     in Thumb mode assuming that r1 is free.  */
+  if (const_store
+      && REGNO (operands[0]) == REGNO (operands[1])
+      && INTVAL (operands[4]) != INTVAL (operands[5]))
+    {
+    if (TARGET_THUMB2)
+      {
+        CLEAR_HARD_REG_SET (regset);
+        tmp = peep2_find_free_register (0, 4, "r", SImode, &regset);
+        if (tmp == NULL_RTX)
+          return false;
+
+        /* Use the new register in the first load to ensure that
+           if the original input register is not dead after peephole,
+           then it will have the correct constant value.  */
+        operands[0] = tmp;
+      }
+    else if (TARGET_ARM)
+      {
+        return false;
+        int regno = REGNO (operands[0]);
+        if (!peep2_reg_dead_p (4, operands[0]))
+          {
+            /* When the input register is even and is not dead after the
+               pattern, it has to hold the second constant but we cannot
+               form a legal STRD in ARM mode with this register as the second
+               register.  */
+            if (regno % 2 == 0)
+              return false;
+
+            /* Is regno-1 free? */
+            SET_HARD_REG_SET (regset);
+            CLEAR_HARD_REG_BIT(regset, regno - 1);
+            tmp = peep2_find_free_register (0, 4, "r", SImode, &regset);
+            if (tmp == NULL_RTX)
+              return false;
+
+            operands[0] = tmp;
+          }
+        else
+          {
+            /* Find a DImode register.  */
+            CLEAR_HARD_REG_SET (regset);
+            tmp = peep2_find_free_register (0, 4, "r", DImode, &regset);
+            if (tmp != NULL_RTX)
+              {
+                operands[0] = simplify_gen_subreg (SImode, tmp, DImode, 0);
+                operands[1] = simplify_gen_subreg (SImode, tmp, DImode, 4);
+              }
+            else
+              {
+                /* Can we use the input register to form a DI register?  */
+                SET_HARD_REG_SET (regset);
+                CLEAR_HARD_REG_BIT(regset,
+                                   regno % 2 == 0 ? regno + 1 : regno - 1);
+                tmp = peep2_find_free_register (0, 4, "r", SImode, &regset);
+                if (tmp == NULL_RTX)
+                  return false;
+                operands[regno % 2 == 1 ? 0 : 1] = tmp;
+              }
+          }
+
+        gcc_assert (operands[0] != NULL_RTX);
+        gcc_assert (operands[1] != NULL_RTX);
+        gcc_assert (REGNO (operands[0]) % 2 == 0);
+        gcc_assert (REGNO (operands[1]) == REGNO (operands[0]) + 1);
+      }
+    }
+
+  /* Make sure the instructions are ordered with lower memory access first.  */
+  if (offsets[0] > offsets[1])
+    {
+      gap = offsets[0] - offsets[1];
+      offset = offsets[1];
+
+      /* Swap the instructions such that lower memory is accessed first.  */
+      SWAP_RTX (operands[0], operands[1]);
+      SWAP_RTX (operands[2], operands[3]);
+      if (const_store)
+        SWAP_RTX (operands[4], operands[5]);
+    }
+  else
+    {
+      gap = offsets[1] - offsets[0];
+      offset = offsets[0];
+    }
+
+  /* Make sure accesses are to consecutive memory locations.  */
+  if (gap != 4)
+    return false;
+
+  /* Make sure we generate legal instructions.  */
+  if (operands_ok_ldrd_strd (operands[0], operands[1], base, offset,
+                             false, load))
+    return true;
+
+  /* In Thumb state, where registers are almost unconstrained, there
+     is little hope to fix it.  */
+  if (TARGET_THUMB2)
+    return false;
+
+  if (load && commute)
+    {
+      /* Try reordering registers.  */
+      SWAP_RTX (operands[0], operands[1]);
+      if (operands_ok_ldrd_strd (operands[0], operands[1], base, offset,
+                                 false, load))
+        return true;
+    }
+
+  if (const_store)
+    {
+      /* If input registers are dead after this pattern, they can be
+         reordered or replaced by other registers that are free in the
+         current pattern.  */
+      if (!peep2_reg_dead_p (4, operands[0])
+          || !peep2_reg_dead_p (4, operands[1]))
+        return false;
+
+      /* Try to reorder the input registers.  */
+      /* For example, the code
+           mov r0, 0
+           mov r1, 1
+           str r1, [r2]
+           str r0, [r2, #4]
+         can be transformed into
+           mov r1, 0
+           mov r0, 1
+           strd r0, [r2]
+      */
+      if (operands_ok_ldrd_strd (operands[1], operands[0], base, offset,
+                                  false, false))
+        {
+          SWAP_RTX (operands[0], operands[1]);
+          return true;
+        }
+
+      /* Try to find a free DI register.  */
+      CLEAR_HARD_REG_SET (regset);
+      add_to_hard_reg_set (&regset, SImode, REGNO (operands[0]));
+      add_to_hard_reg_set (&regset, SImode, REGNO (operands[1]));
+      while (true)
+        {
+          tmp = peep2_find_free_register (0, 4, "r", DImode, &regset);
+          if (tmp == NULL_RTX)
+            return false;
+
+          /* DREG must be an even-numbered register in DImode.
+             Split it into SI registers.  */
+          operands[0] = simplify_gen_subreg (SImode, tmp, DImode, 0);
+          operands[1] = simplify_gen_subreg (SImode, tmp, DImode, 4);
+          gcc_assert (operands[0] != NULL_RTX);
+          gcc_assert (operands[1] != NULL_RTX);
+          gcc_assert (REGNO (operands[0]) % 2 == 0);
+          gcc_assert (REGNO (operands[0]) + 1 == REGNO (operands[1]));
+
+          return (operands_ok_ldrd_strd (operands[0], operands[1],
+                                         base, offset,
+                                         false, load));
+        }
+    }
+
+  return false;
+}
+#undef SWAP_RTX
+
+
+
 
 /* Print a symbolic form of X to the debug file, F.  */
 static void
@@ -12806,8 +13298,8 @@ is_jump_table (rtx insn)
   rtx table;
 
   if (jump_to_label_p (insn)
-      && ((table = next_real_insn (JUMP_LABEL (insn)))
-	  == next_real_insn (insn))
+      && ((table = next_active_insn (JUMP_LABEL (insn)))
+	  == next_active_insn (insn))
       && table != NULL
       && JUMP_P (table)
       && (GET_CODE (PATTERN (table)) == ADDR_VEC
@@ -14805,7 +15297,8 @@ output_move_double (rtx *operands, bool emit, int *count)
     {
       /* Constraints should ensure this.  */
       gcc_assert (code0 == MEM && code1 == REG);
-      gcc_assert (REGNO (operands[1]) != IP_REGNUM);
+      gcc_assert ((REGNO (operands[1]) != IP_REGNUM)
+                  || (TARGET_ARM && TARGET_LDRD));
 
       switch (GET_CODE (XEXP (operands[0], 0)))
         {
@@ -15695,25 +16188,34 @@ arm_compute_save_reg0_reg12_mask (void)
   return save_reg_mask;
 }
 
+/* Return true if r3 is live at the start of the function.  */
+
+static bool
+arm_r3_live_at_start_p (void)
+{
+  /* Just look at cfg info, which is still close enough to correct at this
+     point.  This gives false positives for broken functions that might use
+     uninitialized data that happens to be allocated in r3, but who cares?  */
+  return REGNO_REG_SET_P (df_get_live_out (ENTRY_BLOCK_PTR), 3);
+}
 
 /* Compute the number of bytes used to store the static chain register on the
-   stack, above the stack frame. We need to know this accurately to get the
-   alignment of the rest of the stack frame correct. */
+   stack, above the stack frame.  We need to know this accurately to get the
+   alignment of the rest of the stack frame correct.  */
 
-static int arm_compute_static_chain_stack_bytes (void)
+static int
+arm_compute_static_chain_stack_bytes (void)
 {
-  unsigned long func_type = arm_current_func_type ();
-  int static_chain_stack_bytes = 0;
-
-  if (TARGET_APCS_FRAME && frame_pointer_needed && TARGET_ARM &&
-      IS_NESTED (func_type) &&
-      df_regs_ever_live_p (3) && crtl->args.pretend_args_size == 0)
-    static_chain_stack_bytes = 4;
+  /* See the defining assertion in arm_expand_prologue.  */
+  if (TARGET_APCS_FRAME && frame_pointer_needed && TARGET_ARM
+      && IS_NESTED (arm_current_func_type ())
+      && arm_r3_live_at_start_p ()
+      && crtl->args.pretend_args_size == 0)
+    return 4;
 
-  return static_chain_stack_bytes;
+  return 0;
 }
 
-
 /* Compute a bit mask of which registers need to be
    saved on the stack for the current function.
    This is used by arm_get_frame_offsets, which may add extra registers.  */
@@ -16398,6 +16900,148 @@ thumb2_emit_strd_push (unsigned long saved_regs_mask)
   return;
 }
 
+/* STRD in ARM mode requires consecutive registers.  This function emits STRD
+   whenever possible, otherwise it emits single-word stores.  The first store
+   also allocates stack space for all saved registers, using writeback with
+   post-addressing mode.  All other stores use offset addressing.  If no STRD
+   can be emitted, this function emits a sequence of single-word stores,
+   and not an STM as before, because single-word stores provide more freedom
+   scheduling and can be turned into an STM by peephole optimizations.  */
+static void
+arm_emit_strd_push (unsigned long saved_regs_mask)
+{
+  int num_regs = 0;
+  int i, j, dwarf_index  = 0;
+  int offset = 0;
+  rtx dwarf = NULL_RTX;
+  rtx insn = NULL_RTX;
+  rtx tmp, mem;
+
+  /* TODO: A more efficient code can be emitted by changing the
+     layout, e.g., first push all pairs that can use STRD to keep the
+     stack aligned, and then push all other registers.  */
+  for (i = 0; i <= LAST_ARM_REGNUM; i++)
+    if (saved_regs_mask & (1 << i))
+      num_regs++;
+
+  gcc_assert (!(saved_regs_mask & (1 << SP_REGNUM)));
+  gcc_assert (!(saved_regs_mask & (1 << PC_REGNUM)));
+  gcc_assert (num_regs > 0);
+
+  /* Create sequence for DWARF info.  */
+  dwarf = gen_rtx_SEQUENCE (VOIDmode, rtvec_alloc (num_regs + 1));
+
+  /* For dwarf info, we generate explicit stack update.  */
+  tmp = gen_rtx_SET (VOIDmode,
+                     stack_pointer_rtx,
+                     plus_constant (Pmode, stack_pointer_rtx, -4 * num_regs));
+  RTX_FRAME_RELATED_P (tmp) = 1;
+  XVECEXP (dwarf, 0, dwarf_index++) = tmp;
+
+  /* Save registers.  */
+  offset = - 4 * num_regs;
+  j = 0;
+  while (j <= LAST_ARM_REGNUM)
+    if (saved_regs_mask & (1 << j))
+      {
+        if ((j % 2 == 0)
+            && (saved_regs_mask & (1 << (j + 1))))
+          {
+            /* Current register and previous register form register pair for
+               which STRD can be generated.  */
+            if (offset < 0)
+              {
+                /* Allocate stack space for all saved registers.  */
+                tmp = plus_constant (Pmode, stack_pointer_rtx, offset);
+                tmp = gen_rtx_PRE_MODIFY (Pmode, stack_pointer_rtx, tmp);
+                mem = gen_frame_mem (DImode, tmp);
+                offset = 0;
+              }
+            else if (offset > 0)
+              mem = gen_frame_mem (DImode,
+                                   plus_constant (Pmode,
+                                                  stack_pointer_rtx,
+                                                  offset));
+            else
+              mem = gen_frame_mem (DImode, stack_pointer_rtx);
+
+            tmp = gen_rtx_SET (DImode, mem, gen_rtx_REG (DImode, j));
+            RTX_FRAME_RELATED_P (tmp) = 1;
+            tmp = emit_insn (tmp);
+
+            /* Record the first store insn.  */
+            if (dwarf_index == 1)
+              insn = tmp;
+
+            /* Generate dwarf info.  */
+            mem = gen_frame_mem (SImode,
+                                 plus_constant (Pmode,
+                                                stack_pointer_rtx,
+                                                offset));
+            tmp = gen_rtx_SET (SImode, mem, gen_rtx_REG (SImode, j));
+            RTX_FRAME_RELATED_P (tmp) = 1;
+            XVECEXP (dwarf, 0, dwarf_index++) = tmp;
+
+            mem = gen_frame_mem (SImode,
+                                 plus_constant (Pmode,
+                                                stack_pointer_rtx,
+                                                offset + 4));
+            tmp = gen_rtx_SET (SImode, mem, gen_rtx_REG (SImode, j + 1));
+            RTX_FRAME_RELATED_P (tmp) = 1;
+            XVECEXP (dwarf, 0, dwarf_index++) = tmp;
+
+            offset += 8;
+            j += 2;
+          }
+        else
+          {
+            /* Emit a single word store.  */
+            if (offset < 0)
+              {
+                /* Allocate stack space for all saved registers.  */
+                tmp = plus_constant (Pmode, stack_pointer_rtx, offset);
+                tmp = gen_rtx_PRE_MODIFY (Pmode, stack_pointer_rtx, tmp);
+                mem = gen_frame_mem (SImode, tmp);
+                offset = 0;
+              }
+            else if (offset > 0)
+              mem = gen_frame_mem (SImode,
+                                   plus_constant (Pmode,
+                                                  stack_pointer_rtx,
+                                                  offset));
+            else
+              mem = gen_frame_mem (SImode, stack_pointer_rtx);
+
+            tmp = gen_rtx_SET (SImode, mem, gen_rtx_REG (SImode, j));
+            RTX_FRAME_RELATED_P (tmp) = 1;
+            tmp = emit_insn (tmp);
+
+            /* Record the first store insn.  */
+            if (dwarf_index == 1)
+              insn = tmp;
+
+            /* Generate dwarf info.  */
+            mem = gen_frame_mem (SImode,
+                                 plus_constant(Pmode,
+                                               stack_pointer_rtx,
+                                               offset));
+            tmp = gen_rtx_SET (SImode, mem, gen_rtx_REG (SImode, j));
+            RTX_FRAME_RELATED_P (tmp) = 1;
+            XVECEXP (dwarf, 0, dwarf_index++) = tmp;
+
+            offset += 4;
+            j += 1;
+          }
+      }
+    else
+      j++;
+
+  /* Attach dwarf info to the first insn we generate.  */
+  gcc_assert (insn != NULL_RTX);
+  add_reg_note (insn, REG_FRAME_RELATED_EXPR, dwarf);
+  RTX_FRAME_RELATED_P (insn) = 1;
+}
+
 /* Generate and emit an insn that we will recognize as a push_multi.
    Unfortunately, since this insn does not reflect very well the actual
    semantics of the operation, we need to annotate the insn for the benefit
@@ -16540,6 +17184,19 @@ emit_multi_reg_push (unsigned long mask)
   return par;
 }
 
+/* Add a REG_CFA_ADJUST_CFA REG note to INSN.
+   SIZE is the offset to be adjusted.
+   DEST and SRC might be stack_pointer_rtx or hard_frame_pointer_rtx.  */
+static void
+arm_add_cfa_adjust_cfa_note (rtx insn, int size, rtx dest, rtx src)
+{
+  rtx dwarf;
+
+  RTX_FRAME_RELATED_P (insn) = 1;
+  dwarf = gen_rtx_SET (VOIDmode, dest, plus_constant (Pmode, src, size));
+  add_reg_note (insn, REG_CFA_ADJUST_CFA, dwarf);
+}
+
 /* Generate and emit an insn pattern that we will recognize as a pop_multi.
    SAVED_REGS_MASK shows which registers need to be restored.
 
@@ -16597,6 +17254,17 @@ arm_emit_multi_reg_pop (unsigned long saved_regs_mask)
     if (saved_regs_mask & (1 << i))
       {
         reg = gen_rtx_REG (SImode, i);
+        if ((num_regs == 1) && emit_update && !return_in_pc)
+          {
+            /* Emit single load with writeback.  */
+            tmp = gen_frame_mem (SImode,
+                                 gen_rtx_POST_INC (Pmode,
+                                                   stack_pointer_rtx));
+            tmp = emit_insn (gen_rtx_SET (VOIDmode, reg, tmp));
+            REG_NOTES (tmp) = alloc_reg_note (REG_CFA_RESTORE, reg, dwarf);
+            return;
+          }
+
         tmp = gen_rtx_SET (VOIDmode,
                            reg,
                            gen_frame_mem
@@ -16619,6 +17287,9 @@ arm_emit_multi_reg_pop (unsigned long saved_regs_mask)
     par = emit_insn (par);
 
   REG_NOTES (par) = dwarf;
+  if (!return_in_pc)
+    arm_add_cfa_adjust_cfa_note (par, UNITS_PER_WORD * num_regs,
+				 stack_pointer_rtx, stack_pointer_rtx);
 }
 
 /* Generate and emit an insn pattern that we will recognize as a pop_multi
@@ -16689,6 +17360,9 @@ arm_emit_vfp_multi_reg_pop (int first_reg, int num_regs, rtx base_reg)
 
   par = emit_insn (par);
   REG_NOTES (par) = dwarf;
+
+  arm_add_cfa_adjust_cfa_note (par, 2 * UNITS_PER_WORD * num_regs,
+			       base_reg, base_reg);
 }
 
 /* Generate and emit a pattern that will be recognized as LDRD pattern.  If even
@@ -16764,6 +17438,7 @@ thumb2_emit_ldrd_pop (unsigned long saved_regs_mask)
                pattern can be emitted now.  */
             par = emit_insn (par);
             REG_NOTES (par) = dwarf;
+	    RTX_FRAME_RELATED_P (par) = 1;
           }
 
         i++;
@@ -16780,7 +17455,12 @@ thumb2_emit_ldrd_pop (unsigned long saved_regs_mask)
                      stack_pointer_rtx,
                      plus_constant (Pmode, stack_pointer_rtx, 4 * i));
   RTX_FRAME_RELATED_P (tmp) = 1;
-  emit_insn (tmp);
+  tmp = emit_insn (tmp);
+  if (!return_in_pc)
+    {
+      arm_add_cfa_adjust_cfa_note (tmp, UNITS_PER_WORD * i,
+				   stack_pointer_rtx, stack_pointer_rtx);
+    }
 
   dwarf = NULL_RTX;
 
@@ -16814,9 +17494,11 @@ thumb2_emit_ldrd_pop (unsigned long saved_regs_mask)
       else
         {
           par = emit_insn (tmp);
+	  REG_NOTES (par) = dwarf;
+	  arm_add_cfa_adjust_cfa_note (par, UNITS_PER_WORD,
+				       stack_pointer_rtx, stack_pointer_rtx);
         }
 
-      REG_NOTES (par) = dwarf;
     }
   else if ((num_regs % 2) == 1 && return_in_pc)
     {
@@ -16828,6 +17510,129 @@ thumb2_emit_ldrd_pop (unsigned long saved_regs_mask)
   return;
 }
 
+/* LDRD in ARM mode needs consecutive registers as operands.  This function
+   emits LDRD whenever possible, otherwise it emits single-word loads. It uses
+   offset addressing and then generates one separate stack udpate. This provides
+   more scheduling freedom, compared to writeback on every load.  However,
+   if the function returns using load into PC directly
+   (i.e., if PC is in SAVED_REGS_MASK), the stack needs to be updated
+   before the last load.  TODO: Add a peephole optimization to recognize
+   the new epilogue sequence as an LDM instruction whenever possible.  TODO: Add
+   peephole optimization to merge the load at stack-offset zero
+   with the stack update instruction using load with writeback
+   in post-index addressing mode.  */
+static void
+arm_emit_ldrd_pop (unsigned long saved_regs_mask)
+{
+  int j = 0;
+  int offset = 0;
+  rtx par = NULL_RTX;
+  rtx dwarf = NULL_RTX;
+  rtx tmp, mem;
+
+  /* Restore saved registers.  */
+  gcc_assert (!((saved_regs_mask & (1 << SP_REGNUM))));
+  j = 0;
+  while (j <= LAST_ARM_REGNUM)
+    if (saved_regs_mask & (1 << j))
+      {
+        if ((j % 2) == 0
+            && (saved_regs_mask & (1 << (j + 1)))
+            && (j + 1) != PC_REGNUM)
+          {
+            /* Current register and next register form register pair for which
+               LDRD can be generated. PC is always the last register popped, and
+               we handle it separately.  */
+            if (offset > 0)
+              mem = gen_frame_mem (DImode,
+                                   plus_constant (Pmode,
+                                                  stack_pointer_rtx,
+                                                  offset));
+            else
+              mem = gen_frame_mem (DImode, stack_pointer_rtx);
+
+            tmp = gen_rtx_SET (DImode, gen_rtx_REG (DImode, j), mem);
+            RTX_FRAME_RELATED_P (tmp) = 1;
+            tmp = emit_insn (tmp);
+
+            /* Generate dwarf info.  */
+
+            dwarf = alloc_reg_note (REG_CFA_RESTORE,
+                                    gen_rtx_REG (SImode, j),
+                                    NULL_RTX);
+            dwarf = alloc_reg_note (REG_CFA_RESTORE,
+                                    gen_rtx_REG (SImode, j + 1),
+                                    dwarf);
+
+            REG_NOTES (tmp) = dwarf;
+
+            offset += 8;
+            j += 2;
+          }
+        else if (j != PC_REGNUM)
+          {
+            /* Emit a single word load.  */
+            if (offset > 0)
+              mem = gen_frame_mem (SImode,
+                                   plus_constant (Pmode,
+                                                  stack_pointer_rtx,
+                                                  offset));
+            else
+              mem = gen_frame_mem (SImode, stack_pointer_rtx);
+
+            tmp = gen_rtx_SET (SImode, gen_rtx_REG (SImode, j), mem);
+            RTX_FRAME_RELATED_P (tmp) = 1;
+            tmp = emit_insn (tmp);
+
+            /* Generate dwarf info.  */
+            REG_NOTES (tmp) = alloc_reg_note (REG_CFA_RESTORE,
+                                              gen_rtx_REG (SImode, j),
+                                              NULL_RTX);
+
+            offset += 4;
+            j += 1;
+          }
+        else /* j == PC_REGNUM */
+          j++;
+      }
+    else
+      j++;
+
+  /* Update the stack.  */
+  if (offset > 0)
+    {
+      tmp = gen_rtx_SET (Pmode,
+                         stack_pointer_rtx,
+                         plus_constant (Pmode,
+                                        stack_pointer_rtx,
+                                        offset));
+      RTX_FRAME_RELATED_P (tmp) = 1;
+      emit_insn (tmp);
+      offset = 0;
+    }
+
+  if (saved_regs_mask & (1 << PC_REGNUM))
+    {
+      /* Only PC is to be popped.  */
+      par = gen_rtx_PARALLEL (VOIDmode, rtvec_alloc (2));
+      XVECEXP (par, 0, 0) = ret_rtx;
+      tmp = gen_rtx_SET (SImode,
+                         gen_rtx_REG (SImode, PC_REGNUM),
+                         gen_frame_mem (SImode,
+                                        gen_rtx_POST_INC (SImode,
+                                                          stack_pointer_rtx)));
+      RTX_FRAME_RELATED_P (tmp) = 1;
+      XVECEXP (par, 0, 1) = tmp;
+      par = emit_jump_insn (par);
+
+      /* Generate dwarf info.  */
+      dwarf = alloc_reg_note (REG_CFA_RESTORE,
+                              gen_rtx_REG (SImode, PC_REGNUM),
+                              NULL_RTX);
+      REG_NOTES (par) = dwarf;
+    }
+}
+
 /* Calculate the size of the return value that is passed in registers.  */
 static unsigned
 arm_size_return_regs (void)
@@ -16852,11 +17657,27 @@ thumb_force_lr_save (void)
 	     || df_regs_ever_live_p (LR_REGNUM));
 }
 
+/* We do not know if r3 will be available because
+   we do have an indirect tailcall happening in this
+   particular case.  */
+static bool
+is_indirect_tailcall_p (rtx call)
+{
+  rtx pat = PATTERN (call);
+
+  /* Indirect tail call.  */
+  pat = XVECEXP (pat, 0, 0);
+  if (GET_CODE (pat) == SET)
+    pat = SET_SRC (pat);
+
+  pat = XEXP (XEXP (pat, 0), 0);
+  return REG_P (pat);
+}
 
 /* Return true if r3 is used by any of the tail call insns in the
    current function.  */
 static bool
-any_sibcall_uses_r3 (void)
+any_sibcall_could_use_r3 (void)
 {
   edge_iterator ei;
   edge e;
@@ -16870,7 +17691,8 @@ any_sibcall_uses_r3 (void)
 	if (!CALL_P (call))
 	  call = prev_nonnote_nondebug_insn (call);
 	gcc_assert (CALL_P (call) && SIBLING_CALL_P (call));
-	if (find_regno_fusage (call, USE, 3))
+	if (find_regno_fusage (call, USE, 3)
+	    || is_indirect_tailcall_p (call))
 	  return true;
       }
   return false;
@@ -17037,9 +17859,10 @@ arm_get_frame_offsets (void)
 	  /* If it is safe to use r3, then do so.  This sometimes
 	     generates better code on Thumb-2 by avoiding the need to
 	     use 32-bit push/pop instructions.  */
- 	  if (! any_sibcall_uses_r3 ()
+          if (! any_sibcall_could_use_r3 ()
 	      && arm_size_return_regs () <= 12
-	      && (offsets->saved_regs_mask & (1 << 3)) == 0)
+	      && (offsets->saved_regs_mask & (1 << 3)) == 0
+              && (TARGET_THUMB2 || !current_tune->prefer_ldrd_strd))
 	    {
 	      reg = 3;
 	    }
@@ -17347,16 +18170,16 @@ arm_expand_prologue (void)
 	}
       else if (IS_NESTED (func_type))
 	{
-	  /* The Static chain register is the same as the IP register
+	  /* The static chain register is the same as the IP register
 	     used as a scratch register during stack frame creation.
 	     To get around this need to find somewhere to store IP
 	     whilst the frame is being created.  We try the following
 	     places in order:
 
-	       1. The last argument register.
+	       1. The last argument register r3.
 	       2. A slot on the stack above the frame.  (This only
 	          works if the function is not a varargs function).
-	       3. Register r3, after pushing the argument registers
+	       3. Register r3 again, after pushing the argument registers
 	          onto the stack.
 
 	     Note - we only need to tell the dwarf2 backend about the SP
@@ -17364,7 +18187,7 @@ arm_expand_prologue (void)
 	     doesn't need to be unwound, as it doesn't contain a value
 	     inherited from the caller.  */
 
-	  if (df_regs_ever_live_p (3) == false)
+	  if (!arm_r3_live_at_start_p ())
 	    insn = emit_set_insn (gen_rtx_REG (SImode, 3), ip_rtx);
 	  else if (args_to_push == 0)
 	    {
@@ -17471,6 +18294,12 @@ arm_expand_prologue (void)
             {
               thumb2_emit_strd_push (live_regs_mask);
             }
+          else if (TARGET_ARM
+                   && !TARGET_APCS_FRAME
+                   && !IS_INTERRUPT (func_type))
+            {
+              arm_emit_strd_push (live_regs_mask);
+            }
           else
             {
               insn = emit_multi_reg_push (live_regs_mask);
@@ -17499,8 +18328,7 @@ arm_expand_prologue (void)
 	  if (IS_NESTED (func_type))
 	    {
 	      /* Recover the static chain register.  */
-	      if (!df_regs_ever_live_p (3)
-		  || saved_pretend_args)
+	      if (!arm_r3_live_at_start_p () || saved_pretend_args)
 		insn = gen_rtx_REG (SImode, 3);
 	      else /* if (crtl->args.pretend_args_size == 0) */
 		{
@@ -18748,6 +19576,13 @@ thumb2_final_prescan_insn (rtx insn)
   enum arm_cond_code code;
   int n;
   int mask;
+  int max;
+
+  /* Maximum number of conditionally executed instructions in a block
+     is minimum of the two max values: maximum allowed in an IT block
+     and maximum that is beneficial according to the cost model and tune.  */
+  max = (max_insns_skipped < MAX_INSN_PER_IT_BLOCK) ?
+    max_insns_skipped : MAX_INSN_PER_IT_BLOCK;
 
   /* Remove the previous insn from the count of insns to be output.  */
   if (arm_condexec_count)
@@ -18790,9 +19625,9 @@ thumb2_final_prescan_insn (rtx insn)
       /* ??? Recognize conditional jumps, and combine them with IT blocks.  */
       if (GET_CODE (body) != COND_EXEC)
 	break;
-      /* Allow up to 4 conditionally executed instructions in a block.  */
+      /* Maximum number of conditionally executed instructions in a block.  */
       n = get_attr_ce_count (insn);
-      if (arm_condexec_masklen + n > 4)
+      if (arm_condexec_masklen + n > max)
 	break;
 
       predicate = COND_EXEC_TEST (body);
@@ -19470,7 +20305,8 @@ typedef struct {
   VAR9 (T, N, A, B, C, D, E, F, G, H, I), \
   {#N, NEON_##T, UP (J), CF (N, J), 0}
 
-/* The mode entries in the following table correspond to the "key" type of the
+/* The NEON builtin data can be found in arm_neon_builtins.def.
+   The mode entries in the following table correspond to the "key" type of the
    instruction variant, i.e. equivalent to that which would be specified after
    the assembler mnemonic, which usually refers to the last vector operand.
    (Signed/unsigned/polynomial types are not differentiated between though, and
@@ -19480,196 +20316,7 @@ typedef struct {
 
 static neon_builtin_datum neon_builtin_data[] =
 {
-  VAR10 (BINOP, vadd,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR3 (BINOP, vaddl, v8qi, v4hi, v2si),
-  VAR3 (BINOP, vaddw, v8qi, v4hi, v2si),
-  VAR6 (BINOP, vhadd, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR8 (BINOP, vqadd, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR3 (BINOP, vaddhn, v8hi, v4si, v2di),
-  VAR8 (BINOP, vmul, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR8 (TERNOP, vmla, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR3 (TERNOP, vmlal, v8qi, v4hi, v2si),
-  VAR2 (TERNOP, vfma, v2sf, v4sf),
-  VAR2 (TERNOP, vfms, v2sf, v4sf),
-  VAR8 (TERNOP, vmls, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR3 (TERNOP, vmlsl, v8qi, v4hi, v2si),
-  VAR4 (BINOP, vqdmulh, v4hi, v2si, v8hi, v4si),
-  VAR2 (TERNOP, vqdmlal, v4hi, v2si),
-  VAR2 (TERNOP, vqdmlsl, v4hi, v2si),
-  VAR3 (BINOP, vmull, v8qi, v4hi, v2si),
-  VAR2 (SCALARMULL, vmull_n, v4hi, v2si),
-  VAR2 (LANEMULL, vmull_lane, v4hi, v2si),
-  VAR2 (SCALARMULL, vqdmull_n, v4hi, v2si),
-  VAR2 (LANEMULL, vqdmull_lane, v4hi, v2si),
-  VAR4 (SCALARMULH, vqdmulh_n, v4hi, v2si, v8hi, v4si),
-  VAR4 (LANEMULH, vqdmulh_lane, v4hi, v2si, v8hi, v4si),
-  VAR2 (BINOP, vqdmull, v4hi, v2si),
-  VAR8 (BINOP, vshl, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR8 (BINOP, vqshl, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR8 (SHIFTIMM, vshr_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR3 (SHIFTIMM, vshrn_n, v8hi, v4si, v2di),
-  VAR3 (SHIFTIMM, vqshrn_n, v8hi, v4si, v2di),
-  VAR3 (SHIFTIMM, vqshrun_n, v8hi, v4si, v2di),
-  VAR8 (SHIFTIMM, vshl_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR8 (SHIFTIMM, vqshl_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR8 (SHIFTIMM, vqshlu_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR3 (SHIFTIMM, vshll_n, v8qi, v4hi, v2si),
-  VAR8 (SHIFTACC, vsra_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR10 (BINOP, vsub,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR3 (BINOP, vsubl, v8qi, v4hi, v2si),
-  VAR3 (BINOP, vsubw, v8qi, v4hi, v2si),
-  VAR8 (BINOP, vqsub, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR6 (BINOP, vhsub, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR3 (BINOP, vsubhn, v8hi, v4si, v2di),
-  VAR8 (BINOP, vceq, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR8 (BINOP, vcge, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR6 (BINOP, vcgeu, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR8 (BINOP, vcgt, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR6 (BINOP, vcgtu, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR2 (BINOP, vcage, v2sf, v4sf),
-  VAR2 (BINOP, vcagt, v2sf, v4sf),
-  VAR6 (BINOP, vtst, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR8 (BINOP, vabd, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR3 (BINOP, vabdl, v8qi, v4hi, v2si),
-  VAR6 (TERNOP, vaba, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR3 (TERNOP, vabal, v8qi, v4hi, v2si),
-  VAR8 (BINOP, vmax, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR8 (BINOP, vmin, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR4 (BINOP, vpadd, v8qi, v4hi, v2si, v2sf),
-  VAR6 (UNOP, vpaddl, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR6 (BINOP, vpadal, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR4 (BINOP, vpmax, v8qi, v4hi, v2si, v2sf),
-  VAR4 (BINOP, vpmin, v8qi, v4hi, v2si, v2sf),
-  VAR2 (BINOP, vrecps, v2sf, v4sf),
-  VAR2 (BINOP, vrsqrts, v2sf, v4sf),
-  VAR8 (SHIFTINSERT, vsri_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR8 (SHIFTINSERT, vsli_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
-  VAR8 (UNOP, vabs, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR6 (UNOP, vqabs, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR8 (UNOP, vneg, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR6 (UNOP, vqneg, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR6 (UNOP, vcls, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR6 (UNOP, vclz, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  VAR2 (UNOP, vcnt, v8qi, v16qi),
-  VAR4 (UNOP, vrecpe, v2si, v2sf, v4si, v4sf),
-  VAR4 (UNOP, vrsqrte, v2si, v2sf, v4si, v4sf),
-  VAR6 (UNOP, vmvn, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
-  /* FIXME: vget_lane supports more variants than this!  */
-  VAR10 (GETLANE, vget_lane,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (SETLANE, vset_lane,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR5 (CREATE, vcreate, v8qi, v4hi, v2si, v2sf, di),
-  VAR10 (DUP, vdup_n,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (DUPLANE, vdup_lane,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR5 (COMBINE, vcombine, v8qi, v4hi, v2si, v2sf, di),
-  VAR5 (SPLIT, vget_high, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR5 (SPLIT, vget_low, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR3 (UNOP, vmovn, v8hi, v4si, v2di),
-  VAR3 (UNOP, vqmovn, v8hi, v4si, v2di),
-  VAR3 (UNOP, vqmovun, v8hi, v4si, v2di),
-  VAR3 (UNOP, vmovl, v8qi, v4hi, v2si),
-  VAR6 (LANEMUL, vmul_lane, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR6 (LANEMAC, vmla_lane, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR2 (LANEMAC, vmlal_lane, v4hi, v2si),
-  VAR2 (LANEMAC, vqdmlal_lane, v4hi, v2si),
-  VAR6 (LANEMAC, vmls_lane, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR2 (LANEMAC, vmlsl_lane, v4hi, v2si),
-  VAR2 (LANEMAC, vqdmlsl_lane, v4hi, v2si),
-  VAR6 (SCALARMUL, vmul_n, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR6 (SCALARMAC, vmla_n, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR2 (SCALARMAC, vmlal_n, v4hi, v2si),
-  VAR2 (SCALARMAC, vqdmlal_n, v4hi, v2si),
-  VAR6 (SCALARMAC, vmls_n, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR2 (SCALARMAC, vmlsl_n, v4hi, v2si),
-  VAR2 (SCALARMAC, vqdmlsl_n, v4hi, v2si),
-  VAR10 (BINOP, vext,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR8 (UNOP, vrev64, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR4 (UNOP, vrev32, v8qi, v4hi, v16qi, v8hi),
-  VAR2 (UNOP, vrev16, v8qi, v16qi),
-  VAR4 (CONVERT, vcvt, v2si, v2sf, v4si, v4sf),
-  VAR4 (FIXCONV, vcvt_n, v2si, v2sf, v4si, v4sf),
-  VAR10 (SELECT, vbsl,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR2 (RINT, vrintn, v2sf, v4sf),
-  VAR2 (RINT, vrinta, v2sf, v4sf),
-  VAR2 (RINT, vrintp, v2sf, v4sf),
-  VAR2 (RINT, vrintm, v2sf, v4sf),
-  VAR2 (RINT, vrintz, v2sf, v4sf),
-  VAR2 (RINT, vrintx, v2sf, v4sf),
-  VAR1 (VTBL, vtbl1, v8qi),
-  VAR1 (VTBL, vtbl2, v8qi),
-  VAR1 (VTBL, vtbl3, v8qi),
-  VAR1 (VTBL, vtbl4, v8qi),
-  VAR1 (VTBX, vtbx1, v8qi),
-  VAR1 (VTBX, vtbx2, v8qi),
-  VAR1 (VTBX, vtbx3, v8qi),
-  VAR1 (VTBX, vtbx4, v8qi),
-  VAR8 (RESULTPAIR, vtrn, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR8 (RESULTPAIR, vzip, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR8 (RESULTPAIR, vuzp, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
-  VAR5 (REINTERP, vreinterpretv8qi, v8qi, v4hi, v2si, v2sf, di),
-  VAR5 (REINTERP, vreinterpretv4hi, v8qi, v4hi, v2si, v2sf, di),
-  VAR5 (REINTERP, vreinterpretv2si, v8qi, v4hi, v2si, v2sf, di),
-  VAR5 (REINTERP, vreinterpretv2sf, v8qi, v4hi, v2si, v2sf, di),
-  VAR5 (REINTERP, vreinterpretdi, v8qi, v4hi, v2si, v2sf, di),
-  VAR5 (REINTERP, vreinterpretv16qi, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR5 (REINTERP, vreinterpretv8hi, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR5 (REINTERP, vreinterpretv4si, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR5 (REINTERP, vreinterpretv4sf, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR5 (REINTERP, vreinterpretv2di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (LOAD1, vld1,
-         v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (LOAD1LANE, vld1_lane,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (LOAD1, vld1_dup,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (STORE1, vst1,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (STORE1LANE, vst1_lane,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR9 (LOADSTRUCT,
-	vld2, v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
-  VAR7 (LOADSTRUCTLANE, vld2_lane,
-	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR5 (LOADSTRUCT, vld2_dup, v8qi, v4hi, v2si, v2sf, di),
-  VAR9 (STORESTRUCT, vst2,
-	v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
-  VAR7 (STORESTRUCTLANE, vst2_lane,
-	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR9 (LOADSTRUCT,
-	vld3, v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
-  VAR7 (LOADSTRUCTLANE, vld3_lane,
-	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR5 (LOADSTRUCT, vld3_dup, v8qi, v4hi, v2si, v2sf, di),
-  VAR9 (STORESTRUCT, vst3,
-	v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
-  VAR7 (STORESTRUCTLANE, vst3_lane,
-	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR9 (LOADSTRUCT, vld4,
-	v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
-  VAR7 (LOADSTRUCTLANE, vld4_lane,
-	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR5 (LOADSTRUCT, vld4_dup, v8qi, v4hi, v2si, v2sf, di),
-  VAR9 (STORESTRUCT, vst4,
-	v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
-  VAR7 (STORESTRUCTLANE, vst4_lane,
-	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
-  VAR10 (LOGICBINOP, vand,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (LOGICBINOP, vorr,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (BINOP, veor,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (LOGICBINOP, vbic,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
-  VAR10 (LOGICBINOP, vorn,
-	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di)
+#include "arm_neon_builtins.def"
 };
 
 #undef CF
@@ -19684,9 +20331,36 @@ static neon_builtin_datum neon_builtin_data[] =
 #undef VAR9
 #undef VAR10
 
-/* Neon defines builtins from ARM_BUILTIN_MAX upwards, though they don't have
-   symbolic names defined here (which would require too much duplication).
-   FIXME?  */
+#define CF(N,X) ARM_BUILTIN_NEON_##N##X
+#define VAR1(T, N, A) \
+  CF (N, A)
+#define VAR2(T, N, A, B) \
+  VAR1 (T, N, A), \
+  CF (N, B)
+#define VAR3(T, N, A, B, C) \
+  VAR2 (T, N, A, B), \
+  CF (N, C)
+#define VAR4(T, N, A, B, C, D) \
+  VAR3 (T, N, A, B, C), \
+  CF (N, D)
+#define VAR5(T, N, A, B, C, D, E) \
+  VAR4 (T, N, A, B, C, D), \
+  CF (N, E)
+#define VAR6(T, N, A, B, C, D, E, F) \
+  VAR5 (T, N, A, B, C, D, E), \
+  CF (N, F)
+#define VAR7(T, N, A, B, C, D, E, F, G) \
+  VAR6 (T, N, A, B, C, D, E, F), \
+  CF (N, G)
+#define VAR8(T, N, A, B, C, D, E, F, G, H) \
+  VAR7 (T, N, A, B, C, D, E, F, G), \
+  CF (N, H)
+#define VAR9(T, N, A, B, C, D, E, F, G, H, I) \
+  VAR8 (T, N, A, B, C, D, E, F, G, H), \
+  CF (N, I)
+#define VAR10(T, N, A, B, C, D, E, F, G, H, I, J) \
+  VAR9 (T, N, A, B, C, D, E, F, G, H, I), \
+  CF (N, J)
 enum arm_builtins
 {
   ARM_BUILTIN_GETWCGR0,
@@ -19935,11 +20609,25 @@ enum arm_builtins
 
   ARM_BUILTIN_WMERGE,
 
-  ARM_BUILTIN_NEON_BASE,
+#include "arm_neon_builtins.def"
 
-  ARM_BUILTIN_MAX = ARM_BUILTIN_NEON_BASE + ARRAY_SIZE (neon_builtin_data)
+  ,ARM_BUILTIN_MAX
 };
 
+#define ARM_BUILTIN_NEON_BASE (ARM_BUILTIN_MAX - ARRAY_SIZE (neon_builtin_data))
+
+#undef CF
+#undef VAR1
+#undef VAR2
+#undef VAR3
+#undef VAR4
+#undef VAR5
+#undef VAR6
+#undef VAR7
+#undef VAR8
+#undef VAR9
+#undef VAR10
+
 static GTY(()) tree arm_builtin_decls[ARM_BUILTIN_MAX];
 
 static void
@@ -21616,7 +22304,7 @@ arm_expand_builtin (tree exp,
   rtx               op1;
   rtx               op2;
   rtx               pat;
-  int               fcode = DECL_FUNCTION_CODE (fndecl);
+  unsigned int      fcode = DECL_FUNCTION_CODE (fndecl);
   size_t            i;
   enum machine_mode tmode;
   enum machine_mode mode0;
@@ -22568,6 +23256,11 @@ thumb1_final_prescan_insn (rtx insn)
       else if (conds != CONDS_NOCOND)
 	cfun->machine->thumb1_cc_insn = NULL_RTX;
     }
+
+    /* Check if unexpected far jump is used.  */
+    if (cfun->machine->lr_save_eliminated
+        && get_attr_far_jump (insn) == FAR_JUMP_YES)
+      internal_error("Unexpected thumb1 far jump");
 }
 
 int
@@ -22593,6 +23286,8 @@ static int
 thumb_far_jump_used_p (void)
 {
   rtx insn;
+  bool far_jump = false;
+  unsigned int func_size = 0;
 
   /* This test is only important for leaf functions.  */
   /* assert (!leaf_function_p ()); */
@@ -22648,6 +23343,26 @@ thumb_far_jump_used_p (void)
 	  && get_attr_far_jump (insn) == FAR_JUMP_YES
 	  )
 	{
+	  far_jump = true;
+	}
+      func_size += get_attr_length (insn);
+    }
+
+  /* Attribute far_jump will always be true for thumb1 before
+     shorten_branch pass.  So checking far_jump attribute before
+     shorten_branch isn't much useful.
+
+     Following heuristic tries to estimate more accurately if a far jump
+     may finally be used.  The heuristic is very conservative as there is
+     no chance to roll-back the decision of not to use far jump.
+
+     Thumb1 long branch offset is -2048 to 2046.  The worst case is each
+     2-byte insn is associated with a 4 byte constant pool.  Using
+     function size 2048/3 as the threshold is conservative enough.  */
+  if (far_jump)
+    {
+      if ((func_size * 3) >= 2048)
+        {
 	  /* Record the fact that we have decided that
 	     the function does use far jumps.  */
 	  cfun->machine->far_jump_used = 1;
@@ -23333,7 +24048,7 @@ thumb1_expand_prologue (void)
    all we really need to check here is if single register is to be
    returned, or multiple register return.  */
 void
-thumb2_expand_return (void)
+thumb2_expand_return (bool simple_return)
 {
   int i, num_regs;
   unsigned long saved_regs_mask;
@@ -23346,7 +24061,7 @@ thumb2_expand_return (void)
     if (saved_regs_mask & (1 << i))
       num_regs++;
 
-  if (saved_regs_mask)
+  if (!simple_return && saved_regs_mask)
     {
       if (num_regs == 1)
         {
@@ -23624,6 +24339,7 @@ arm_expand_epilogue (bool really_return)
 
   if (frame_pointer_needed)
     {
+      rtx insn;
       /* Restore stack pointer if necessary.  */
       if (TARGET_ARM)
         {
@@ -23634,9 +24350,12 @@ arm_expand_epilogue (bool really_return)
           /* Force out any pending memory operations that reference stacked data
              before stack de-allocation occurs.  */
           emit_insn (gen_blockage ());
-          emit_insn (gen_addsi3 (stack_pointer_rtx,
-                                 hard_frame_pointer_rtx,
-                                 GEN_INT (amount)));
+	  insn = emit_insn (gen_addsi3 (stack_pointer_rtx,
+			    hard_frame_pointer_rtx,
+			    GEN_INT (amount)));
+	  arm_add_cfa_adjust_cfa_note (insn, amount,
+				       stack_pointer_rtx,
+				       hard_frame_pointer_rtx);
 
           /* Emit USE(stack_pointer_rtx) to ensure that stack adjustment is not
              deleted.  */
@@ -23646,16 +24365,25 @@ arm_expand_epilogue (bool really_return)
         {
           /* In Thumb-2 mode, the frame pointer points to the last saved
              register.  */
-          amount = offsets->locals_base - offsets->saved_regs;
-          if (amount)
-            emit_insn (gen_addsi3 (hard_frame_pointer_rtx,
-                                   hard_frame_pointer_rtx,
-                                   GEN_INT (amount)));
+	  amount = offsets->locals_base - offsets->saved_regs;
+	  if (amount)
+	    {
+	      insn = emit_insn (gen_addsi3 (hard_frame_pointer_rtx,
+				hard_frame_pointer_rtx,
+				GEN_INT (amount)));
+	      arm_add_cfa_adjust_cfa_note (insn, amount,
+					   hard_frame_pointer_rtx,
+					   hard_frame_pointer_rtx);
+	    }
 
           /* Force out any pending memory operations that reference stacked data
              before stack de-allocation occurs.  */
           emit_insn (gen_blockage ());
-          emit_insn (gen_movsi (stack_pointer_rtx, hard_frame_pointer_rtx));
+	  insn = emit_insn (gen_movsi (stack_pointer_rtx,
+				       hard_frame_pointer_rtx));
+	  arm_add_cfa_adjust_cfa_note (insn, 0,
+				       stack_pointer_rtx,
+				       hard_frame_pointer_rtx);
           /* Emit USE(stack_pointer_rtx) to ensure that stack adjustment is not
              deleted.  */
           emit_insn (gen_force_register_use (stack_pointer_rtx));
@@ -23668,12 +24396,15 @@ arm_expand_epilogue (bool really_return)
       amount = offsets->outgoing_args - offsets->saved_regs;
       if (amount)
         {
+	  rtx tmp;
           /* Force out any pending memory operations that reference stacked data
              before stack de-allocation occurs.  */
           emit_insn (gen_blockage ());
-          emit_insn (gen_addsi3 (stack_pointer_rtx,
-                                 stack_pointer_rtx,
-                                 GEN_INT (amount)));
+	  tmp = emit_insn (gen_addsi3 (stack_pointer_rtx,
+				       stack_pointer_rtx,
+				       GEN_INT (amount)));
+	  arm_add_cfa_adjust_cfa_note (tmp, amount,
+				       stack_pointer_rtx, stack_pointer_rtx);
           /* Emit USE(stack_pointer_rtx) to ensure that stack adjustment is
              not deleted.  */
           emit_insn (gen_force_register_use (stack_pointer_rtx));
@@ -23726,6 +24457,8 @@ arm_expand_epilogue (bool really_return)
           REG_NOTES (insn) = alloc_reg_note (REG_CFA_RESTORE,
                                              gen_rtx_REG (V2SImode, i),
                                              NULL_RTX);
+	  arm_add_cfa_adjust_cfa_note (insn, UNITS_PER_WORD,
+				       stack_pointer_rtx, stack_pointer_rtx);
         }
 
   if (saved_regs_mask)
@@ -23773,6 +24506,9 @@ arm_expand_epilogue (bool really_return)
                     REG_NOTES (insn) = alloc_reg_note (REG_CFA_RESTORE,
                                                        gen_rtx_REG (SImode, i),
                                                        NULL_RTX);
+		    arm_add_cfa_adjust_cfa_note (insn, UNITS_PER_WORD,
+						 stack_pointer_rtx,
+						 stack_pointer_rtx);
                   }
               }
         }
@@ -23783,6 +24519,8 @@ arm_expand_epilogue (bool really_return)
             {
               if (TARGET_THUMB2)
                 thumb2_emit_ldrd_pop (saved_regs_mask);
+              else if (TARGET_ARM && !IS_INTERRUPT (func_type))
+                arm_emit_ldrd_pop (saved_regs_mask);
               else
                 arm_emit_multi_reg_pop (saved_regs_mask);
             }
@@ -23795,9 +24533,33 @@ arm_expand_epilogue (bool really_return)
     }
 
   if (crtl->args.pretend_args_size)
-    emit_insn (gen_addsi3 (stack_pointer_rtx,
-                           stack_pointer_rtx,
-                           GEN_INT (crtl->args.pretend_args_size)));
+    {
+      int i, j;
+      rtx dwarf = NULL_RTX;
+      rtx tmp = emit_insn (gen_addsi3 (stack_pointer_rtx,
+			   stack_pointer_rtx,
+			   GEN_INT (crtl->args.pretend_args_size)));
+
+      RTX_FRAME_RELATED_P (tmp) = 1;
+
+      if (cfun->machine->uses_anonymous_args)
+	{
+	  /* Restore pretend args.  Refer arm_expand_prologue on how to save
+	     pretend_args in stack.  */
+	  int num_regs = crtl->args.pretend_args_size / 4;
+	  saved_regs_mask = (0xf0 >> num_regs) & 0xf;
+	  for (j = 0, i = 0; j < num_regs; i++)
+	    if (saved_regs_mask & (1 << i))
+	      {
+		rtx reg = gen_rtx_REG (SImode, i);
+		dwarf = alloc_reg_note (REG_CFA_RESTORE, reg, dwarf);
+		j++;
+	      }
+	  REG_NOTES (tmp) = dwarf;
+	}
+      arm_add_cfa_adjust_cfa_note (tmp, crtl->args.pretend_args_size,
+				   stack_pointer_rtx, stack_pointer_rtx);
+    }
 
   if (!really_return)
     return;
@@ -25214,9 +25976,8 @@ arm_dwarf_register_span (rtx rtl)
 
   nregs = GET_MODE_SIZE (GET_MODE (rtl)) / 8;
   p = gen_rtx_PARALLEL (VOIDmode, rtvec_alloc (nregs));
-  regno = (regno - FIRST_VFP_REGNUM) / 2;
   for (i = 0; i < nregs; i++)
-    XVECEXP (p, 0, i) = gen_rtx_REG (DImode, 256 + regno + i);
+    XVECEXP (p, 0, i) = gen_rtx_REG (DImode, regno + i);
 
   return p;
 }
@@ -25466,9 +26227,17 @@ arm_unwind_emit (FILE * asm_out_file, rtx insn)
 	  handled_one = true;
 	  break;
 
+	/* The INSN is generated in epilogue.  It is set as RTX_FRAME_RELATED_P
+	   to get correct dwarf information for shrink-wrap.  We should not
+	   emit unwind information for it because these are used either for
+	   pretend arguments or notes to adjust sp and restore registers from
+	   stack.  */
+	case REG_CFA_ADJUST_CFA:
+	case REG_CFA_RESTORE:
+	  return;
+
 	case REG_CFA_DEF_CFA:
 	case REG_CFA_EXPRESSION:
-	case REG_CFA_ADJUST_CFA:
 	case REG_CFA_OFFSET:
 	  /* ??? Only handling here what we actually emit.  */
 	  gcc_unreachable ();
@@ -25795,7 +26564,7 @@ arm_output_iwmmxt_tinsr (rtx *operands)
 const char *
 thumb1_output_casesi (rtx *operands)
 {
-  rtx diff_vec = PATTERN (next_real_insn (operands[0]));
+  rtx diff_vec = PATTERN (next_active_insn (operands[0]));
 
   gcc_assert (GET_CODE (diff_vec) == ADDR_DIFF_VEC);
 
@@ -25818,7 +26587,7 @@ thumb1_output_casesi (rtx *operands)
 const char *
 thumb2_output_casesi (rtx *operands)
 {
-  rtx diff_vec = PATTERN (next_real_insn (operands[2]));
+  rtx diff_vec = PATTERN (next_active_insn (operands[2]));
 
   gcc_assert (GET_CODE (diff_vec) == ADDR_DIFF_VEC);
 
@@ -25866,6 +26635,7 @@ arm_issue_rate (void)
     case cortexa7:
     case cortexa8:
     case cortexa9:
+    case cortexa53:
     case fa726te:
     case marvell_pj4:
       return 2;
@@ -25921,7 +26691,29 @@ arm_mangle_type (const_tree type)
      has to be managled as if it is in the "std" namespace.  */
   if (TARGET_AAPCS_BASED
       && lang_hooks.types_compatible_p (CONST_CAST_TREE (type), va_list_type))
-    return "St9__va_list";
+    {
+  /* Disable this obsolete warning for Android, because none of the exposed APIs
+     by NDK is impacted by this change of ARM ABI. This warning can be triggered
+     very easily by compiling the following code using arm-linux-androideabi-g++:
+
+         typedef __builtin_va_list __gnuc_va_list;
+         typedef __gnuc_va_list va_list;
+         void foo(va_list v) { }
+
+     We could advise developer to add "-Wno-psabi", but doing so also categorically
+     deny other cases guarded by "warn_psabi".  Hence the decision to disable it
+     case by case here.
+
+      static bool warned;
+      if (!warned && warn_psabi && !in_system_header)
+        {
+          warned = true;
+          inform (input_location,
+                  "the mangling of %<va_list%> has changed in GCC 4.4");
+        }
+   */
+      return "St9__va_list";
+    }
 
   /* Half-precision float.  */
   if (TREE_CODE (type) == REAL_TYPE && TYPE_PRECISION (type) == 16)
@@ -25992,6 +26784,60 @@ arm_have_conditional_execution (void)
   return !TARGET_THUMB1;
 }
 
+tree
+arm_builtin_vectorized_function (tree fndecl, tree type_out, tree type_in)
+{
+  enum machine_mode in_mode, out_mode;
+  int in_n, out_n;
+
+  if (TREE_CODE (type_out) != VECTOR_TYPE
+      || TREE_CODE (type_in) != VECTOR_TYPE
+      || !(TARGET_NEON && TARGET_FPU_ARMV8 && flag_unsafe_math_optimizations))
+    return NULL_TREE;
+
+  out_mode = TYPE_MODE (TREE_TYPE (type_out));
+  out_n = TYPE_VECTOR_SUBPARTS (type_out);
+  in_mode = TYPE_MODE (TREE_TYPE (type_in));
+  in_n = TYPE_VECTOR_SUBPARTS (type_in);
+
+/* ARM_CHECK_BUILTIN_MODE and ARM_FIND_VRINT_VARIANT are used to find the
+   decl of the vectorized builtin for the appropriate vector mode.
+   NULL_TREE is returned if no such builtin is available.  */
+#undef ARM_CHECK_BUILTIN_MODE
+#define ARM_CHECK_BUILTIN_MODE(C) \
+  (out_mode == SFmode && out_n == C \
+   && in_mode == SFmode && in_n == C)
+
+#undef ARM_FIND_VRINT_VARIANT
+#define ARM_FIND_VRINT_VARIANT(N) \
+  (ARM_CHECK_BUILTIN_MODE (2) \
+    ? arm_builtin_decl(ARM_BUILTIN_NEON_##N##v2sf, false) \
+    : (ARM_CHECK_BUILTIN_MODE (4) \
+      ? arm_builtin_decl(ARM_BUILTIN_NEON_##N##v4sf, false) \
+      : NULL_TREE))
+
+  if (DECL_BUILT_IN_CLASS (fndecl) == BUILT_IN_NORMAL)
+    {
+      enum built_in_function fn = DECL_FUNCTION_CODE (fndecl);
+      switch (fn)
+        {
+          case BUILT_IN_FLOORF:
+            return ARM_FIND_VRINT_VARIANT (vrintm);
+          case BUILT_IN_CEILF:
+            return ARM_FIND_VRINT_VARIANT (vrintp);
+          case BUILT_IN_TRUNCF:
+            return ARM_FIND_VRINT_VARIANT (vrintz);
+          case BUILT_IN_ROUNDF:
+            return ARM_FIND_VRINT_VARIANT (vrinta);
+          default:
+            return NULL_TREE;
+        }
+    }
+  return NULL_TREE;
+}
+#undef ARM_CHECK_BUILTIN_MODE
+#undef ARM_FIND_VRINT_VARIANT
+
 /* The AAPCS sets the maximum alignment of a vector to 64 bits.  */
 static HOST_WIDE_INT
 arm_vector_alignment (const_tree type)
@@ -26222,39 +27068,71 @@ arm_post_atomic_barrier (enum memmodel model)
     emit_insn (gen_memory_barrier ());
 }
 
-/* Emit the load-exclusive and store-exclusive instructions.  */
+/* Emit the load-exclusive and store-exclusive instructions.
+   Use acquire and release versions if necessary.  */
 
 static void
-arm_emit_load_exclusive (enum machine_mode mode, rtx rval, rtx mem)
+arm_emit_load_exclusive (enum machine_mode mode, rtx rval, rtx mem, bool acq)
 {
   rtx (*gen) (rtx, rtx);
 
-  switch (mode)
+  if (acq)
     {
-    case QImode: gen = gen_arm_load_exclusiveqi; break;
-    case HImode: gen = gen_arm_load_exclusivehi; break;
-    case SImode: gen = gen_arm_load_exclusivesi; break;
-    case DImode: gen = gen_arm_load_exclusivedi; break;
-    default:
-      gcc_unreachable ();
+      switch (mode)
+        {
+        case QImode: gen = gen_arm_load_acquire_exclusiveqi; break;
+        case HImode: gen = gen_arm_load_acquire_exclusivehi; break;
+        case SImode: gen = gen_arm_load_acquire_exclusivesi; break;
+        case DImode: gen = gen_arm_load_acquire_exclusivedi; break;
+        default:
+          gcc_unreachable ();
+        }
+    }
+  else
+    {
+      switch (mode)
+        {
+        case QImode: gen = gen_arm_load_exclusiveqi; break;
+        case HImode: gen = gen_arm_load_exclusivehi; break;
+        case SImode: gen = gen_arm_load_exclusivesi; break;
+        case DImode: gen = gen_arm_load_exclusivedi; break;
+        default:
+          gcc_unreachable ();
+        }
     }
 
   emit_insn (gen (rval, mem));
 }
 
 static void
-arm_emit_store_exclusive (enum machine_mode mode, rtx bval, rtx rval, rtx mem)
+arm_emit_store_exclusive (enum machine_mode mode, rtx bval, rtx rval,
+                          rtx mem, bool rel)
 {
   rtx (*gen) (rtx, rtx, rtx);
 
-  switch (mode)
+  if (rel)
     {
-    case QImode: gen = gen_arm_store_exclusiveqi; break;
-    case HImode: gen = gen_arm_store_exclusivehi; break;
-    case SImode: gen = gen_arm_store_exclusivesi; break;
-    case DImode: gen = gen_arm_store_exclusivedi; break;
-    default:
-      gcc_unreachable ();
+      switch (mode)
+        {
+        case QImode: gen = gen_arm_store_release_exclusiveqi; break;
+        case HImode: gen = gen_arm_store_release_exclusivehi; break;
+        case SImode: gen = gen_arm_store_release_exclusivesi; break;
+        case DImode: gen = gen_arm_store_release_exclusivedi; break;
+        default:
+          gcc_unreachable ();
+        }
+    }
+  else
+    {
+      switch (mode)
+        {
+        case QImode: gen = gen_arm_store_exclusiveqi; break;
+        case HImode: gen = gen_arm_store_exclusivehi; break;
+        case SImode: gen = gen_arm_store_exclusivesi; break;
+        case DImode: gen = gen_arm_store_exclusivedi; break;
+        default:
+          gcc_unreachable ();
+        }
     }
 
   emit_insn (gen (bval, rval, mem));
@@ -26290,6 +27168,15 @@ arm_expand_compare_and_swap (rtx operands[])
   mod_f = operands[7];
   mode = GET_MODE (mem);
 
+  /* Normally the succ memory model must be stronger than fail, but in the
+     unlikely event of fail being ACQUIRE and succ being RELEASE we need to
+     promote succ to ACQ_REL so that we don't lose the acquire semantics.  */
+
+  if (TARGET_HAVE_LDACQ
+      && INTVAL (mod_f) == MEMMODEL_ACQUIRE
+      && INTVAL (mod_s) == MEMMODEL_RELEASE)
+    mod_s = GEN_INT (MEMMODEL_ACQ_REL);
+
   switch (mode)
     {
     case QImode:
@@ -26364,7 +27251,19 @@ arm_split_compare_and_swap (rtx operands[])
   scratch = operands[7];
   mode = GET_MODE (mem);
 
-  arm_pre_atomic_barrier (mod_s);
+  bool use_acquire = TARGET_HAVE_LDACQ
+                     && !(mod_s == MEMMODEL_RELAXED
+                          || mod_s == MEMMODEL_CONSUME
+                          || mod_s == MEMMODEL_RELEASE);
+
+  bool use_release = TARGET_HAVE_LDACQ
+                     && !(mod_s == MEMMODEL_RELAXED
+                          || mod_s == MEMMODEL_CONSUME
+                          || mod_s == MEMMODEL_ACQUIRE);
+
+  /* Checks whether a barrier is needed and emits one accordingly.  */
+  if (!(use_acquire || use_release))
+    arm_pre_atomic_barrier (mod_s);
 
   label1 = NULL_RTX;
   if (!is_weak)
@@ -26374,7 +27273,7 @@ arm_split_compare_and_swap (rtx operands[])
     }
   label2 = gen_label_rtx ();
 
-  arm_emit_load_exclusive (mode, rval, mem);
+  arm_emit_load_exclusive (mode, rval, mem, use_acquire);
 
   cond = arm_gen_compare_reg (NE, rval, oldval, scratch);
   x = gen_rtx_NE (VOIDmode, cond, const0_rtx);
@@ -26382,7 +27281,7 @@ arm_split_compare_and_swap (rtx operands[])
 			    gen_rtx_LABEL_REF (Pmode, label2), pc_rtx);
   emit_unlikely_jump (gen_rtx_SET (VOIDmode, pc_rtx, x));
 
-  arm_emit_store_exclusive (mode, scratch, mem, newval);
+  arm_emit_store_exclusive (mode, scratch, mem, newval, use_release);
 
   /* Weak or strong, we want EQ to be true for success, so that we
      match the flags that we got from the compare above.  */
@@ -26401,7 +27300,9 @@ arm_split_compare_and_swap (rtx operands[])
   if (mod_f != MEMMODEL_RELAXED)
     emit_label (label2);
 
-  arm_post_atomic_barrier (mod_s);
+  /* Checks whether a barrier is needed and emits one accordingly.  */
+  if (!(use_acquire || use_release))
+    arm_post_atomic_barrier (mod_s);
 
   if (mod_f == MEMMODEL_RELAXED)
     emit_label (label2);
@@ -26416,7 +27317,19 @@ arm_split_atomic_op (enum rtx_code code, rtx old_out, rtx new_out, rtx mem,
   enum machine_mode wmode = (mode == DImode ? DImode : SImode);
   rtx label, x;
 
-  arm_pre_atomic_barrier (model);
+  bool use_acquire = TARGET_HAVE_LDACQ
+                     && !(model == MEMMODEL_RELAXED
+                          || model == MEMMODEL_CONSUME
+                          || model == MEMMODEL_RELEASE);
+
+  bool use_release = TARGET_HAVE_LDACQ
+                     && !(model == MEMMODEL_RELAXED
+                          || model == MEMMODEL_CONSUME
+                          || model == MEMMODEL_ACQUIRE);
+
+  /* Checks whether a barrier is needed and emits one accordingly.  */
+  if (!(use_acquire || use_release))
+    arm_pre_atomic_barrier (model);
 
   label = gen_label_rtx ();
   emit_label (label);
@@ -26429,7 +27342,7 @@ arm_split_atomic_op (enum rtx_code code, rtx old_out, rtx new_out, rtx mem,
     old_out = new_out;
   value = simplify_gen_subreg (wmode, value, mode, 0);
 
-  arm_emit_load_exclusive (mode, old_out, mem);
+  arm_emit_load_exclusive (mode, old_out, mem, use_acquire);
 
   switch (code)
     {
@@ -26477,12 +27390,15 @@ arm_split_atomic_op (enum rtx_code code, rtx old_out, rtx new_out, rtx mem,
       break;
     }
 
-  arm_emit_store_exclusive (mode, cond, mem, gen_lowpart (mode, new_out));
+  arm_emit_store_exclusive (mode, cond, mem, gen_lowpart (mode, new_out),
+                            use_release);
 
   x = gen_rtx_NE (VOIDmode, cond, const0_rtx);
   emit_unlikely_jump (gen_cbranchsi4 (x, cond, const0_rtx, label));
 
-  arm_post_atomic_barrier (model);
+  /* Checks whether a barrier is needed and emits one accordingly.  */
+  if (!(use_acquire || use_release))
+    arm_post_atomic_barrier (model);
 }
 
 #define MAX_VECT_LEN 16
@@ -27422,4 +28338,12 @@ arm_validize_comparison (rtx *comparison, rtx * op1, rtx * op2)
 
 }
 
+/* Implement the TARGET_ASAN_SHADOW_OFFSET hook.  */
+
+static unsigned HOST_WIDE_INT
+arm_asan_shadow_offset (void)
+{
+  return (unsigned HOST_WIDE_INT) 1 << 29;
+}
+
 #include "gt-arm.h"
diff --git a/gcc/config/arm/arm.h b/gcc/config/arm/arm.h
index 05aea35..10cd737 100644
--- a/gcc/config/arm/arm.h
+++ b/gcc/config/arm/arm.h
@@ -183,6 +183,11 @@ extern arm_cc arm_current_cc;
 
 #define ARM_INVERSE_CONDITION_CODE(X)  ((arm_cc) (((int)X) ^ 1))
 
+/* The maximaum number of instructions that is beneficial to
+   conditionally execute. */
+#undef MAX_CONDITIONAL_EXECUTE
+#define MAX_CONDITIONAL_EXECUTE arm_max_conditional_execute ()
+
 extern int arm_target_label;
 extern int arm_ccfsm_state;
 extern GTY(()) rtx arm_target_insn;
@@ -350,10 +355,16 @@ extern void (*arm_lang_output_object_attributes_hook)(void);
 #define TARGET_HAVE_LDREXD	(((arm_arch6k && TARGET_ARM) || arm_arch7) \
 				 && arm_arch_notm)
 
+/* Nonzero if this chip supports load-acquire and store-release.  */
+#define TARGET_HAVE_LDACQ	(TARGET_ARM_ARCH >= 8)
+
 /* Nonzero if integer division instructions supported.  */
 #define TARGET_IDIV		((TARGET_ARM && arm_arch_arm_hwdiv) \
 				 || (TARGET_THUMB2 && arm_arch_thumb_hwdiv))
 
+/* Should NEON be used for 64-bits bitops.  */
+#define TARGET_PREFER_NEON_64BITS (prefer_neon_for_64bits)
+
 /* True iff the full BPABI is being used.  If TARGET_BPABI is true,
    then TARGET_AAPCS_BASED must be true -- but the converse does not
    hold.  TARGET_BPABI implies the use of the BPABI runtime library,
@@ -539,6 +550,10 @@ extern int arm_arch_arm_hwdiv;
 /* Nonzero if chip supports integer division instruction in Thumb mode.  */
 extern int arm_arch_thumb_hwdiv;
 
+/* Nonzero if we should use Neon to handle 64-bits operations rather
+   than core registers.  */
+extern int prefer_neon_for_64bits;
+
 #ifndef TARGET_DEFAULT
 #define TARGET_DEFAULT  (MASK_APCS_FRAME)
 #endif
@@ -945,6 +960,8 @@ extern int arm_arch_thumb_hwdiv;
 
 #define FIRST_IWMMXT_REGNUM	(LAST_HI_VFP_REGNUM + 1)
 #define LAST_IWMMXT_REGNUM	(FIRST_IWMMXT_REGNUM + 15)
+
+/* Need to sync with WCGR in iwmmxt.md.  */
 #define FIRST_IWMMXT_GR_REGNUM	(LAST_IWMMXT_REGNUM + 1)
 #define LAST_IWMMXT_GR_REGNUM	(FIRST_IWMMXT_GR_REGNUM + 3)
 
@@ -1130,6 +1147,7 @@ enum reg_class
   STACK_REG,
   BASE_REGS,
   HI_REGS,
+  CALLER_SAVE_REGS,
   GENERAL_REGS,
   CORE_REGS,
   VFP_D0_D7_REGS,
@@ -1156,6 +1174,7 @@ enum reg_class
   "STACK_REG",		\
   "BASE_REGS",		\
   "HI_REGS",		\
+  "CALLER_SAVE_REGS",	\
   "GENERAL_REGS",	\
   "CORE_REGS",		\
   "VFP_D0_D7_REGS",	\
@@ -1181,6 +1200,7 @@ enum reg_class
   { 0x00002000, 0x00000000, 0x00000000, 0x00000000 }, /* STACK_REG */	\
   { 0x000020FF, 0x00000000, 0x00000000, 0x00000000 }, /* BASE_REGS */	\
   { 0x00005F00, 0x00000000, 0x00000000, 0x00000000 }, /* HI_REGS */	\
+  { 0x0000100F, 0x00000000, 0x00000000, 0x00000000 }, /* CALLER_SAVE_REGS */ \
   { 0x00005FFF, 0x00000000, 0x00000000, 0x00000000 }, /* GENERAL_REGS */ \
   { 0x00007FFF, 0x00000000, 0x00000000, 0x00000000 }, /* CORE_REGS */	\
   { 0xFFFF0000, 0x00000000, 0x00000000, 0x00000000 }, /* VFP_D0_D7_REGS  */ \
@@ -1193,7 +1213,7 @@ enum reg_class
   { 0x00000000, 0x00000000, 0x00000000, 0x00000020 }, /* VFPCC_REG */	\
   { 0x00000000, 0x00000000, 0x00000000, 0x00000040 }, /* SFP_REG */	\
   { 0x00000000, 0x00000000, 0x00000000, 0x00000080 }, /* AFP_REG */	\
-  { 0xFFFF7FFF, 0xFFFFFFFF, 0xFFFFFFFF, 0x00000000 }  /* ALL_REGS */	\
+  { 0xFFFF7FFF, 0xFFFFFFFF, 0xFFFFFFFF, 0x0000000F }  /* ALL_REGS */	\
 }
 
 /* Any of the VFP register classes.  */
@@ -1639,7 +1659,7 @@ typedef struct
    frame.  */
 #define EXIT_IGNORE_STACK 1
 
-#define EPILOGUE_USES(REGNO) ((REGNO) == LR_REGNUM)
+#define EPILOGUE_USES(REGNO) (epilogue_completed && (REGNO) == LR_REGNUM)
 
 /* Determine if the epilogue should be output as RTL.
    You should override this if you define FUNCTION_EXTRA_EPILOGUE.  */
diff --git a/gcc/config/arm/arm.md b/gcc/config/arm/arm.md
index f3c59f3..2bdf0dd 100644
--- a/gcc/config/arm/arm.md
+++ b/gcc/config/arm/arm.md
@@ -22,6 +22,25 @@
 
 ;;- See file "rtl.def" for documentation on define_insn, match_*, et. al.
 
+;; Beware of splitting Thumb1 patterns that output multiple
+;; assembly instructions, in particular instruction such as SBC and
+;; ADC which consume flags.  For example, in the pattern thumb_subdi3
+;; below, the output SUB implicitly sets the flags (assembled to SUBS)
+;; and then the Carry flag is used by SBC to compute the correct
+;; result.  If we split thumb_subdi3 pattern into two separate RTL
+;; insns (using define_insn_and_split), the scheduler might place
+;; other RTL insns between SUB and SBC, possibly modifying the Carry
+;; flag used by SBC.  This might happen because most Thumb1 patterns
+;; for flag-setting instructions do not have explicit RTL for setting
+;; or clobbering the flags.  Instead, they have the attribute "conds"
+;; with value "set" or "clob".  However, this attribute is not used to
+;; identify dependencies and therefore the scheduler might reorder
+;; these instruction.  Currenly, this problem cannot happen because
+;; there are no separate Thumb1 patterns for individual instruction
+;; that consume flags (except conditional execution, which is treated
+;; differently).  In particular there is no Thumb1 armv6-m pattern for
+;; sbc or adc.
+
 
 ;;---------------------------------------------------------------------------
 ;; Constants
@@ -94,7 +113,7 @@
 ; for ARM or Thumb-2 with arm_arch6, and nov6 for ARM without
 ; arm_arch6.  This attribute is used to compute attribute "enabled",
 ; use type "any" to enable an alternative in all cases.
-(define_attr "arch" "any,a,t,32,t1,t2,v6,nov6,onlya8,neon_onlya8,nota8,neon_nota8,iwmmxt,iwmmxt2"
+(define_attr "arch" "any,a,t,32,t1,t2,v6,nov6,neon_for_64bits,avoid_neon_for_64bits,iwmmxt,iwmmxt2"
   (const_string "any"))
 
 (define_attr "arch_enabled" "no,yes"
@@ -129,22 +148,14 @@
 	      (match_test "TARGET_32BIT && !arm_arch6"))
 	 (const_string "yes")
 
-	 (and (eq_attr "arch" "onlya8")
-	      (eq_attr "tune" "cortexa8"))
-	 (const_string "yes")
-
-	 (and (eq_attr "arch" "neon_onlya8")
-	      (eq_attr "tune" "cortexa8")
-	      (match_test "TARGET_NEON"))
+	 (and (eq_attr "arch" "avoid_neon_for_64bits")
+	      (match_test "TARGET_NEON")
+	      (not (match_test "TARGET_PREFER_NEON_64BITS")))
 	 (const_string "yes")
 
-	 (and (eq_attr "arch" "nota8")
-	      (not (eq_attr "tune" "cortexa8")))
-	 (const_string "yes")
-
-	 (and (eq_attr "arch" "neon_nota8")
-	      (not (eq_attr "tune" "cortexa8"))
-	      (match_test "TARGET_NEON"))
+	 (and (eq_attr "arch" "neon_for_64bits")
+	      (match_test "TARGET_NEON")
+	      (match_test "TARGET_PREFER_NEON_64BITS"))
 	 (const_string "yes")
 
 	 (and (eq_attr "arch" "iwmmxt2")
@@ -219,53 +230,155 @@
 ;; scheduling information.
 
 (define_attr "insn"
-        "mov,mvn,smulxy,smlaxy,smlalxy,smulwy,smlawx,mul,muls,mla,mlas,umull,umulls,umlal,umlals,smull,smulls,smlal,smlals,smlawy,smuad,smuadx,smlad,smladx,smusd,smusdx,smlsd,smlsdx,smmul,smmulr,smmla,umaal,smlald,smlsld,clz,mrs,msr,xtab,sdiv,udiv,sat,other"
+        "mov,mvn,clz,mrs,msr,xtab,sat,other"
         (const_string "other"))
 
-; TYPE attribute is used to detect floating point instructions which, if
-; running on a co-processor can run in parallel with other, basic instructions
-; If write-buffer scheduling is enabled then it can also be used in the
-; scheduling of writes.
-
-; Classification of each insn
-; Note: vfp.md has different meanings for some of these, and some further
-; types as well.  See that file for details.
-; simple_alu_imm  a simple alu instruction that doesn't hit memory or fp
-;               regs or have a shifted source operand and has an immediate
-;               operand. This currently only tracks very basic immediate
-;               alu operations.
-; alu_reg       any alu instruction that doesn't hit memory or fp
-;               regs or have a shifted source operand
-;               and does not have an immediate operand. This is
-;               also the default
-; simple_alu_shift covers UXTH, UXTB, SXTH, SXTB
-; alu_shift	any data instruction that doesn't hit memory or fp
-;		regs, but has a source operand shifted by a constant
-; alu_shift_reg	any data instruction that doesn't hit memory or fp
-;		regs, but has a source operand shifted by a register value
-; mult		a multiply instruction
-; block		blockage insn, this blocks all functional units
-; float		a floating point arithmetic operation (subject to expansion)
-; fdivd		DFmode floating point division
-; fdivs		SFmode floating point division
-; f_load[sd]	A single/double load from memory. Used for VFP unit.
-; f_store[sd]	A single/double store to memory. Used for VFP unit.
-; f_flag	a transfer of co-processor flags to the CPSR
-; f_2_r		transfer float to core (no memory needed)
-; r_2_f		transfer core to float
-; f_cvt		convert floating<->integral
-; branch	a branch
-; call		a subroutine call
-; load_byte	load byte(s) from memory to arm registers
-; load1		load 1 word from memory to arm registers
-; load2         load 2 words from memory to arm registers
-; load3         load 3 words from memory to arm registers
-; load4         load 4 words from memory to arm registers
-; store		store 1 word to memory from arm registers
-; store2	store 2 words
-; store3	store 3 words
-; store4	store 4 (or more) words
+; TYPE attribute is used to classify instructions for use in scheduling.
+;
+; Instruction classification:
 ;
+; alu_reg            any alu instruction that doesn't hit memory or fp
+;                    regs or have a shifted source operand and does not have
+;                    an immediate operand.  This is also the default.
+; alu_shift          any data instruction that doesn't hit memory or fp.
+;                    regs, but has a source operand shifted by a constant.
+; alu_shift_reg      any data instruction that doesn't hit memory or fp.
+; block              blockage insn, this blocks all functional units.
+; branch             branch.
+; call               subroutine call.
+; f_2_r              transfer from float to core (no memory needed).
+; f_cvt              conversion between float and integral.
+; f_flag             transfer of co-processor flags to the CPSR.
+; f_load[d,s]        double/single load from memory.  Used for VFP unit.
+; f_minmax[d,s]      double/single floating point minimum/maximum.
+; f_rint[d,s]        double/single floating point rount to integral.
+; f_sel[d,s]         double/single floating byte select.
+; f_store[d,s]       double/single store to memory.  Used for VFP unit.
+; fadd[d,s]          double/single floating-point scalar addition.
+; fcmp[d,s]          double/single floating-point compare.
+; fconst[d,s]        double/single load immediate.
+; fcpys              single precision floating point cpy.
+; fdiv[d,s]          double/single precision floating point division.
+; ffarith[d,s]       double/single floating point abs/neg/cpy.
+; ffma[d,s]          double/single floating point fused multiply-accumulate.
+; float              floating point arithmetic operation.
+; fmac[d,s]          double/single floating point multiply-accumulate.
+; fmul[d,s]          double/single floating point multiply.
+; load_byte          load byte(s) from memory to arm registers.
+; load1              load 1 word from memory to arm registers.
+; load2              load 2 words from memory to arm registers.
+; load3              load 3 words from memory to arm registers.
+; load4              load 4 words from memory to arm registers.
+; mla                integer multiply accumulate.
+; mlas               integer multiply accumulate, flag setting.
+; mov                integer move.
+; mul                integer multiply.
+; muls               integer multiply, flag setting.
+; r_2_f              transfer from core to float.
+; sdiv               signed division.
+; simple_alu_imm     simple alu instruction that doesn't hit memory or fp
+;                    regs or have a shifted source operand and has an
+;                    immediate operand.  This currently only tracks very basic
+;                    immediate alu operations.
+; simple_alu_shift   simple alu instruction with a shifted source operand.
+; smlad              signed multiply accumulate dual.
+; smladx             signed multiply accumulate dual reverse.
+; smlal              signed multiply accumulate long.
+; smlald             signed multiply accumulate long dual.
+; smlals             signed multiply accumulate long, flag setting.
+; smlalxy            signed multiply accumulate, 16x16-bit, 64-bit accumulate.
+; smlawx             signed multiply accumulate, 32x16-bit, 32-bit accumulate.
+; smlawy             signed multiply accumulate wide, 32x16-bit,
+;                    32-bit accumulate.
+; smlaxy             signed multiply accumulate, 16x16-bit, 32-bit accumulate.
+; smlsd              signed multiply subtract dual.
+; smlsdx             signed multiply subtract dual reverse.
+; smlsld             signed multiply subtract long dual.
+; smmla              signed most significant word multiply accumulate.
+; smmul              signed most significant word multiply.
+; smmulr             signed most significant word multiply, rounded.
+; smuad              signed dual multiply add.
+; smuadx             signed dual multiply add reverse.
+; smull              signed multiply long.
+; smulls             signed multiply long, flag setting.
+; smulwy             signed multiply wide, 32x16-bit, 32-bit accumulate.
+; smulxy             signed multiply, 16x16-bit, 32-bit accumulate.
+; smusd              signed dual multiply subtract.
+; smusdx             signed dual multiply subtract reverse.
+; store1             store 1 word to memory from arm registers.
+; store2             store 2 words to memory from arm registers.
+; store3             store 3 words to memory from arm registers.
+; store4             store 4 (or more) words to memory from arm registers.
+; udiv               unsigned division.
+; umaal              unsigned multiply accumulate accumulate long.
+; umlal              unsigned multiply accumulate long.
+; umlals             unsigned multiply accumulate long, flag setting.
+; umull              unsigned multiply long.
+; umulls             unsigned multiply long, flag setting.
+;
+; The classification below is for instructions used by the Wireless MMX
+; Technology. Each attribute value is used to classify an instruction of the
+; same name or family.
+;
+; wmmx_tandc
+; wmmx_tbcst
+; wmmx_textrc
+; wmmx_textrm
+; wmmx_tinsr
+; wmmx_tmcr
+; wmmx_tmcrr
+; wmmx_tmia
+; wmmx_tmiaph
+; wmmx_tmiaxy
+; wmmx_tmrc
+; wmmx_tmrrc
+; wmmx_tmovmsk
+; wmmx_torc
+; wmmx_torvsc
+; wmmx_wabs
+; wmmx_wdiff
+; wmmx_wacc
+; wmmx_wadd
+; wmmx_waddbhus
+; wmmx_waddsubhx
+; wmmx_waligni
+; wmmx_walignr
+; wmmx_wand
+; wmmx_wandn
+; wmmx_wavg2
+; wmmx_wavg4
+; wmmx_wcmpeq
+; wmmx_wcmpgt
+; wmmx_wmac
+; wmmx_wmadd
+; wmmx_wmax
+; wmmx_wmerge
+; wmmx_wmiawxy
+; wmmx_wmiaxy
+; wmmx_wmin
+; wmmx_wmov
+; wmmx_wmul
+; wmmx_wmulw
+; wmmx_wldr
+; wmmx_wor
+; wmmx_wpack
+; wmmx_wqmiaxy
+; wmmx_wqmulm
+; wmmx_wqmulwm
+; wmmx_wror
+; wmmx_wsad
+; wmmx_wshufh
+; wmmx_wsll
+; wmmx_wsra
+; wmmx_wsrl
+; wmmx_wstr
+; wmmx_wsub
+; wmmx_wsubaddhx
+; wmmx_wunpckeh
+; wmmx_wunpckel
+; wmmx_wunpckih
+; wmmx_wunpckil
+; wmmx_wxor
 
 (define_attr "type"
  "simple_alu_imm,\
@@ -273,7 +386,6 @@
   simple_alu_shift,\
   alu_shift,\
   alu_shift_reg,\
-  mult,\
   block,\
   float,\
   fdivd,\
@@ -296,6 +408,8 @@
   f_2_r,\
   r_2_f,\
   f_cvt,\
+  f_sels,\
+  f_seld,\
   branch,\
   call,\
   load_byte,\
@@ -315,25 +429,119 @@
   ffarithd,\
   fcmps,\
   fcmpd,\
-  fcpys"
- (if_then_else 
-    (eq_attr "insn" "smulxy,smlaxy,smlalxy,smulwy,smlawx,mul,muls,mla,mlas,\
-	     	     umull,umulls,umlal,umlals,smull,smulls,smlal,smlals")
-    (const_string "mult")
-    (const_string "alu_reg")))
+  fcpys,\
+  smulxy,\
+  smlaxy,\
+  smlalxy,\
+  smulwy,\
+  smlawx,\
+  mul,\
+  muls,\
+  mla,\
+  mlas,\
+  umull,\
+  umulls,\
+  umlal,\
+  umlals,\
+  smull,\
+  smulls,\
+  smlal,\
+  smlals,\
+  smlawy,\
+  smuad,\
+  smuadx,\
+  smlad,\
+  smladx,\
+  smusd,\
+  smusdx,\
+  smlsd,\
+  smlsdx,\
+  smmul,\
+  smmulr,\
+  smmla,\
+  umaal,\
+  smlald,\
+  smlsld,\
+  sdiv,\
+  udiv,\
+  wmmx_tandc,\
+  wmmx_tbcst,\
+  wmmx_textrc,\
+  wmmx_textrm,\
+  wmmx_tinsr,\
+  wmmx_tmcr,\
+  wmmx_tmcrr,\
+  wmmx_tmia,\
+  wmmx_tmiaph,\
+  wmmx_tmiaxy,\
+  wmmx_tmrc,\
+  wmmx_tmrrc,\
+  wmmx_tmovmsk,\
+  wmmx_torc,\
+  wmmx_torvsc,\
+  wmmx_wabs,\
+  wmmx_wabsdiff,\
+  wmmx_wacc,\
+  wmmx_wadd,\
+  wmmx_waddbhus,\
+  wmmx_waddsubhx,\
+  wmmx_waligni,\
+  wmmx_walignr,\
+  wmmx_wand,\
+  wmmx_wandn,\
+  wmmx_wavg2,\
+  wmmx_wavg4,\
+  wmmx_wcmpeq,\
+  wmmx_wcmpgt,\
+  wmmx_wmac,\
+  wmmx_wmadd,\
+  wmmx_wmax,\
+  wmmx_wmerge,\
+  wmmx_wmiawxy,\
+  wmmx_wmiaxy,\
+  wmmx_wmin,\
+  wmmx_wmov,\
+  wmmx_wmul,\
+  wmmx_wmulw,\
+  wmmx_wldr,\
+  wmmx_wor,\
+  wmmx_wpack,\
+  wmmx_wqmiaxy,\
+  wmmx_wqmulm,\
+  wmmx_wqmulwm,\
+  wmmx_wror,\
+  wmmx_wsad,\
+  wmmx_wshufh,\
+  wmmx_wsll,\
+  wmmx_wsra,\
+  wmmx_wsrl,\
+  wmmx_wstr,\
+  wmmx_wsub,\
+  wmmx_wsubaddhx,\
+  wmmx_wunpckeh,\
+  wmmx_wunpckel,\
+  wmmx_wunpckih,\
+  wmmx_wunpckil,\
+  wmmx_wxor"
+  (const_string "alu_reg"))
+
+; Is this an (integer side) multiply with a 32-bit (or smaller) result?
+(define_attr "mul32" "no,yes"
+  (if_then_else
+    (eq_attr "type"
+     "smulxy,smlaxy,smulwy,smlawx,mul,muls,mla,mlas,smlawy,smuad,smuadx,\
+      smlad,smladx,smusd,smusdx,smlsd,smlsdx,smmul,smmulr,smmla,smlald,smlsld")
+    (const_string "yes")
+    (const_string "no")))
 
 ; Is this an (integer side) multiply with a 64-bit result?
 (define_attr "mul64" "no,yes"
   (if_then_else
-    (eq_attr "insn"
-     "smlalxy,umull,umulls,umlal,umlals,smull,smulls,smlal,smlals")
+    (eq_attr "type"
+     "smlalxy,umull,umulls,umaal,umlal,umlals,smull,smulls,smlal,smlals")
     (const_string "yes")
     (const_string "no")))
 
-; wtype for WMMX insn scheduling purposes.
-(define_attr "wtype"
-        "none,wor,wxor,wand,wandn,wmov,tmcrr,tmrrc,wldr,wstr,tmcr,tmrc,wadd,wsub,wmul,wmac,wavg2,tinsr,textrm,wshufh,wcmpeq,wcmpgt,wmax,wmin,wpack,wunpckih,wunpckil,wunpckeh,wunpckel,wror,wsra,wsrl,wsll,wmadd,tmia,tmiaph,tmiaxy,tbcst,tmovmsk,wacc,waligni,walignr,tandc,textrc,torc,torvsc,wsad,wabs,wabsdiff,waddsubhx,wsubaddhx,wavg4,wmulw,wqmulm,wqmulwm,waddbhus,wqmiaxy,wmiaxy,wmiawxy,wmerge" (const_string "none"))
-
 ; Load scheduling, set from the arm_ld_sched variable
 ; initialized by arm_option_override()
 (define_attr "ldsched" "no,yes" (const (symbol_ref "arm_ld_sched")))
@@ -458,9 +666,19 @@
 ; than one on the main cpu execution unit.
 (define_attr "core_cycles" "single,multi"
   (if_then_else (eq_attr "type"
-		 "simple_alu_imm,alu_reg,\
-                  simple_alu_shift,alu_shift,\
-                  float,fdivd,fdivs")
+    "simple_alu_imm, alu_reg,\
+    simple_alu_shift, alu_shift, float, fdivd, fdivs,\
+    wmmx_wor, wmmx_wxor, wmmx_wand, wmmx_wandn, wmmx_wmov, wmmx_tmcrr,\
+    wmmx_tmrrc, wmmx_wldr, wmmx_wstr, wmmx_tmcr, wmmx_tmrc, wmmx_wadd,\
+    wmmx_wsub, wmmx_wmul, wmmx_wmac, wmmx_wavg2, wmmx_tinsr, wmmx_textrm,\
+    wmmx_wshufh, wmmx_wcmpeq, wmmx_wcmpgt, wmmx_wmax, wmmx_wmin, wmmx_wpack,\
+    wmmx_wunpckih, wmmx_wunpckil, wmmx_wunpckeh, wmmx_wunpckel, wmmx_wror,\
+    wmmx_wsra, wmmx_wsrl, wmmx_wsll, wmmx_wmadd, wmmx_tmia, wmmx_tmiaph,\
+    wmmx_tmiaxy, wmmx_tbcst, wmmx_tmovmsk, wmmx_wacc, wmmx_waligni,\
+    wmmx_walignr, wmmx_tandc, wmmx_textrc, wmmx_torc, wmmx_torvsc, wmmx_wsad,\
+    wmmx_wabs, wmmx_wabsdiff, wmmx_waddsubhx, wmmx_wsubaddhx, wmmx_wavg4,\
+    wmmx_wmulw, wmmx_wqmulm, wmmx_wqmulwm, wmmx_waddbhus, wmmx_wqmiaxy,\
+    wmmx_wmiaxy, wmmx_wmiawxy, wmmx_wmerge")
 		(const_string "single")
 	        (const_string "multi")))
 
@@ -502,7 +720,7 @@
 
 (define_attr "generic_sched" "yes,no"
   (const (if_then_else
-          (ior (eq_attr "tune" "fa526,fa626,fa606te,fa626te,fmp626,fa726te,arm926ejs,arm1020e,arm1026ejs,arm1136js,arm1136jfs,cortexa5,cortexa7,cortexa8,cortexa9,cortexa15,cortexm4,marvell_pj4")
+          (ior (eq_attr "tune" "fa526,fa626,fa606te,fa626te,fmp626,fa726te,arm926ejs,arm1020e,arm1026ejs,arm1136js,arm1136jfs,cortexa5,cortexa7,cortexa8,cortexa9,cortexa15,cortexa53,cortexm4,marvell_pj4")
 	       (eq_attr "tune_cortexr4" "yes"))
           (const_string "no")
           (const_string "yes"))))
@@ -510,7 +728,7 @@
 (define_attr "generic_vfp" "yes,no"
   (const (if_then_else
 	  (and (eq_attr "fpu" "vfp")
-	       (eq_attr "tune" "!arm1020e,arm1022e,cortexa5,cortexa7,cortexa8,cortexa9,cortexm4,marvell_pj4")
+	       (eq_attr "tune" "!arm1020e,arm1022e,cortexa5,cortexa7,cortexa8,cortexa9,cortexa53,cortexm4,marvell_pj4")
 	       (eq_attr "tune_cortexr4" "no"))
 	  (const_string "yes")
 	  (const_string "no"))))
@@ -531,6 +749,7 @@
 (include "cortex-a8.md")
 (include "cortex-a9.md")
 (include "cortex-a15.md")
+(include "cortex-a53.md")
 (include "cortex-r4.md")
 (include "cortex-r4f.md")
 (include "cortex-m4.md")
@@ -844,7 +1063,7 @@
 
 ;; This is the canonicalization of addsi3_compare0_for_combiner when the
 ;; addend is a constant.
-(define_insn "*cmpsi2_addneg"
+(define_insn "cmpsi2_addneg"
   [(set (reg:CC CC_REGNUM)
 	(compare:CC
 	 (match_operand:SI 1 "s_register_operand" "r,r")
@@ -975,7 +1194,8 @@
   "@
    adc%?\\t%0, %1, %2
    sbc%?\\t%0, %1, #%B2"
-  [(set_attr "conds" "use")]
+  [(set_attr "conds" "use")
+   (set_attr "predicable" "yes")]
 )
 
 (define_insn "*addsi3_carryin_alt2_<optab>"
@@ -987,7 +1207,8 @@
   "@
    adc%?\\t%0, %1, %2
    sbc%?\\t%0, %1, #%B2"
-  [(set_attr "conds" "use")]
+  [(set_attr "conds" "use")
+   (set_attr "predicable" "yes")]
 )
 
 (define_insn "*addsi3_carryin_shift_<optab>"
@@ -1001,6 +1222,7 @@
   "TARGET_32BIT"
   "adc%?\\t%0, %1, %3%S2"
   [(set_attr "conds" "use")
+   (set_attr "predicable" "yes")
    (set (attr "type") (if_then_else (match_operand 4 "const_int_operand" "")
 		      (const_string "alu_shift")
 		      (const_string "alu_shift_reg")))]
@@ -1017,26 +1239,88 @@
    [(set_attr "conds" "set")]
 )
 
-(define_expand "incscc"
+(define_insn "*subsi3_carryin"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r")
-        (plus:SI (match_operator:SI 2 "arm_comparison_operator"
-                    [(match_operand:CC 3 "cc_register" "") (const_int 0)])
-                 (match_operand:SI 1 "s_register_operand" "0,?r")))]
+        (minus:SI (minus:SI (match_operand:SI 1 "reg_or_int_operand" "r,I")
+                            (match_operand:SI 2 "s_register_operand" "r,r"))
+                  (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
   "TARGET_32BIT"
-  ""
+  "@
+   sbc%?\\t%0, %1, %2
+   rsc%?\\t%0, %2, %1"
+  [(set_attr "conds" "use")
+   (set_attr "arch" "*,a")
+   (set_attr "predicable" "yes")]
 )
 
-(define_insn "*arm_incscc"
-  [(set (match_operand:SI 0 "s_register_operand" "=r,r")
-        (plus:SI (match_operator:SI 2 "arm_comparison_operator"
-                    [(match_operand:CC 3 "cc_register" "") (const_int 0)])
-                 (match_operand:SI 1 "s_register_operand" "0,?r")))]
+(define_insn "*subsi3_carryin_const"
+  [(set (match_operand:SI 0 "s_register_operand" "=r")
+        (minus:SI (plus:SI (match_operand:SI 1 "reg_or_int_operand" "r")
+                           (match_operand:SI 2 "arm_not_operand" "K"))
+                  (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  "TARGET_32BIT"
+  "sbc\\t%0, %1, #%B2"
+  [(set_attr "conds" "use")]
+)
+
+(define_insn "*subsi3_carryin_compare"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_operand:SI 1 "s_register_operand" "r")
+                    (match_operand:SI 2 "s_register_operand" "r")))
+   (set (match_operand:SI 0 "s_register_operand" "=r")
+        (minus:SI (minus:SI (match_dup 1)
+                            (match_dup 2))
+                  (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  "TARGET_32BIT"
+  "sbcs\\t%0, %1, %2"
+  [(set_attr "conds" "set")]
+)
+
+(define_insn "*subsi3_carryin_compare_const"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_operand:SI 1 "reg_or_int_operand" "r")
+                    (match_operand:SI 2 "arm_not_operand" "K")))
+   (set (match_operand:SI 0 "s_register_operand" "=r")
+        (minus:SI (plus:SI (match_dup 1)
+                           (match_dup 2))
+                  (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  "TARGET_32BIT"
+  "sbcs\\t%0, %1, #%B2"
+  [(set_attr "conds" "set")]
+)
+
+(define_insn "*subsi3_carryin_shift"
+  [(set (match_operand:SI 0 "s_register_operand" "=r")
+	(minus:SI (minus:SI
+		  (match_operand:SI 1 "s_register_operand" "r")
+                  (match_operator:SI 2 "shift_operator"
+                   [(match_operand:SI 3 "s_register_operand" "r")
+                    (match_operand:SI 4 "reg_or_int_operand" "rM")]))
+                 (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  "TARGET_32BIT"
+  "sbc%?\\t%0, %1, %3%S2"
+  [(set_attr "conds" "use")
+   (set_attr "predicable" "yes")
+   (set (attr "type") (if_then_else (match_operand 4 "const_int_operand" "")
+		      (const_string "alu_shift")
+                     (const_string "alu_shift_reg")))]
+)
+
+(define_insn "*rsbsi3_carryin_shift"
+  [(set (match_operand:SI 0 "s_register_operand" "=r")
+	(minus:SI (minus:SI
+                  (match_operator:SI 2 "shift_operator"
+                   [(match_operand:SI 3 "s_register_operand" "r")
+                    (match_operand:SI 4 "reg_or_int_operand" "rM")])
+		   (match_operand:SI 1 "s_register_operand" "r"))
+                 (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
   "TARGET_ARM"
-  "@
-  add%d2\\t%0, %1, #1
-  mov%D2\\t%0, %1\;add%d2\\t%0, %1, #1"
+  "rsc%?\\t%0, %1, %3%S2"
   [(set_attr "conds" "use")
-   (set_attr "length" "4,8")]
+   (set_attr "predicable" "yes")
+   (set (attr "type") (if_then_else (match_operand 4 "const_int_operand" "")
+		      (const_string "alu_shift")
+		      (const_string "alu_shift_reg")))]
 )
 
 ; transform ((x << y) - 1) to ~(~(x-1) << y)  Where X is a constant.
@@ -1087,13 +1371,27 @@
   "
 )
 
-(define_insn "*arm_subdi3"
+(define_insn_and_split "*arm_subdi3"
   [(set (match_operand:DI           0 "s_register_operand" "=&r,&r,&r")
 	(minus:DI (match_operand:DI 1 "s_register_operand" "0,r,0")
 		  (match_operand:DI 2 "s_register_operand" "r,0,0")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_32BIT && !TARGET_NEON"
-  "subs\\t%Q0, %Q1, %Q2\;sbc\\t%R0, %R1, %R2"
+  "#"  ; "subs\\t%Q0, %Q1, %Q2\;sbc\\t%R0, %R1, %R2"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+		   (compare:CC (match_dup 1) (match_dup 2)))
+	      (set (match_dup 0) (minus:SI (match_dup 1) (match_dup 2)))])
+   (set (match_dup 3) (minus:SI (minus:SI (match_dup 4) (match_dup 5))
+			       (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+    operands[3] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[4] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+    operands[5] = gen_highpart (SImode, operands[2]);
+    operands[2] = gen_lowpart (SImode, operands[2]);
+   }
   [(set_attr "conds" "clob")
    (set_attr "length" "8")]
 )
@@ -1108,55 +1406,113 @@
   [(set_attr "length" "4")]
 )
 
-(define_insn "*subdi_di_zesidi"
+(define_insn_and_split "*subdi_di_zesidi"
   [(set (match_operand:DI           0 "s_register_operand" "=&r,&r")
 	(minus:DI (match_operand:DI 1 "s_register_operand"  "0,r")
 		  (zero_extend:DI
 		   (match_operand:SI 2 "s_register_operand"  "r,r"))))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_32BIT"
-  "subs\\t%Q0, %Q1, %2\;sbc\\t%R0, %R1, #0"
+  "#"   ; "subs\\t%Q0, %Q1, %2\;sbc\\t%R0, %R1, #0"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+		   (compare:CC (match_dup 1) (match_dup 2)))
+	      (set (match_dup 0) (minus:SI (match_dup 1) (match_dup 2)))])
+   (set (match_dup 3) (minus:SI (plus:SI (match_dup 4) (match_dup 5))
+                                (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+    operands[3] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[4] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+    operands[5] = GEN_INT (~0);
+   }
   [(set_attr "conds" "clob")
    (set_attr "length" "8")]
 )
 
-(define_insn "*subdi_di_sesidi"
+(define_insn_and_split "*subdi_di_sesidi"
   [(set (match_operand:DI            0 "s_register_operand" "=&r,&r")
 	(minus:DI (match_operand:DI  1 "s_register_operand"  "0,r")
 		  (sign_extend:DI
 		   (match_operand:SI 2 "s_register_operand"  "r,r"))))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_32BIT"
-  "subs\\t%Q0, %Q1, %2\;sbc\\t%R0, %R1, %2, asr #31"
+  "#"   ; "subs\\t%Q0, %Q1, %2\;sbc\\t%R0, %R1, %2, asr #31"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+		   (compare:CC (match_dup 1) (match_dup 2)))
+	      (set (match_dup 0) (minus:SI (match_dup 1) (match_dup 2)))])
+   (set (match_dup 3) (minus:SI (minus:SI (match_dup 4)
+                                         (ashiftrt:SI (match_dup 2)
+                                                      (const_int 31)))
+                                (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+    operands[3] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[4] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "conds" "clob")
    (set_attr "length" "8")]
 )
 
-(define_insn "*subdi_zesidi_di"
+(define_insn_and_split "*subdi_zesidi_di"
   [(set (match_operand:DI            0 "s_register_operand" "=&r,&r")
 	(minus:DI (zero_extend:DI
 		   (match_operand:SI 2 "s_register_operand"  "r,r"))
 		  (match_operand:DI  1 "s_register_operand" "0,r")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "rsbs\\t%Q0, %Q1, %2\;rsc\\t%R0, %R1, #0"
+  "#"   ; "rsbs\\t%Q0, %Q1, %2\;rsc\\t%R0, %R1, #0"
+        ; is equivalent to:
+        ; "subs\\t%Q0, %2, %Q1\;rsc\\t%R0, %R1, #0"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+		   (compare:CC (match_dup 2) (match_dup 1)))
+	      (set (match_dup 0) (minus:SI (match_dup 2) (match_dup 1)))])
+   (set (match_dup 3) (minus:SI (minus:SI (const_int 0) (match_dup 4))
+			       (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+    operands[3] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[4] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "conds" "clob")
    (set_attr "length" "8")]
 )
 
-(define_insn "*subdi_sesidi_di"
+(define_insn_and_split "*subdi_sesidi_di"
   [(set (match_operand:DI            0 "s_register_operand" "=&r,&r")
 	(minus:DI (sign_extend:DI
 		   (match_operand:SI 2 "s_register_operand"   "r,r"))
 		  (match_operand:DI  1 "s_register_operand"  "0,r")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "rsbs\\t%Q0, %Q1, %2\;rsc\\t%R0, %R1, %2, asr #31"
+  "#"   ; "rsbs\\t%Q0, %Q1, %2\;rsc\\t%R0, %R1, %2, asr #31"
+        ; is equivalent to:
+        ; "subs\\t%Q0, %2, %Q1\;rsc\\t%R0, %R1, %2, asr #31"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+		   (compare:CC (match_dup 2) (match_dup 1)))
+	      (set (match_dup 0) (minus:SI (match_dup 2) (match_dup 1)))])
+   (set (match_dup 3) (minus:SI (minus:SI
+                                (ashiftrt:SI (match_dup 2)
+                                             (const_int 31))
+                                (match_dup 4))
+			       (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+    operands[3] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[4] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "conds" "clob")
    (set_attr "length" "8")]
 )
 
-(define_insn "*subdi_zesidi_zesidi"
+(define_insn_and_split "*subdi_zesidi_zesidi"
   [(set (match_operand:DI            0 "s_register_operand" "=r")
 	(minus:DI (zero_extend:DI
 		   (match_operand:SI 1 "s_register_operand"  "r"))
@@ -1164,7 +1520,17 @@
 		   (match_operand:SI 2 "s_register_operand"  "r"))))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_32BIT"
-  "subs\\t%Q0, %1, %2\;sbc\\t%R0, %1, %1"
+  "#"   ; "subs\\t%Q0, %1, %2\;sbc\\t%R0, %1, %1"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+		   (compare:CC (match_dup 1) (match_dup 2)))
+	      (set (match_dup 0) (minus:SI (match_dup 1) (match_dup 2)))])
+   (set (match_dup 3) (minus:SI (minus:SI (match_dup 1) (match_dup 1))
+			       (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+       operands[3] = gen_highpart (SImode, operands[0]);
+       operands[0] = gen_lowpart (SImode, operands[0]);
+  }
   [(set_attr "conds" "clob")
    (set_attr "length" "8")]
 )
@@ -1254,7 +1620,7 @@
    (set_attr "type"  "simple_alu_imm,*,*")]
 )
 
-(define_insn "*subsi3_compare"
+(define_insn "subsi3_compare"
   [(set (reg:CC CC_REGNUM)
 	(compare:CC (match_operand:SI 1 "arm_rhs_operand" "r,r,I")
 		    (match_operand:SI 2 "arm_rhs_operand" "I,r,r")))
@@ -1269,29 +1635,6 @@
    (set_attr "type" "simple_alu_imm,*,*")]
 )
 
-(define_expand "decscc"
-  [(set (match_operand:SI            0 "s_register_operand" "=r,r")
-        (minus:SI (match_operand:SI  1 "s_register_operand" "0,?r")
-		  (match_operator:SI 2 "arm_comparison_operator"
-                   [(match_operand   3 "cc_register" "") (const_int 0)])))]
-  "TARGET_32BIT"
-  ""
-)
-
-(define_insn "*arm_decscc"
-  [(set (match_operand:SI            0 "s_register_operand" "=r,r")
-        (minus:SI (match_operand:SI  1 "s_register_operand" "0,?r")
-		  (match_operator:SI 2 "arm_comparison_operator"
-                   [(match_operand   3 "cc_register" "") (const_int 0)])))]
-  "TARGET_ARM"
-  "@
-   sub%d2\\t%0, %1, #1
-   mov%D2\\t%0, %1\;sub%d2\\t%0, %1, #1"
-  [(set_attr "conds" "use")
-   (set_attr "length" "*,8")
-   (set_attr "type" "simple_alu_imm,*")]
-)
-
 (define_expand "subsf3"
   [(set (match_operand:SF           0 "s_register_operand" "")
 	(minus:SF (match_operand:SF 1 "s_register_operand" "")
@@ -1326,18 +1669,21 @@
 		 (match_operand:SI 1 "s_register_operand" "%0,r")))]
   "TARGET_32BIT && !arm_arch6"
   "mul%?\\t%0, %2, %1"
-  [(set_attr "insn" "mul")
+  [(set_attr "type" "mul")
    (set_attr "predicable" "yes")]
 )
 
 (define_insn "*arm_mulsi3_v6"
-  [(set (match_operand:SI          0 "s_register_operand" "=r")
-	(mult:SI (match_operand:SI 1 "s_register_operand" "r")
-		 (match_operand:SI 2 "s_register_operand" "r")))]
+  [(set (match_operand:SI          0 "s_register_operand" "=l,l,r")
+	(mult:SI (match_operand:SI 1 "s_register_operand" "0,l,r")
+		 (match_operand:SI 2 "s_register_operand" "l,0,r")))]
   "TARGET_32BIT && arm_arch6"
   "mul%?\\t%0, %1, %2"
-  [(set_attr "insn" "mul")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "mul")
+   (set_attr "predicable" "yes")
+   (set_attr "arch" "t2,t2,*")
+   (set_attr "length" "4")
+   (set_attr "predicable_short_it" "yes,yes,no")]
 )
 
 ; Unfortunately with the Thumb the '&'/'0' trick can fails when operands 
@@ -1357,7 +1703,7 @@
     return \"mul\\t%0, %2\";
   "
   [(set_attr "length" "4,4,2")
-   (set_attr "insn" "mul")]
+   (set_attr "type" "muls")]
 )
 
 (define_insn "*thumb_mulsi3_v6"
@@ -1370,7 +1716,7 @@
    mul\\t%0, %1
    mul\\t%0, %1"
   [(set_attr "length" "2")
-   (set_attr "insn" "mul")]
+   (set_attr "type" "muls")]
 )
 
 (define_insn "*mulsi3_compare0"
@@ -1384,7 +1730,7 @@
   "TARGET_ARM && !arm_arch6"
   "mul%.\\t%0, %2, %1"
   [(set_attr "conds" "set")
-   (set_attr "insn" "muls")]
+   (set_attr "type" "muls")]
 )
 
 (define_insn "*mulsi3_compare0_v6"
@@ -1398,7 +1744,7 @@
   "TARGET_ARM && arm_arch6 && optimize_size"
   "mul%.\\t%0, %2, %1"
   [(set_attr "conds" "set")
-   (set_attr "insn" "muls")]
+   (set_attr "type" "muls")]
 )
 
 (define_insn "*mulsi_compare0_scratch"
@@ -1411,7 +1757,7 @@
   "TARGET_ARM && !arm_arch6"
   "mul%.\\t%0, %2, %1"
   [(set_attr "conds" "set")
-   (set_attr "insn" "muls")]
+   (set_attr "type" "muls")]
 )
 
 (define_insn "*mulsi_compare0_scratch_v6"
@@ -1424,7 +1770,7 @@
   "TARGET_ARM && arm_arch6 && optimize_size"
   "mul%.\\t%0, %2, %1"
   [(set_attr "conds" "set")
-   (set_attr "insn" "muls")]
+   (set_attr "type" "muls")]
 )
 
 ;; Unnamed templates to match MLA instruction.
@@ -1437,7 +1783,7 @@
 	  (match_operand:SI 3 "s_register_operand" "r,r,0,0")))]
   "TARGET_32BIT && !arm_arch6"
   "mla%?\\t%0, %2, %1, %3"
-  [(set_attr "insn" "mla")
+  [(set_attr "type" "mla")
    (set_attr "predicable" "yes")]
 )
 
@@ -1449,8 +1795,9 @@
 	  (match_operand:SI 3 "s_register_operand" "r")))]
   "TARGET_32BIT && arm_arch6"
   "mla%?\\t%0, %2, %1, %3"
-  [(set_attr "insn" "mla")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "mla")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "*mulsi3addsi_compare0"
@@ -1467,7 +1814,7 @@
   "TARGET_ARM && arm_arch6"
   "mla%.\\t%0, %2, %1, %3"
   [(set_attr "conds" "set")
-   (set_attr "insn" "mlas")]
+   (set_attr "type" "mlas")]
 )
 
 (define_insn "*mulsi3addsi_compare0_v6"
@@ -1484,7 +1831,7 @@
   "TARGET_ARM && arm_arch6 && optimize_size"
   "mla%.\\t%0, %2, %1, %3"
   [(set_attr "conds" "set")
-   (set_attr "insn" "mlas")]
+   (set_attr "type" "mlas")]
 )
 
 (define_insn "*mulsi3addsi_compare0_scratch"
@@ -1499,7 +1846,7 @@
   "TARGET_ARM && !arm_arch6"
   "mla%.\\t%0, %2, %1, %3"
   [(set_attr "conds" "set")
-   (set_attr "insn" "mlas")]
+   (set_attr "type" "mlas")]
 )
 
 (define_insn "*mulsi3addsi_compare0_scratch_v6"
@@ -1514,7 +1861,7 @@
   "TARGET_ARM && arm_arch6 && optimize_size"
   "mla%.\\t%0, %2, %1, %3"
   [(set_attr "conds" "set")
-   (set_attr "insn" "mlas")]
+   (set_attr "type" "mlas")]
 )
 
 (define_insn "*mulsi3subsi"
@@ -1525,8 +1872,9 @@
 		   (match_operand:SI 1 "s_register_operand" "r"))))]
   "TARGET_32BIT && arm_arch_thumb2"
   "mls%?\\t%0, %2, %1, %3"
-  [(set_attr "insn" "mla")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "mla")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_expand "maddsidi4"
@@ -1548,7 +1896,7 @@
 	 (match_operand:DI 1 "s_register_operand" "0")))]
   "TARGET_32BIT && arm_arch3m && !arm_arch6"
   "smlal%?\\t%Q0, %R0, %3, %2"
-  [(set_attr "insn" "smlal")
+  [(set_attr "type" "smlal")
    (set_attr "predicable" "yes")]
 )
 
@@ -1561,8 +1909,9 @@
 	 (match_operand:DI 1 "s_register_operand" "0")))]
   "TARGET_32BIT && arm_arch6"
   "smlal%?\\t%Q0, %R0, %3, %2"
-  [(set_attr "insn" "smlal")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "smlal")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 ;; 32x32->64 widening multiply.
@@ -1587,7 +1936,7 @@
 	 (sign_extend:DI (match_operand:SI 2 "s_register_operand" "r"))))]
   "TARGET_32BIT && arm_arch3m && !arm_arch6"
   "smull%?\\t%Q0, %R0, %1, %2"
-  [(set_attr "insn" "smull")
+  [(set_attr "type" "smull")
    (set_attr "predicable" "yes")]
 )
 
@@ -1598,8 +1947,9 @@
 	 (sign_extend:DI (match_operand:SI 2 "s_register_operand" "r"))))]
   "TARGET_32BIT && arm_arch6"
   "smull%?\\t%Q0, %R0, %1, %2"
-  [(set_attr "insn" "smull")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "smull")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_expand "umulsidi3"
@@ -1618,7 +1968,7 @@
 	 (zero_extend:DI (match_operand:SI 2 "s_register_operand" "r"))))]
   "TARGET_32BIT && arm_arch3m && !arm_arch6"
   "umull%?\\t%Q0, %R0, %1, %2"
-  [(set_attr "insn" "umull")
+  [(set_attr "type" "umull")
    (set_attr "predicable" "yes")]
 )
 
@@ -1629,8 +1979,9 @@
 	 (zero_extend:DI (match_operand:SI 2 "s_register_operand" "r"))))]
   "TARGET_32BIT && arm_arch6"
   "umull%?\\t%Q0, %R0, %1, %2"
-  [(set_attr "insn" "umull")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "umull")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_expand "umaddsidi4"
@@ -1652,7 +2003,7 @@
 	 (match_operand:DI 1 "s_register_operand" "0")))]
   "TARGET_32BIT && arm_arch3m && !arm_arch6"
   "umlal%?\\t%Q0, %R0, %3, %2"
-  [(set_attr "insn" "umlal")
+  [(set_attr "type" "umlal")
    (set_attr "predicable" "yes")]
 )
 
@@ -1665,8 +2016,9 @@
 	 (match_operand:DI 1 "s_register_operand" "0")))]
   "TARGET_32BIT && arm_arch6"
   "umlal%?\\t%Q0, %R0, %3, %2"
-  [(set_attr "insn" "umlal")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "umlal")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_expand "smulsi3_highpart"
@@ -1694,7 +2046,7 @@
    (clobber (match_scratch:SI 3 "=&r,&r"))]
   "TARGET_32BIT && arm_arch3m && !arm_arch6"
   "smull%?\\t%3, %0, %2, %1"
-  [(set_attr "insn" "smull")
+  [(set_attr "type" "smull")
    (set_attr "predicable" "yes")]
 )
 
@@ -1709,8 +2061,9 @@
    (clobber (match_scratch:SI 3 "=r"))]
   "TARGET_32BIT && arm_arch6"
   "smull%?\\t%3, %0, %2, %1"
-  [(set_attr "insn" "smull")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "smull")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_expand "umulsi3_highpart"
@@ -1738,7 +2091,7 @@
    (clobber (match_scratch:SI 3 "=&r,&r"))]
   "TARGET_32BIT && arm_arch3m && !arm_arch6"
   "umull%?\\t%3, %0, %2, %1"
-  [(set_attr "insn" "umull")
+  [(set_attr "type" "umull")
    (set_attr "predicable" "yes")]
 )
 
@@ -1753,8 +2106,9 @@
    (clobber (match_scratch:SI 3 "=r"))]
   "TARGET_32BIT && arm_arch6"
   "umull%?\\t%3, %0, %2, %1"
-  [(set_attr "insn" "umull")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "umull")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "mulhisi3"
@@ -1765,7 +2119,7 @@
 		  (match_operand:HI 2 "s_register_operand" "r"))))]
   "TARGET_DSP_MULTIPLY"
   "smulbb%?\\t%0, %1, %2"
-  [(set_attr "insn" "smulxy")
+  [(set_attr "type" "smulxy")
    (set_attr "predicable" "yes")]
 )
 
@@ -1778,8 +2132,9 @@
 		  (match_operand:HI 2 "s_register_operand" "r"))))]
   "TARGET_DSP_MULTIPLY"
   "smultb%?\\t%0, %1, %2"
-  [(set_attr "insn" "smulxy")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "smulxy")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "*mulhisi3bt"
@@ -1791,8 +2146,9 @@
 		  (const_int 16))))]
   "TARGET_DSP_MULTIPLY"
   "smulbt%?\\t%0, %1, %2"
-  [(set_attr "insn" "smulxy")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "smulxy")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "*mulhisi3tt"
@@ -1805,8 +2161,9 @@
 		  (const_int 16))))]
   "TARGET_DSP_MULTIPLY"
   "smultt%?\\t%0, %1, %2"
-  [(set_attr "insn" "smulxy")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "smulxy")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "maddhisi4"
@@ -1818,8 +2175,9 @@
 		 (match_operand:SI 3 "s_register_operand" "r")))]
   "TARGET_DSP_MULTIPLY"
   "smlabb%?\\t%0, %1, %2, %3"
-  [(set_attr "insn" "smlaxy")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "smlaxy")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 ;; Note: there is no maddhisi4ibt because this one is canonical form
@@ -1833,8 +2191,9 @@
 		 (match_operand:SI 3 "s_register_operand" "r")))]
   "TARGET_DSP_MULTIPLY"
   "smlatb%?\\t%0, %1, %2, %3"
-  [(set_attr "insn" "smlaxy")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "smlaxy")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "*maddhisi4tt"
@@ -1848,22 +2207,24 @@
 		 (match_operand:SI 3 "s_register_operand" "r")))]
   "TARGET_DSP_MULTIPLY"
   "smlatt%?\\t%0, %1, %2, %3"
-  [(set_attr "insn" "smlaxy")
-   (set_attr "predicable" "yes")]
+  [(set_attr "type" "smlaxy")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "maddhidi4"
   [(set (match_operand:DI 0 "s_register_operand" "=r")
 	(plus:DI
 	  (mult:DI (sign_extend:DI
-	 	    (match_operand:HI 1 "s_register_operand" "r"))
+		    (match_operand:HI 1 "s_register_operand" "r"))
 		   (sign_extend:DI
 		    (match_operand:HI 2 "s_register_operand" "r")))
 	  (match_operand:DI 3 "s_register_operand" "0")))]
   "TARGET_DSP_MULTIPLY"
   "smlalbb%?\\t%Q0, %R0, %1, %2"
-  [(set_attr "insn" "smlalxy")
-   (set_attr "predicable" "yes")])
+  [(set_attr "type" "smlalxy")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 ;; Note: there is no maddhidi4ibt because this one is canonical form
 (define_insn "*maddhidi4tb"
@@ -1878,8 +2239,9 @@
 	  (match_operand:DI 3 "s_register_operand" "0")))]
   "TARGET_DSP_MULTIPLY"
   "smlaltb%?\\t%Q0, %R0, %1, %2"
-  [(set_attr "insn" "smlalxy")
-   (set_attr "predicable" "yes")])
+  [(set_attr "type" "smlalxy")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*maddhidi4tt"
   [(set (match_operand:DI 0 "s_register_operand" "=r")
@@ -1895,8 +2257,9 @@
 	  (match_operand:DI 3 "s_register_operand" "0")))]
   "TARGET_DSP_MULTIPLY"
   "smlaltt%?\\t%Q0, %R0, %1, %2"
-  [(set_attr "insn" "smlalxy")
-   (set_attr "predicable" "yes")])
+  [(set_attr "type" "smlalxy")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_expand "mulsf3"
   [(set (match_operand:SF          0 "s_register_operand" "")
@@ -2024,13 +2387,49 @@
   ""
 )
 
-(define_insn "*anddi3_insn"
-  [(set (match_operand:DI         0 "s_register_operand" "=&r,&r")
-	(and:DI (match_operand:DI 1 "s_register_operand"  "%0,r")
-		(match_operand:DI 2 "s_register_operand"   "r,r")))]
-  "TARGET_32BIT && !TARGET_IWMMXT && !TARGET_NEON"
-  "#"
-  [(set_attr "length" "8")]
+(define_insn_and_split "*anddi3_insn"
+  [(set (match_operand:DI         0 "s_register_operand"     "=w,w ,&r,&r,&r,&r,?w,?w")
+        (and:DI (match_operand:DI 1 "s_register_operand"     "%w,0 ,0 ,r ,0 ,r ,w ,0")
+                (match_operand:DI 2 "arm_anddi_operand_neon" "w ,DL,r ,r ,De,De,w ,DL")))]
+  "TARGET_32BIT && !TARGET_IWMMXT"
+{
+  switch (which_alternative)
+    {
+    case 0: /* fall through */
+    case 6: return "vand\t%P0, %P1, %P2";
+    case 1: /* fall through */
+    case 7: return neon_output_logic_immediate ("vand", &operands[2],
+                    DImode, 1, VALID_NEON_QREG_MODE (DImode));
+    case 2:
+    case 3:
+    case 4:
+    case 5: /* fall through */
+      return "#";
+    default: gcc_unreachable ();
+    }
+}
+  "TARGET_32BIT && !TARGET_IWMMXT && reload_completed
+   && !(IS_VFP_REGNUM (REGNO (operands[0])))"
+  [(set (match_dup 3) (match_dup 4))
+   (set (match_dup 5) (match_dup 6))]
+  "
+  {
+    operands[3] = gen_lowpart (SImode, operands[0]);
+    operands[5] = gen_highpart (SImode, operands[0]);
+
+    operands[4] = simplify_gen_binary (AND, SImode,
+                                           gen_lowpart (SImode, operands[1]),
+                                           gen_lowpart (SImode, operands[2]));
+    operands[6] = simplify_gen_binary (AND, SImode,
+                                           gen_highpart (SImode, operands[1]),
+                                           gen_highpart_mode (SImode, DImode, operands[2]));
+
+  }"
+  [(set_attr "neon_type" "neon_int_1,neon_int_1,*,*,*,*,neon_int_1,neon_int_1")
+   (set_attr "arch" "neon_for_64bits,neon_for_64bits,*,*,*,*,
+                     avoid_neon_for_64bits,avoid_neon_for_64bits")
+   (set_attr "length" "*,*,8,8,8,8,*,*")
+  ]
 )
 
 (define_insn_and_split "*anddi_zesidi_di"
@@ -2145,12 +2544,13 @@
 
 ; ??? Check split length for Thumb-2
 (define_insn_and_split "*arm_andsi3_insn"
-  [(set (match_operand:SI         0 "s_register_operand" "=r,r,r,r")
-	(and:SI (match_operand:SI 1 "s_register_operand" "r,r,r,r")
-		(match_operand:SI 2 "reg_or_int_operand" "I,K,r,?n")))]
+  [(set (match_operand:SI         0 "s_register_operand" "=r,l,r,r,r")
+	(and:SI (match_operand:SI 1 "s_register_operand" "%r,0,r,r,r")
+		(match_operand:SI 2 "reg_or_int_operand" "I,l,K,r,?n")))]
   "TARGET_32BIT"
   "@
    and%?\\t%0, %1, %2
+   and%?\\t%0, %1, %2
    bic%?\\t%0, %1, #%B2
    and%?\\t%0, %1, %2
    #"
@@ -2164,9 +2564,11 @@
 	               INTVAL (operands[2]), operands[0], operands[1], 0);
   DONE;
   "
-  [(set_attr "length" "4,4,4,16")
+  [(set_attr "length" "4,4,4,4,16")
    (set_attr "predicable" "yes")
-   (set_attr "type" 	"simple_alu_imm,simple_alu_imm,*,simple_alu_imm")]
+   (set_attr "predicable_short_it" "no,yes,no,no,no")
+   (set_attr "type"
+     "simple_alu_imm,simple_alu_imm,*,*,simple_alu_imm")]
 )
 
 (define_insn "*thumb1_andsi3_insn"
@@ -2216,7 +2618,7 @@
   [(set (reg:CC_NOOV CC_REGNUM)
 	(compare:CC_NOOV (zero_extract:SI
 			  (match_operand:SI 0 "s_register_operand" "r")
-		 	  (match_operand 1 "const_int_operand" "n")
+			  (match_operand 1 "const_int_operand" "n")
 			  (match_operand 2 "const_int_operand" "n"))
 			 (const_int 0)))]
   "TARGET_32BIT
@@ -2232,6 +2634,7 @@
   "
   [(set_attr "conds" "set")
    (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "simple_alu_imm")]
 )
 
@@ -2659,7 +3062,8 @@
   "arm_arch_thumb2"
   "bfc%?\t%0, %2, %1"
   [(set_attr "length" "4")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "insv_t2"
@@ -2670,7 +3074,8 @@
   "arm_arch_thumb2"
   "bfi%?\t%0, %3, %2, %1"
   [(set_attr "length" "4")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 ; constants for op 2 will never be given to these patterns.
@@ -2697,7 +3102,7 @@
   [(set_attr "length" "8")
    (set_attr "predicable" "yes")]
 )
-  
+
 (define_insn_and_split "*anddi_notzesidi_di"
   [(set (match_operand:DI 0 "s_register_operand" "=&r,&r")
 	(and:DI (not:DI (zero_extend:DI
@@ -2722,9 +3127,10 @@
     operands[1] = gen_lowpart (SImode, operands[1]);
   }"
   [(set_attr "length" "4,8")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
-  
+
 (define_insn_and_split "*anddi_notsesidi_di"
   [(set (match_operand:DI 0 "s_register_operand" "=&r,&r")
 	(and:DI (not:DI (sign_extend:DI
@@ -2745,16 +3151,18 @@
     operands[1] = gen_lowpart (SImode, operands[1]);
   }"
   [(set_attr "length" "8")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
-  
+
 (define_insn "andsi_notsi_si"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(and:SI (not:SI (match_operand:SI 2 "s_register_operand" "r"))
 		(match_operand:SI 1 "s_register_operand" "r")))]
   "TARGET_32BIT"
   "bic%?\\t%0, %1, %2"
-  [(set_attr "predicable" "yes")]
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "thumb1_bicsi3"
@@ -2814,14 +3222,47 @@
   ""
 )
 
-(define_insn "*iordi3_insn"
-  [(set (match_operand:DI         0 "s_register_operand" "=&r,&r")
-	(ior:DI (match_operand:DI 1 "s_register_operand"  "%0,r")
-		(match_operand:DI 2 "s_register_operand"   "r,r")))]
-  "TARGET_32BIT && !TARGET_IWMMXT && !TARGET_NEON"
-  "#"
-  [(set_attr "length" "8")
-   (set_attr "predicable" "yes")]
+(define_insn_and_split "*iordi3_insn"
+  [(set (match_operand:DI         0 "s_register_operand"     "=w,w ,&r,&r,&r,&r,?w,?w")
+	(ior:DI (match_operand:DI 1 "s_register_operand"     "%w,0 ,0 ,r ,0 ,r ,w ,0")
+		(match_operand:DI 2 "arm_iordi_operand_neon" "w ,Dl,r ,r ,Df,Df,w ,Dl")))]
+  "TARGET_32BIT && !TARGET_IWMMXT"
+  {
+  switch (which_alternative)
+    {
+    case 0: /* fall through */
+    case 6: return "vorr\t%P0, %P1, %P2";
+    case 1: /* fall through */
+    case 7: return neon_output_logic_immediate ("vorr", &operands[2],
+		     DImode, 0, VALID_NEON_QREG_MODE (DImode));
+    case 2:
+    case 3:
+    case 4:
+    case 5:
+      return "#";
+    default: gcc_unreachable ();
+    }
+  }
+  "TARGET_32BIT && !TARGET_IWMMXT && reload_completed
+   && !(IS_VFP_REGNUM (REGNO (operands[0])))"
+  [(set (match_dup 3) (match_dup 4))
+   (set (match_dup 5) (match_dup 6))]
+  "
+  {
+    operands[3] = gen_lowpart (SImode, operands[0]);
+    operands[5] = gen_highpart (SImode, operands[0]);
+
+    operands[4] = simplify_gen_binary (IOR, SImode,
+                                           gen_lowpart (SImode, operands[1]),
+                                           gen_lowpart (SImode, operands[2]));
+    operands[6] = simplify_gen_binary (IOR, SImode,
+                                           gen_highpart (SImode, operands[1]),
+                                           gen_highpart_mode (SImode, DImode, operands[2]));
+
+  }"
+  [(set_attr "neon_type" "neon_int_1,neon_int_1,*,*,*,*,neon_int_1,neon_int_1")
+   (set_attr "length" "*,*,8,8,8,8,*,*")
+   (set_attr "arch" "neon_for_64bits,neon_for_64bits,*,*,*,*,avoid_neon_for_64bits,avoid_neon_for_64bits")]
 )
 
 (define_insn "*iordi_zesidi_di"
@@ -2834,7 +3275,8 @@
    orr%?\\t%Q0, %Q1, %2
    #"
   [(set_attr "length" "4,8")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "*iordi_sesidi_di"
@@ -2879,12 +3321,13 @@
 )
 
 (define_insn_and_split "*iorsi3_insn"
-  [(set (match_operand:SI 0 "s_register_operand" "=r,r,r,r")
-	(ior:SI (match_operand:SI 1 "s_register_operand" "%r,r,r,r")
-		(match_operand:SI 2 "reg_or_int_operand" "I,K,r,?n")))]
+  [(set (match_operand:SI 0 "s_register_operand" "=r,l,r,r,r")
+	(ior:SI (match_operand:SI 1 "s_register_operand" "%r,0,r,r,r")
+		(match_operand:SI 2 "reg_or_int_operand" "I,l,K,r,?n")))]
   "TARGET_32BIT"
   "@
    orr%?\\t%0, %1, %2
+   orr%?\\t%0, %1, %2
    orn%?\\t%0, %1, #%B2
    orr%?\\t%0, %1, %2
    #"
@@ -2894,14 +3337,15 @@
         || (TARGET_THUMB2 && const_ok_for_arm (~INTVAL (operands[2]))))"
   [(clobber (const_int 0))]
 {
-  arm_split_constant (IOR, SImode, curr_insn, 
+  arm_split_constant (IOR, SImode, curr_insn,
                       INTVAL (operands[2]), operands[0], operands[1], 0);
   DONE;
 }
-  [(set_attr "length" "4,4,4,16")
-   (set_attr "arch" "32,t2,32,32")
+  [(set_attr "length" "4,4,4,4,16")
+   (set_attr "arch" "32,t2,t2,32,32")
    (set_attr "predicable" "yes")
-   (set_attr "type" "simple_alu_imm,simple_alu_imm,*,*")]
+   (set_attr "predicable_short_it" "no,yes,no,no,no")
+   (set_attr "type" "simple_alu_imm,*,simple_alu_imm,*,*")]
 )
 
 (define_insn "*thumb1_iorsi3_insn"
@@ -2954,19 +3398,49 @@
 (define_expand "xordi3"
   [(set (match_operand:DI         0 "s_register_operand" "")
 	(xor:DI (match_operand:DI 1 "s_register_operand" "")
-		(match_operand:DI 2 "s_register_operand" "")))]
+		(match_operand:DI 2 "arm_xordi_operand" "")))]
   "TARGET_32BIT"
   ""
 )
 
-(define_insn "*xordi3_insn"
-  [(set (match_operand:DI         0 "s_register_operand" "=&r,&r")
-	(xor:DI (match_operand:DI 1 "s_register_operand"  "%0,r")
-		(match_operand:DI 2 "s_register_operand"   "r,r")))]
-  "TARGET_32BIT && !TARGET_IWMMXT && !TARGET_NEON"
-  "#"
-  [(set_attr "length" "8")
-   (set_attr "predicable" "yes")]
+(define_insn_and_split "*xordi3_insn"
+  [(set (match_operand:DI         0 "s_register_operand" "=w,&r,&r,&r,&r,?w")
+	(xor:DI (match_operand:DI 1 "s_register_operand" "w ,%0,r ,0 ,r ,w")
+		(match_operand:DI 2 "arm_xordi_operand"  "w ,r ,r ,Dg,Dg,w")))]
+  "TARGET_32BIT && !TARGET_IWMMXT"
+{
+  switch (which_alternative)
+    {
+    case 1:
+    case 2:
+    case 3:
+    case 4:  /* fall through */
+      return "#";
+    case 0: /* fall through */
+    case 5: return "veor\t%P0, %P1, %P2";
+    default: gcc_unreachable ();
+    }
+}
+  "TARGET_32BIT && !TARGET_IWMMXT && reload_completed
+   && !(IS_VFP_REGNUM (REGNO (operands[0])))"
+  [(set (match_dup 3) (match_dup 4))
+   (set (match_dup 5) (match_dup 6))]
+  "
+  {
+    operands[3] = gen_lowpart (SImode, operands[0]);
+    operands[5] = gen_highpart (SImode, operands[0]);
+
+    operands[4] = simplify_gen_binary (XOR, SImode,
+                                           gen_lowpart (SImode, operands[1]),
+                                           gen_lowpart (SImode, operands[2]));
+    operands[6] = simplify_gen_binary (XOR, SImode,
+                                           gen_highpart (SImode, operands[1]),
+                                           gen_highpart_mode (SImode, DImode, operands[2]));
+
+  }"
+  [(set_attr "length" "*,8,8,8,8,*")
+   (set_attr "neon_type" "neon_int_1,*,*,*,*,neon_int_1")
+   (set_attr "arch" "neon_for_64bits,*,*,*,*,avoid_neon_for_64bits")]
 )
 
 (define_insn "*xordi_zesidi_di"
@@ -2979,7 +3453,8 @@
    eor%?\\t%Q0, %Q1, %2
    #"
   [(set_attr "length" "4,8")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "*xordi_sesidi_di"
@@ -3022,13 +3497,14 @@
 )
 
 (define_insn_and_split "*arm_xorsi3"
-  [(set (match_operand:SI         0 "s_register_operand" "=r,r,r")
-	(xor:SI (match_operand:SI 1 "s_register_operand" "%r,r,r")
-		(match_operand:SI 2 "reg_or_int_operand" "I,r,?n")))]
+  [(set (match_operand:SI         0 "s_register_operand" "=r,l,r,r")
+	(xor:SI (match_operand:SI 1 "s_register_operand" "%r,0,r,r")
+		(match_operand:SI 2 "reg_or_int_operand" "I,l,r,?n")))]
   "TARGET_32BIT"
   "@
    eor%?\\t%0, %1, %2
    eor%?\\t%0, %1, %2
+   eor%?\\t%0, %1, %2
    #"
   "TARGET_32BIT
    && CONST_INT_P (operands[2])
@@ -3039,9 +3515,10 @@
                       INTVAL (operands[2]), operands[0], operands[1], 0);
   DONE;
 }
-  [(set_attr "length" "4,4,16")
+  [(set_attr "length" "4,4,4,16")
    (set_attr "predicable" "yes")
-   (set_attr "type"  "simple_alu_imm,*,*")]
+   (set_attr "predicable_short_it" "no,yes,no,no")
+   (set_attr "type"  "simple_alu_imm,*,*,*")]
 )
 
 (define_insn "*thumb1_xorsi3_insn"
@@ -3096,16 +3573,21 @@
   ""
 )
 
-(define_insn "*andsi_iorsi3_notsi"
+(define_insn_and_split "*andsi_iorsi3_notsi"
   [(set (match_operand:SI 0 "s_register_operand" "=&r,&r,&r")
 	(and:SI (ior:SI (match_operand:SI 1 "s_register_operand" "%0,r,r")
 			(match_operand:SI 2 "arm_rhs_operand" "rI,0,rI"))
 		(not:SI (match_operand:SI 3 "arm_rhs_operand" "rI,rI,rI"))))]
   "TARGET_32BIT"
-  "orr%?\\t%0, %1, %2\;bic%?\\t%0, %0, %3"
+  "#"   ; "orr%?\\t%0, %1, %2\;bic%?\\t%0, %0, %3"
+  "&& reload_completed"
+  [(set (match_dup 0) (ior:SI (match_dup 1) (match_dup 2)))
+   (set (match_dup 0) (and:SI (not:SI (match_dup 3)) (match_dup 0)))]
+  ""
   [(set_attr "length" "8")
    (set_attr "ce_count" "2")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 ; ??? Are these four splitters still beneficial when the Thumb-2 bitfield
@@ -3241,7 +3723,8 @@
 		 (const_int 0)))]
   "TARGET_32BIT"
   "bic%?\\t%0, %1, %1, asr #31"
-  [(set_attr "predicable" "yes")]
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "*smax_m1"
@@ -3250,18 +3733,27 @@
 		 (const_int -1)))]
   "TARGET_32BIT"
   "orr%?\\t%0, %1, %1, asr #31"
-  [(set_attr "predicable" "yes")]
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
-(define_insn "*arm_smax_insn"
+(define_insn_and_split "*arm_smax_insn"
   [(set (match_operand:SI          0 "s_register_operand" "=r,r")
 	(smax:SI (match_operand:SI 1 "s_register_operand"  "%0,?r")
 		 (match_operand:SI 2 "arm_rhs_operand"    "rI,rI")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "@
-   cmp\\t%1, %2\;movlt\\t%0, %2
-   cmp\\t%1, %2\;movge\\t%0, %1\;movlt\\t%0, %2"
+  "#"
+   ; cmp\\t%1, %2\;movlt\\t%0, %2
+   ; cmp\\t%1, %2\;movge\\t%0, %1\;movlt\\t%0, %2"
+  "TARGET_ARM"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+        (if_then_else:SI (ge:SI (reg:CC CC_REGNUM) (const_int 0))
+                         (match_dup 1)
+                         (match_dup 2)))]
+  ""
   [(set_attr "conds" "clob")
    (set_attr "length" "8,12")]
 )
@@ -3290,18 +3782,27 @@
 		 (const_int 0)))]
   "TARGET_32BIT"
   "and%?\\t%0, %1, %1, asr #31"
-  [(set_attr "predicable" "yes")]
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
-(define_insn "*arm_smin_insn"
+(define_insn_and_split "*arm_smin_insn"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r")
 	(smin:SI (match_operand:SI 1 "s_register_operand" "%0,?r")
 		 (match_operand:SI 2 "arm_rhs_operand" "rI,rI")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "@
-   cmp\\t%1, %2\;movge\\t%0, %2
-   cmp\\t%1, %2\;movlt\\t%0, %1\;movge\\t%0, %2"
+  "#"
+    ; cmp\\t%1, %2\;movge\\t%0, %2
+    ; cmp\\t%1, %2\;movlt\\t%0, %1\;movge\\t%0, %2"
+  "TARGET_ARM"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+        (if_then_else:SI (lt:SI (reg:CC CC_REGNUM) (const_int 0))
+                         (match_dup 1)
+                         (match_dup 2)))]
+  ""
   [(set_attr "conds" "clob")
    (set_attr "length" "8,12")]
 )
@@ -3316,16 +3817,24 @@
   ""
 )
 
-(define_insn "*arm_umaxsi3"
+(define_insn_and_split "*arm_umaxsi3"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r,r")
 	(umax:SI (match_operand:SI 1 "s_register_operand" "0,r,?r")
 		 (match_operand:SI 2 "arm_rhs_operand" "rI,0,rI")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "@
-   cmp\\t%1, %2\;movcc\\t%0, %2
-   cmp\\t%1, %2\;movcs\\t%0, %1
-   cmp\\t%1, %2\;movcs\\t%0, %1\;movcc\\t%0, %2"
+  "#"
+    ; cmp\\t%1, %2\;movcc\\t%0, %2
+    ; cmp\\t%1, %2\;movcs\\t%0, %1
+    ; cmp\\t%1, %2\;movcs\\t%0, %1\;movcc\\t%0, %2"
+  "TARGET_ARM"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+        (if_then_else:SI (geu:SI (reg:CC CC_REGNUM) (const_int 0))
+                         (match_dup 1)
+                         (match_dup 2)))]
+  ""
   [(set_attr "conds" "clob")
    (set_attr "length" "8,8,12")]
 )
@@ -3340,16 +3849,24 @@
   ""
 )
 
-(define_insn "*arm_uminsi3"
+(define_insn_and_split "*arm_uminsi3"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r,r")
 	(umin:SI (match_operand:SI 1 "s_register_operand" "0,r,?r")
 		 (match_operand:SI 2 "arm_rhs_operand" "rI,0,rI")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "@
-   cmp\\t%1, %2\;movcs\\t%0, %2
-   cmp\\t%1, %2\;movcc\\t%0, %1
-   cmp\\t%1, %2\;movcc\\t%0, %1\;movcs\\t%0, %2"
+  "#"
+   ; cmp\\t%1, %2\;movcs\\t%0, %2
+   ; cmp\\t%1, %2\;movcc\\t%0, %1
+   ; cmp\\t%1, %2\;movcc\\t%0, %1\;movcs\\t%0, %2"
+  "TARGET_ARM"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+        (if_then_else:SI (ltu:SI (reg:CC CC_REGNUM) (const_int 0))
+                         (match_dup 1)
+                         (match_dup 2)))]
+  ""
   [(set_attr "conds" "clob")
    (set_attr "length" "8,8,12")]
 )
@@ -3360,7 +3877,7 @@
 	 [(match_operand:SI 1 "s_register_operand" "r")
 	  (match_operand:SI 2 "s_register_operand" "r")]))
    (clobber (reg:CC CC_REGNUM))]
-  "TARGET_32BIT"
+  "TARGET_32BIT && optimize_insn_for_size_p()"
   "*
   operands[3] = gen_rtx_fmt_ee (minmax_code (operands[3]), SImode,
 				operands[1], operands[2]);
@@ -3423,6 +3940,50 @@
 		      (const_int 12)))]
 )
 
+; Reject the frame pointer in operand[1], since reloading this after
+; it has been eliminated can cause carnage.
+(define_insn_and_split "*minmax_arithsi_non_canon"
+  [(set (match_operand:SI 0 "s_register_operand" "=r,r")
+	(minus:SI
+	 (match_operand:SI 1 "s_register_operand" "0,?r")
+	  (match_operator:SI 4 "minmax_operator"
+	   [(match_operand:SI 2 "s_register_operand" "r,r")
+	    (match_operand:SI 3 "arm_rhs_operand" "rI,rI")])))
+   (clobber (reg:CC CC_REGNUM))]
+  "TARGET_32BIT && !arm_eliminable_register (operands[1])"
+  "#"
+  "TARGET_32BIT && !arm_eliminable_register (operands[1]) && reload_completed"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 2) (match_dup 3)))
+
+   (cond_exec (match_op_dup 4 [(reg:CC CC_REGNUM) (const_int 0)])
+              (set (match_dup 0)
+                   (minus:SI (match_dup 1)
+                             (match_dup 2))))
+   (cond_exec (match_op_dup 5 [(reg:CC CC_REGNUM) (const_int 0)])
+              (set (match_dup 0)
+                   (minus:SI (match_dup 1)
+                             (match_dup 3))))]
+  {
+  enum machine_mode mode = SELECT_CC_MODE (GET_CODE (operands[1]),
+                                           operands[2], operands[3]);
+  enum rtx_code rc = minmax_code (operands[4]);
+  operands[4] = gen_rtx_fmt_ee (rc, VOIDmode,
+                                operands[2], operands[3]);
+
+  if (mode == CCFPmode || mode == CCFPEmode)
+    rc = reverse_condition_maybe_unordered (rc);
+  else
+    rc = reverse_condition (rc);
+  operands[5] = gen_rtx_fmt_ee (rc, SImode, operands[2], operands[3]);
+  }
+  [(set_attr "conds" "clob")
+   (set (attr "length")
+	(if_then_else (eq_attr "is_thumb" "yes")
+		      (const_int 14)
+		      (const_int 12)))]
+)
+
 (define_code_iterator SAT [smin smax])
 (define_code_iterator SATrev [smin smax])
 (define_code_attr SATlo [(smin "1") (smax "2")])
@@ -3533,13 +4094,26 @@
   "
 )
 
-(define_insn "arm_ashldi3_1bit"
+(define_insn_and_split "arm_ashldi3_1bit"
   [(set (match_operand:DI            0 "s_register_operand" "=r,&r")
         (ashift:DI (match_operand:DI 1 "s_register_operand" "0,r")
                    (const_int 1)))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_32BIT"
-  "movs\\t%Q0, %Q1, asl #1\;adc\\t%R0, %R1, %R1"
+  "#"   ; "movs\\t%Q0, %Q1, asl #1\;adc\\t%R0, %R1, %R1"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+		   (compare:CC (ashift:SI (match_dup 1) (const_int 1))
+                               (const_int 0)))
+	      (set (match_dup 0) (ashift:SI (match_dup 1) (const_int 1)))])
+   (set (match_dup 2) (plus:SI (plus:SI (match_dup 3) (match_dup 3))
+			       (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+    operands[2] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[3] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "conds" "clob")
    (set_attr "length" "8")]
 )
@@ -3615,18 +4189,43 @@
   "
 )
 
-(define_insn "arm_ashrdi3_1bit"
+(define_insn_and_split "arm_ashrdi3_1bit"
   [(set (match_operand:DI              0 "s_register_operand" "=r,&r")
         (ashiftrt:DI (match_operand:DI 1 "s_register_operand" "0,r")
                      (const_int 1)))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_32BIT"
-  "movs\\t%R0, %R1, asr #1\;mov\\t%Q0, %Q1, rrx"
+  "#"   ; "movs\\t%R0, %R1, asr #1\;mov\\t%Q0, %Q1, rrx"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+                   (compare:CC (ashiftrt:SI (match_dup 3) (const_int 1))
+                               (const_int 0)))
+              (set (match_dup 2) (ashiftrt:SI (match_dup 3) (const_int 1)))])
+   (set (match_dup 0) (unspec:SI [(match_dup 1)
+                                  (reg:CC_C CC_REGNUM)]
+                                 UNSPEC_RRX))]
+  {
+    operands[2] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[3] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "conds" "clob")
-   (set_attr "insn" "mov")
    (set_attr "length" "8")]
 )
 
+(define_insn "*rrx"
+  [(set (match_operand:SI 0 "s_register_operand" "=r")
+        (unspec:SI [(match_operand:SI 1 "s_register_operand" "r")
+                    (reg:CC_C CC_REGNUM)]
+                   UNSPEC_RRX))]
+  "TARGET_32BIT"
+  "mov\\t%0, %1, rrx"
+  [(set_attr "conds" "use")
+   (set_attr "insn" "mov")
+   (set_attr "type" "alu_shift")]
+)
+
 (define_expand "ashrsi3"
   [(set (match_operand:SI              0 "s_register_operand" "")
 	(ashiftrt:SI (match_operand:SI 1 "s_register_operand" "")
@@ -3695,15 +4294,28 @@
   "
 )
 
-(define_insn "arm_lshrdi3_1bit"
+(define_insn_and_split "arm_lshrdi3_1bit"
   [(set (match_operand:DI              0 "s_register_operand" "=r,&r")
         (lshiftrt:DI (match_operand:DI 1 "s_register_operand" "0,r")
                      (const_int 1)))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_32BIT"
-  "movs\\t%R0, %R1, lsr #1\;mov\\t%Q0, %Q1, rrx"
+  "#"   ;  "movs\\t%R0, %R1, lsr #1\;mov\\t%Q0, %Q1, rrx"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+                   (compare:CC (lshiftrt:SI (match_dup 3) (const_int 1))
+                               (const_int 0)))
+              (set (match_dup 2) (lshiftrt:SI (match_dup 3) (const_int 1)))])
+   (set (match_dup 0) (unspec:SI [(match_dup 1)
+                                  (reg:CC_C CC_REGNUM)]
+                                 UNSPEC_RRX))]
+  {
+    operands[2] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[3] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "conds" "clob")
-   (set_attr "insn" "mov")
    (set_attr "length" "8")]
 )
 
@@ -3791,6 +4403,23 @@
 		      (const_string "alu_shift_reg")))]
 )
 
+(define_insn "*shiftsi3_compare"
+  [(set (reg:CC CC_REGNUM)
+	(compare:CC (match_operator:SI 3 "shift_operator"
+			  [(match_operand:SI 1 "s_register_operand" "r")
+			   (match_operand:SI 2 "arm_rhs_operand" "rM")])
+                    (const_int 0)))
+   (set (match_operand:SI 0 "s_register_operand" "=r")
+	(match_op_dup 3 [(match_dup 1) (match_dup 2)]))]
+  "TARGET_32BIT"
+  "* return arm_output_shift(operands, 1);"
+  [(set_attr "conds" "set")
+   (set_attr "shift" "1")
+   (set (attr "type") (if_then_else (match_operand 2 "const_int_operand" "")
+		      (const_string "alu_shift")
+		      (const_string "alu_shift_reg")))]
+)
+
 (define_insn "*shiftsi3_compare0"
   [(set (reg:CC_NOOV CC_REGNUM)
 	(compare:CC_NOOV (match_operator:SI 3 "shift_operator"
@@ -3829,6 +4458,7 @@
   "TARGET_32BIT"
   "mvn%?\\t%0, %1%S3"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "shift" "1")
    (set_attr "insn" "mvn")
    (set_attr "arch" "32,a")
@@ -4042,6 +4672,7 @@
   [(set_attr "arch" "t2,any")
    (set_attr "length" "2,4")
    (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "yes,no")
    (set_attr "type" "load1")])
 
 (define_insn "unaligned_loadhis"
@@ -4054,6 +4685,7 @@
   [(set_attr "arch" "t2,any")
    (set_attr "length" "2,4")
    (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "yes,no")
    (set_attr "type" "load_byte")])
 
 (define_insn "unaligned_loadhiu"
@@ -4066,6 +4698,7 @@
   [(set_attr "arch" "t2,any")
    (set_attr "length" "2,4")
    (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "yes,no")
    (set_attr "type" "load_byte")])
 
 (define_insn "unaligned_storesi"
@@ -4077,18 +4710,78 @@
   [(set_attr "arch" "t2,any")
    (set_attr "length" "2,4")
    (set_attr "predicable" "yes")
-   (set_attr "type" "store1")])
+   (set_attr "predicable_short_it" "yes,no")
+   (set_attr "type" "store1")])
+
+(define_insn "unaligned_storehi"
+  [(set (match_operand:HI 0 "memory_operand" "=Uw,m")
+	(unspec:HI [(match_operand:HI 1 "s_register_operand" "l,r")]
+		   UNSPEC_UNALIGNED_STORE))]
+  "unaligned_access && TARGET_32BIT"
+  "str%(h%)\t%1, %0\t@ unaligned"
+  [(set_attr "arch" "t2,any")
+   (set_attr "length" "2,4")
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "yes,no")
+   (set_attr "type" "store1")])
+
+;; Unaligned double-word load and store.
+;; Split after reload into two unaligned single-word accesses.
+;; It prevents lower_subreg from splitting some other aligned
+;; double-word accesses too early. Used for internal memcpy.
+
+(define_insn_and_split "unaligned_loaddi"
+  [(set (match_operand:DI 0 "s_register_operand" "=l,r")
+	(unspec:DI [(match_operand:DI 1 "memory_operand" "o,o")]
+		   UNSPEC_UNALIGNED_LOAD))]
+  "unaligned_access && TARGET_32BIT"
+  "#"
+  "&& reload_completed"
+  [(set (match_dup 0) (unspec:SI [(match_dup 1)] UNSPEC_UNALIGNED_LOAD))
+   (set (match_dup 2) (unspec:SI [(match_dup 3)] UNSPEC_UNALIGNED_LOAD))]
+  {
+    operands[2] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[3] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+
+    /* If the first destination register overlaps with the base address,
+       swap the order in which the loads are emitted.  */
+    if (reg_overlap_mentioned_p (operands[0], operands[1]))
+      {
+        rtx tmp = operands[1];
+        operands[1] = operands[3];
+        operands[3] = tmp;
+        tmp = operands[0];
+        operands[0] = operands[2];
+        operands[2] = tmp;
+      }
+  }
+  [(set_attr "arch" "t2,any")
+   (set_attr "length" "4,8")
+   (set_attr "predicable" "yes")
+   (set_attr "type" "load2")])
 
-(define_insn "unaligned_storehi"
-  [(set (match_operand:HI 0 "memory_operand" "=Uw,m")
-	(unspec:HI [(match_operand:HI 1 "s_register_operand" "l,r")]
+(define_insn_and_split "unaligned_storedi"
+  [(set (match_operand:DI 0 "memory_operand" "=o,o")
+	(unspec:DI [(match_operand:DI 1 "s_register_operand" "l,r")]
 		   UNSPEC_UNALIGNED_STORE))]
   "unaligned_access && TARGET_32BIT"
-  "str%(h%)\t%1, %0\t@ unaligned"
+  "#"
+  "&& reload_completed"
+  [(set (match_dup 0) (unspec:SI [(match_dup 1)] UNSPEC_UNALIGNED_STORE))
+   (set (match_dup 2) (unspec:SI [(match_dup 3)] UNSPEC_UNALIGNED_STORE))]
+  {
+    operands[2] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[3] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "arch" "t2,any")
-   (set_attr "length" "2,4")
+   (set_attr "length" "4,8")
    (set_attr "predicable" "yes")
-   (set_attr "type" "store1")])
+   (set_attr "type" "store2")])
+
 
 (define_insn "*extv_reg"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
@@ -4098,7 +4791,8 @@
   "arm_arch_thumb2"
   "sbfx%?\t%0, %1, %3, %2"
   [(set_attr "length" "4")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_insn "extzv_t2"
@@ -4109,7 +4803,8 @@
   "arm_arch_thumb2"
   "ubfx%?\t%0, %1, %3, %2"
   [(set_attr "length" "4")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 
@@ -4121,7 +4816,8 @@
   "TARGET_IDIV"
   "sdiv%?\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "insn" "sdiv")]
+   (set_attr "predicable_short_it" "no")
+   (set_attr "type" "sdiv")]
 )
 
 (define_insn "udivsi3"
@@ -4131,7 +4827,8 @@
   "TARGET_IDIV"
   "udiv%?\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "insn" "udiv")]
+   (set_attr "predicable_short_it" "no")
+   (set_attr "type" "udiv")]
 )
 
 
@@ -4154,12 +4851,24 @@
 
 ;; The constraints here are to prevent a *partial* overlap (where %Q0 == %R1).
 ;; The first alternative allows the common case of a *full* overlap.
-(define_insn "*arm_negdi2"
+(define_insn_and_split "*arm_negdi2"
   [(set (match_operand:DI         0 "s_register_operand" "=r,&r")
 	(neg:DI (match_operand:DI 1 "s_register_operand"  "0,r")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "rsbs\\t%Q0, %Q1, #0\;rsc\\t%R0, %R1, #0"
+  "#"   ; "rsbs\\t%Q0, %Q1, #0\;rsc\\t%R0, %R1, #0"
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+		   (compare:CC (const_int 0) (match_dup 1)))
+	      (set (match_dup 0) (minus:SI (const_int 0) (match_dup 1)))])
+   (set (match_dup 2) (minus:SI (minus:SI (const_int 0) (match_dup 3))
+                                (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+    operands[2] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[3] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "conds" "clob")
    (set_attr "length" "8")]
 )
@@ -4181,11 +4890,14 @@
 )
 
 (define_insn "*arm_negsi2"
-  [(set (match_operand:SI         0 "s_register_operand" "=r")
-	(neg:SI (match_operand:SI 1 "s_register_operand" "r")))]
+  [(set (match_operand:SI         0 "s_register_operand" "=l,r")
+	(neg:SI (match_operand:SI 1 "s_register_operand" "l,r")))]
   "TARGET_32BIT"
   "rsb%?\\t%0, %1, #0"
-  [(set_attr "predicable" "yes")]
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "yes,no")
+   (set_attr "arch" "t2,*")
+   (set_attr "length" "4")]
 )
 
 (define_insn "*thumb1_negsi2"
@@ -4209,6 +4921,73 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "")
 
+;; Negate an extended 32-bit value.
+(define_insn_and_split "*negdi_extendsidi"
+  [(set (match_operand:DI 0 "s_register_operand" "=r,&r,l,&l")
+	(neg:DI (sign_extend:DI (match_operand:SI 1 "s_register_operand" "0,r,0,l"))))
+   (clobber (reg:CC CC_REGNUM))]
+  "TARGET_32BIT"
+  "#" ; rsb\\t%Q0, %1, #0\;asr\\t%R0, %Q0, #31
+  "&& reload_completed"
+  [(const_int 0)]
+  {
+     operands[2] = gen_highpart (SImode, operands[0]);
+     operands[0] = gen_lowpart (SImode, operands[0]);
+     rtx tmp = gen_rtx_SET (VOIDmode,
+                            operands[0],
+                            gen_rtx_MINUS (SImode,
+                                           const0_rtx,
+                                           operands[1]));
+     if (TARGET_ARM)
+       {
+         emit_insn (tmp);
+       }
+     else
+       {
+         /* Set the flags, to emit the short encoding in Thumb2.  */
+         rtx flags = gen_rtx_SET (VOIDmode,
+                                  gen_rtx_REG (CCmode, CC_REGNUM),
+                                  gen_rtx_COMPARE (CCmode,
+                                                   const0_rtx,
+                                                   operands[1]));
+         emit_insn (gen_rtx_PARALLEL (VOIDmode,
+                                      gen_rtvec (2,
+                                                 flags,
+                                                 tmp)));
+       }
+       emit_insn (gen_rtx_SET (VOIDmode,
+                              operands[2],
+                              gen_rtx_ASHIFTRT (SImode,
+                                                operands[0],
+                                                GEN_INT (31))));
+     DONE;
+  }
+  [(set_attr "length" "8,8,4,4")
+   (set_attr "arch" "a,a,t2,t2")]
+)
+
+(define_insn_and_split "*negdi_zero_extendsidi"
+  [(set (match_operand:DI 0 "s_register_operand" "=r,&r")
+	(neg:DI (zero_extend:DI (match_operand:SI 1 "s_register_operand" "0,r"))))
+   (clobber (reg:CC CC_REGNUM))]
+  "TARGET_32BIT"
+  "#" ; "rsbs\\t%Q0, %1, #0\;sbc\\t%R0,%R0,%R0"
+      ;; Don't care what register is input to sbc,
+      ;; since we just just need to propagate the carry.
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+                   (compare:CC (const_int 0) (match_dup 1)))
+              (set (match_dup 0) (minus:SI (const_int 0) (match_dup 1)))])
+   (set (match_dup 2) (minus:SI (minus:SI (match_dup 2) (match_dup 2))
+                                (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+    operands[2] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+  }
+  [(set_attr "conds" "clob")
+   (set_attr "length" "8")]   ;; length in thumb is 4
+)
+
 ;; abssi2 doesn't really clobber the condition codes if a different register
 ;; is being set.  To keep things simple, assume during rtl manipulations that
 ;; it does, but tell the final scan operator the truth.  Similarly for
@@ -4227,14 +5006,67 @@
     operands[2] = gen_rtx_REG (CCmode, CC_REGNUM);
 ")
 
-(define_insn "*arm_abssi2"
+(define_insn_and_split "*arm_abssi2"
   [(set (match_operand:SI 0 "s_register_operand" "=r,&r")
 	(abs:SI (match_operand:SI 1 "s_register_operand" "0,r")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "@
-   cmp\\t%0, #0\;rsblt\\t%0, %0, #0
-   eor%?\\t%0, %1, %1, asr #31\;sub%?\\t%0, %0, %1, asr #31"
+  "#"
+  "&& reload_completed"
+  [(const_int 0)]
+  {
+   /* if (which_alternative == 0) */
+   if (REGNO(operands[0]) == REGNO(operands[1]))
+     {
+      /* Emit the pattern:
+         cmp\\t%0, #0\;rsblt\\t%0, %0, #0
+         [(set (reg:CC CC_REGNUM)
+               (compare:CC (match_dup 0) (const_int 0)))
+          (cond_exec (lt:CC (reg:CC CC_REGNUM) (const_int 0))
+                     (set (match_dup 0) (minus:SI (const_int 0) (match_dup 1))))]
+      */
+      emit_insn (gen_rtx_SET (VOIDmode,
+                              gen_rtx_REG (CCmode, CC_REGNUM),
+                              gen_rtx_COMPARE (CCmode, operands[0], const0_rtx)));
+      emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                    (gen_rtx_LT (SImode,
+                                                 gen_rtx_REG (CCmode, CC_REGNUM),
+                                                 const0_rtx)),
+                                    (gen_rtx_SET (VOIDmode,
+                                                  operands[0],
+                                                  (gen_rtx_MINUS (SImode,
+                                                                  const0_rtx,
+                                                                  operands[1]))))));
+      DONE;
+     }
+   else
+     {
+      /* Emit the pattern:
+         alt1: eor%?\\t%0, %1, %1, asr #31\;sub%?\\t%0, %0, %1, asr #31
+         [(set (match_dup 0)
+               (xor:SI (match_dup 1)
+                       (ashiftrt:SI (match_dup 1) (const_int 31))))
+          (set (match_dup 0)
+               (minus:SI (match_dup 0)
+                      (ashiftrt:SI (match_dup 1) (const_int 31))))]
+      */
+      emit_insn (gen_rtx_SET (VOIDmode,
+                              operands[0],
+                              gen_rtx_XOR (SImode,
+                                           gen_rtx_ASHIFTRT (SImode,
+                                                             operands[1],
+                                                             GEN_INT (31)),
+                                           operands[1])));
+      emit_insn (gen_rtx_SET (VOIDmode,
+                              operands[0],
+                              gen_rtx_MINUS (SImode,
+                                             operands[0],
+                                             gen_rtx_ASHIFTRT (SImode,
+                                                               operands[1],
+                                                               GEN_INT (31)))));
+      DONE;
+     }
+  }
   [(set_attr "conds" "clob,*")
    (set_attr "shift" "1")
    (set_attr "predicable" "no, yes")
@@ -4255,14 +5087,56 @@
   [(set_attr "length" "6")]
 )
 
-(define_insn "*arm_neg_abssi2"
+(define_insn_and_split "*arm_neg_abssi2"
   [(set (match_operand:SI 0 "s_register_operand" "=r,&r")
 	(neg:SI (abs:SI (match_operand:SI 1 "s_register_operand" "0,r"))))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "@
-   cmp\\t%0, #0\;rsbgt\\t%0, %0, #0
-   eor%?\\t%0, %1, %1, asr #31\;rsb%?\\t%0, %0, %1, asr #31"
+  "#"
+  "&& reload_completed"
+  [(const_int 0)]
+  {
+   /* if (which_alternative == 0) */
+   if (REGNO (operands[0]) == REGNO (operands[1]))
+     {
+      /* Emit the pattern:
+         cmp\\t%0, #0\;rsbgt\\t%0, %0, #0
+      */
+      emit_insn (gen_rtx_SET (VOIDmode,
+                              gen_rtx_REG (CCmode, CC_REGNUM),
+                              gen_rtx_COMPARE (CCmode, operands[0], const0_rtx)));
+      emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                    gen_rtx_GT (SImode,
+                                                gen_rtx_REG (CCmode, CC_REGNUM),
+                                                const0_rtx),
+                                    gen_rtx_SET (VOIDmode,
+                                                 operands[0],
+                                                 (gen_rtx_MINUS (SImode,
+                                                                 const0_rtx,
+                                                                 operands[1])))));
+     }
+   else
+     {
+      /* Emit the pattern:
+         eor%?\\t%0, %1, %1, asr #31\;rsb%?\\t%0, %0, %1, asr #31
+      */
+      emit_insn (gen_rtx_SET (VOIDmode,
+                              operands[0],
+                              gen_rtx_XOR (SImode,
+                                           gen_rtx_ASHIFTRT (SImode,
+                                                             operands[1],
+                                                             GEN_INT (31)),
+                                           operands[1])));
+      emit_insn (gen_rtx_SET (VOIDmode,
+                              operands[0],
+                              gen_rtx_MINUS (SImode,
+                                             gen_rtx_ASHIFTRT (SImode,
+                                                               operands[1],
+                                                               GEN_INT (31)),
+                                             operands[0])));
+     }
+   DONE;
+  }
   [(set_attr "conds" "clob,*")
    (set_attr "shift" "1")
    (set_attr "predicable" "no, yes")
@@ -4330,7 +5204,7 @@
   [(set_attr "length" "*,8,8,*")
    (set_attr "predicable" "no,yes,yes,no")
    (set_attr "neon_type" "neon_int_1,*,*,neon_int_1")
-   (set_attr "arch" "neon_nota8,*,*,neon_onlya8")]
+   (set_attr "arch" "neon_for_64bits,*,*,avoid_neon_for_64bits")]
 )
 
 (define_expand "one_cmplsi2"
@@ -4341,11 +5215,14 @@
 )
 
 (define_insn "*arm_one_cmplsi2"
-  [(set (match_operand:SI         0 "s_register_operand" "=r")
-	(not:SI (match_operand:SI 1 "s_register_operand"  "r")))]
+  [(set (match_operand:SI         0 "s_register_operand" "=l,r")
+	(not:SI (match_operand:SI 1 "s_register_operand"  "l,r")))]
   "TARGET_32BIT"
   "mvn%?\\t%0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "yes,no")
+   (set_attr "arch" "t2,*")
+   (set_attr "length" "4")
    (set_attr "insn" "mvn")]
 )
 
@@ -4498,7 +5375,7 @@
   "TARGET_32BIT <qhs_zextenddi_cond>"
   "#"
   [(set_attr "length" "8,4,8,8")
-   (set_attr "arch" "neon_nota8,*,*,neon_onlya8")
+   (set_attr "arch" "neon_for_64bits,*,*,avoid_neon_for_64bits")
    (set_attr "ce_count" "2")
    (set_attr "predicable" "yes")]
 )
@@ -4513,7 +5390,7 @@
    (set_attr "ce_count" "2")
    (set_attr "shift" "1")
    (set_attr "predicable" "yes")
-   (set_attr "arch" "neon_nota8,*,a,t,neon_onlya8")]
+   (set_attr "arch" "neon_for_64bits,*,a,t,avoid_neon_for_64bits")]
 )
 
 ;; Splits for all extensions to DImode
@@ -4671,7 +5548,8 @@
   "TARGET_INT_SIMD"
   "uxtah%?\\t%0, %2, %1"
   [(set_attr "type" "alu_shift")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_expand "zero_extendqisi2"
@@ -4764,6 +5642,7 @@
   "TARGET_INT_SIMD"
   "uxtab%?\\t%0, %2, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "insn" "xtab")
    (set_attr "type" "alu_shift")]
 )
@@ -4816,7 +5695,8 @@
   "TARGET_32BIT"
   "tst%?\\t%0, #255"
   [(set_attr "conds" "set")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_expand "extendhisi2"
@@ -5002,6 +5882,7 @@
    ldr%(sh%)\\t%0, %1"
   [(set_attr "type" "simple_alu_shift,load_byte")
    (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "pool_range" "*,256")
    (set_attr "neg_pool_range" "*,244")]
 )
@@ -5114,7 +5995,8 @@
   "sxtab%?\\t%0, %2, %1"
   [(set_attr "type" "alu_shift")
    (set_attr "insn" "xtab")
-   (set_attr "predicable" "yes")]
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")]
 )
 
 (define_split
@@ -5313,8 +6195,8 @@
 )
 
 (define_insn "*arm_movdi"
-  [(set (match_operand:DI 0 "nonimmediate_di_operand" "=r, r, r, r, m")
-	(match_operand:DI 1 "di_operand"              "rDa,Db,Dc,mi,r"))]
+  [(set (match_operand:DI 0 "nonimmediate_di_operand" "=r, r, r, q, m")
+	(match_operand:DI 1 "di_operand"              "rDa,Db,Dc,mi,q"))]
   "TARGET_32BIT
    && !(TARGET_HARD_FLOAT && TARGET_VFP)
    && !TARGET_IWMMXT
@@ -5570,6 +6452,7 @@
   "arm_arch_thumb2"
   "movt%?\t%0, #:upper16:%c2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "length" "4")]
 )
 
@@ -6365,7 +7248,7 @@
 (define_expand "reload_inhi"
   [(parallel [(match_operand:HI 0 "s_register_operand" "=r")
 	      (match_operand:HI 1 "arm_reload_memory_operand" "o")
-	      (match_operand:DI 2 "s_register_operand" "=&r")])]
+	      (match_operand:DI 2 "s_register_operand" "=&l")])]
   "TARGET_EITHER"
   "
   if (TARGET_ARM)
@@ -6449,26 +7332,28 @@
   "
 )
 
-
 (define_insn "*arm_movqi_insn"
-  [(set (match_operand:QI 0 "nonimmediate_operand" "=r,r,r,l,Uu,r,m")
-	(match_operand:QI 1 "general_operand" "r,I,K,Uu,l,m,r"))]
+  [(set (match_operand:QI 0 "nonimmediate_operand" "=r,r,r,l,r,l,Uu,r,m")
+	(match_operand:QI 1 "general_operand" "r,r,I,Py,K,Uu,l,m,r"))]
   "TARGET_32BIT
    && (   register_operand (operands[0], QImode)
        || register_operand (operands[1], QImode))"
   "@
    mov%?\\t%0, %1
    mov%?\\t%0, %1
+   mov%?\\t%0, %1
+   mov%?\\t%0, %1
    mvn%?\\t%0, #%B1
    ldr%(b%)\\t%0, %1
    str%(b%)\\t%1, %0
    ldr%(b%)\\t%0, %1
    str%(b%)\\t%1, %0"
-  [(set_attr "type" "*,simple_alu_imm,simple_alu_imm,load1, store1, load1, store1")
-   (set_attr "insn" "mov,mov,mvn,*,*,*,*")
+  [(set_attr "type" "*,*,simple_alu_imm,simple_alu_imm,simple_alu_imm,load1, store1, load1, store1")
+   (set_attr "insn" "mov,mov,mov,mov,mvn,*,*,*,*")
    (set_attr "predicable" "yes")
-   (set_attr "arch" "any,any,any,t2,t2,any,any")
-   (set_attr "length" "4,4,4,2,2,4,4")]
+   (set_attr "predicable_short_it" "yes,yes,yes,no,no,no,no,no,no")
+   (set_attr "arch" "t2,any,any,t2,any,t2,t2,any,any")
+   (set_attr "length" "2,4,4,2,4,2,2,4,4")]
 )
 
 (define_insn "*thumb1_movqi_insn"
@@ -6738,8 +7623,8 @@
 )
 
 (define_insn "*movdf_soft_insn"
-  [(set (match_operand:DF 0 "nonimmediate_soft_df_operand" "=r,r,r,r,m")
-	(match_operand:DF 1 "soft_df_operand" "rDa,Db,Dc,mF,r"))]
+  [(set (match_operand:DF 0 "nonimmediate_soft_df_operand" "=r,r,r,q,m")
+	(match_operand:DF 1 "soft_df_operand" "rDa,Db,Dc,mF,q"))]
   "TARGET_32BIT && TARGET_SOFT_FLOAT
    && (   register_operand (operands[0], DFmode)
        || register_operand (operands[1], DFmode))"
@@ -6869,10 +7754,18 @@
    (match_operand:BLK 1 "general_operand" "")
    (match_operand:SI 2 "const_int_operand" "")
    (match_operand:SI 3 "const_int_operand" "")]
-  "TARGET_EITHER"
+  ""
   "
   if (TARGET_32BIT)
     {
+      if (TARGET_LDRD && current_tune->prefer_ldrd_strd
+          && !optimize_function_for_size_p (cfun))
+        {
+          if (gen_movmem_ldrd_strd (operands))
+            DONE;
+          FAIL;
+        }
+
       if (arm_gen_movmemqi (operands))
         DONE;
       FAIL;
@@ -7617,23 +8510,64 @@
 ;; if-conversion can not reduce to a conditional compare, so we do
 ;; that directly.
 
-(define_insn "*arm_cmpdi_insn"
+(define_insn_and_split "*arm_cmpdi_insn"
   [(set (reg:CC_NCV CC_REGNUM)
 	(compare:CC_NCV (match_operand:DI 0 "s_register_operand" "r")
 			(match_operand:DI 1 "arm_di_operand"	   "rDi")))
    (clobber (match_scratch:SI 2 "=r"))]
   "TARGET_32BIT"
-  "cmp\\t%Q0, %Q1\;sbcs\\t%2, %R0, %R1"
+  "#"   ; "cmp\\t%Q0, %Q1\;sbcs\\t%2, %R0, %R1"
+  "&& reload_completed"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 0) (match_dup 1)))
+   (parallel [(set (reg:CC CC_REGNUM)
+                   (compare:CC (match_dup 3) (match_dup 4)))
+              (set (match_dup 2)
+                   (minus:SI (match_dup 5)
+                            (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))])]
+  {
+    operands[3] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    if (CONST_INT_P (operands[1]))
+      {
+        operands[4] = GEN_INT (~INTVAL (gen_highpart_mode (SImode,
+                                                           DImode,
+                                                           operands[1])));
+        operands[5] = gen_rtx_PLUS (SImode, operands[3], operands[4]);
+      }
+    else
+      {
+        operands[4] = gen_highpart (SImode, operands[1]);
+        operands[5] = gen_rtx_MINUS (SImode, operands[3], operands[4]);
+      }
+    operands[1] = gen_lowpart (SImode, operands[1]);
+    operands[2] = gen_lowpart (SImode, operands[2]);
+  }
   [(set_attr "conds" "set")
    (set_attr "length" "8")]
 )
 
-(define_insn "*arm_cmpdi_unsigned"
+(define_insn_and_split "*arm_cmpdi_unsigned"
   [(set (reg:CC_CZ CC_REGNUM)
 	(compare:CC_CZ (match_operand:DI 0 "s_register_operand" "r")
 		       (match_operand:DI 1 "arm_di_operand"	"rDi")))]
   "TARGET_32BIT"
-  "cmp\\t%R0, %R1\;it eq\;cmpeq\\t%Q0, %Q1"
+  "#"   ; "cmp\\t%R0, %R1\;it eq\;cmpeq\\t%Q0, %Q1"
+  "&& reload_completed"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 2) (match_dup 3)))
+   (cond_exec (eq:SI (reg:CC CC_REGNUM) (const_int 0))
+              (set (reg:CC CC_REGNUM)
+                   (compare:CC (match_dup 0) (match_dup 1))))]
+  {
+    operands[2] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    if (CONST_INT_P (operands[1]))
+      operands[3] = gen_highpart_mode (SImode, DImode, operands[1]);
+    else
+      operands[3] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "conds" "set")
    (set_attr "length" "8")]
 )
@@ -7758,36 +8692,56 @@
    operands[3] = const0_rtx;"
 )
 
-(define_insn "*mov_scc"
+(define_insn_and_split "*mov_scc"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(match_operator:SI 1 "arm_comparison_operator"
 	 [(match_operand 2 "cc_register" "") (const_int 0)]))]
   "TARGET_ARM"
-  "mov%D1\\t%0, #0\;mov%d1\\t%0, #1"
+  "#"   ; "mov%D1\\t%0, #0\;mov%d1\\t%0, #1"
+  "TARGET_ARM"
+  [(set (match_dup 0)
+        (if_then_else:SI (match_dup 1)
+                         (const_int 1)
+                         (const_int 0)))]
+  ""
   [(set_attr "conds" "use")
-   (set_attr "insn" "mov")
    (set_attr "length" "8")]
 )
 
-(define_insn "*mov_negscc"
+(define_insn_and_split "*mov_negscc"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(neg:SI (match_operator:SI 1 "arm_comparison_operator"
 		 [(match_operand 2 "cc_register" "") (const_int 0)])))]
   "TARGET_ARM"
-  "mov%D1\\t%0, #0\;mvn%d1\\t%0, #0"
+  "#"   ; "mov%D1\\t%0, #0\;mvn%d1\\t%0, #0"
+  "TARGET_ARM"
+  [(set (match_dup 0)
+        (if_then_else:SI (match_dup 1)
+                         (match_dup 3)
+                         (const_int 0)))]
+  {
+    operands[3] = GEN_INT (~0);
+  }
   [(set_attr "conds" "use")
-   (set_attr "insn" "mov")
    (set_attr "length" "8")]
 )
 
-(define_insn "*mov_notscc"
+(define_insn_and_split "*mov_notscc"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(not:SI (match_operator:SI 1 "arm_comparison_operator"
 		 [(match_operand 2 "cc_register" "") (const_int 0)])))]
   "TARGET_ARM"
-  "mvn%D1\\t%0, #0\;mvn%d1\\t%0, #1"
+  "#"   ; "mvn%D1\\t%0, #0\;mvn%d1\\t%0, #1"
+  "TARGET_ARM"
+  [(set (match_dup 0)
+        (if_then_else:SI (match_dup 1)
+                         (match_dup 3)
+                         (match_dup 4)))]
+  {
+    operands[3] = GEN_INT (~1);
+    operands[4] = GEN_INT (~0);
+  }
   [(set_attr "conds" "use")
-   (set_attr "insn" "mov")
    (set_attr "length" "8")]
 )
 
@@ -8069,7 +9023,7 @@
 
 (define_expand "movsfcc"
   [(set (match_operand:SF 0 "s_register_operand" "")
-	(if_then_else:SF (match_operand 1 "expandable_comparison_operator" "")
+	(if_then_else:SF (match_operand 1 "arm_cond_move_operator" "")
 			 (match_operand:SF 2 "s_register_operand" "")
 			 (match_operand:SF 3 "s_register_operand" "")))]
   "TARGET_32BIT && TARGET_HARD_FLOAT"
@@ -8091,7 +9045,7 @@
 
 (define_expand "movdfcc"
   [(set (match_operand:DF 0 "s_register_operand" "")
-	(if_then_else:DF (match_operand 1 "expandable_comparison_operator" "")
+	(if_then_else:DF (match_operand 1 "arm_cond_move_operator" "")
 			 (match_operand:DF 2 "s_register_operand" "")
 			 (match_operand:DF 3 "s_register_operand" "")))]
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
@@ -8110,7 +9064,40 @@
   }"
 )
 
-(define_insn "*movsicc_insn"
+(define_insn "*cmov<mode>"
+    [(set (match_operand:SDF 0 "s_register_operand" "=<F_constraint>")
+	(if_then_else:SDF (match_operator 1 "arm_vsel_comparison_operator"
+			  [(match_operand 2 "cc_register" "") (const_int 0)])
+			  (match_operand:SDF 3 "s_register_operand"
+			                      "<F_constraint>")
+			  (match_operand:SDF 4 "s_register_operand"
+			                      "<F_constraint>")))]
+  "TARGET_HARD_FLOAT && TARGET_FPU_ARMV8 <vfp_double_cond>"
+  "*
+  {
+    enum arm_cond_code code = maybe_get_arm_condition_code (operands[1]);
+    switch (code)
+      {
+      case ARM_GE:
+      case ARM_GT:
+      case ARM_EQ:
+      case ARM_VS:
+        return \"vsel%d1.<V_if_elem>\\t%<V_reg>0, %<V_reg>3, %<V_reg>4\";
+      case ARM_LT:
+      case ARM_LE:
+      case ARM_NE:
+      case ARM_VC:
+        return \"vsel%D1.<V_if_elem>\\t%<V_reg>0, %<V_reg>4, %<V_reg>3\";
+      default:
+        gcc_unreachable ();
+      }
+    return \"\";
+  }"
+  [(set_attr "conds" "use")
+   (set_attr "type" "f_sel<vfp_type>")]
+)
+
+(define_insn_and_split "*movsicc_insn"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r,r,r,r,r,r,r")
 	(if_then_else:SI
 	 (match_operator 3 "arm_comparison_operator"
@@ -8123,10 +9110,45 @@
    mvn%D3\\t%0, #%B2
    mov%d3\\t%0, %1
    mvn%d3\\t%0, #%B1
-   mov%d3\\t%0, %1\;mov%D3\\t%0, %2
-   mov%d3\\t%0, %1\;mvn%D3\\t%0, #%B2
-   mvn%d3\\t%0, #%B1\;mov%D3\\t%0, %2
-   mvn%d3\\t%0, #%B1\;mvn%D3\\t%0, #%B2"
+   #
+   #
+   #
+   #"
+   ; alt4: mov%d3\\t%0, %1\;mov%D3\\t%0, %2
+   ; alt5: mov%d3\\t%0, %1\;mvn%D3\\t%0, #%B2
+   ; alt6: mvn%d3\\t%0, #%B1\;mov%D3\\t%0, %2
+   ; alt7: mvn%d3\\t%0, #%B1\;mvn%D3\\t%0, #%B2"
+  "&& reload_completed"
+  [(const_int 0)]
+  {
+    enum rtx_code rev_code;
+    enum machine_mode mode;
+    rtx rev_cond;
+
+    emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                  operands[3],
+                                  gen_rtx_SET (VOIDmode,
+                                               operands[0],
+                                               operands[1])));
+
+    rev_code = GET_CODE (operands[3]);
+    mode = GET_MODE (operands[4]);
+    if (mode == CCFPmode || mode == CCFPEmode)
+      rev_code = reverse_condition_maybe_unordered (rev_code);
+    else
+      rev_code = reverse_condition (rev_code);
+
+    rev_cond = gen_rtx_fmt_ee (rev_code,
+                               VOIDmode,
+                               operands[4],
+                               const0_rtx);
+    emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                  rev_cond,
+                                  gen_rtx_SET (VOIDmode,
+                                               operands[0],
+                                               operands[2])));
+    DONE;
+  }
   [(set_attr "length" "4,4,4,4,8,8,8,8")
    (set_attr "conds" "use")
    (set_attr "insn" "mov,mvn,mov,mvn,mov,mov,mvn,mvn")
@@ -8255,7 +9277,7 @@
          (match_operand 1 "" ""))
    (use (match_operand 2 "" ""))
    (clobber (reg:SI LR_REGNUM))]
-  "TARGET_ARM && arm_arch5"
+  "TARGET_ARM && arm_arch5 && !SIBLING_CALL_P (insn)"
   "blx%?\\t%0"
   [(set_attr "type" "call")]
 )
@@ -8265,7 +9287,7 @@
          (match_operand 1 "" ""))
    (use (match_operand 2 "" ""))
    (clobber (reg:SI LR_REGNUM))]
-  "TARGET_ARM && !arm_arch5"
+  "TARGET_ARM && !arm_arch5 && !SIBLING_CALL_P (insn)"
   "*
   return output_call (operands);
   "
@@ -8284,7 +9306,7 @@
 	 (match_operand 1 "" ""))
    (use (match_operand 2 "" ""))
    (clobber (reg:SI LR_REGNUM))]
-  "TARGET_ARM && !arm_arch5"
+  "TARGET_ARM && !arm_arch5 && !SIBLING_CALL_P (insn)"
   "*
   return output_call_mem (operands);
   "
@@ -8297,7 +9319,7 @@
 	 (match_operand 1 "" ""))
    (use (match_operand 2 "" ""))
    (clobber (reg:SI LR_REGNUM))]
-  "TARGET_THUMB1 && arm_arch5"
+  "TARGET_THUMB1 && arm_arch5 && !SIBLING_CALL_P (insn)"
   "blx\\t%0"
   [(set_attr "length" "2")
    (set_attr "type" "call")]
@@ -8308,7 +9330,7 @@
 	 (match_operand 1 "" ""))
    (use (match_operand 2 "" ""))
    (clobber (reg:SI LR_REGNUM))]
-  "TARGET_THUMB1 && !arm_arch5"
+  "TARGET_THUMB1 && !arm_arch5 && !SIBLING_CALL_P (insn)"
   "*
   {
     if (!TARGET_CALLER_INTERWORKING)
@@ -8367,7 +9389,7 @@
 	      (match_operand 2 "" "")))
    (use (match_operand 3 "" ""))
    (clobber (reg:SI LR_REGNUM))]
-  "TARGET_ARM && arm_arch5"
+  "TARGET_ARM && arm_arch5 && !SIBLING_CALL_P (insn)"
   "blx%?\\t%1"
   [(set_attr "type" "call")]
 )
@@ -8378,7 +9400,7 @@
 	      (match_operand 2 "" "")))
    (use (match_operand 3 "" ""))
    (clobber (reg:SI LR_REGNUM))]
-  "TARGET_ARM && !arm_arch5"
+  "TARGET_ARM && !arm_arch5 && !SIBLING_CALL_P (insn)"
   "*
   return output_call (&operands[1]);
   "
@@ -8394,7 +9416,8 @@
 	      (match_operand 2 "" "")))
    (use (match_operand 3 "" ""))
    (clobber (reg:SI LR_REGNUM))]
-  "TARGET_ARM && !arm_arch5 && (!CONSTANT_ADDRESS_P (XEXP (operands[1], 0)))"
+  "TARGET_ARM && !arm_arch5 && (!CONSTANT_ADDRESS_P (XEXP (operands[1], 0)))
+   && !SIBLING_CALL_P (insn)"
   "*
   return output_call_mem (&operands[1]);
   "
@@ -8444,6 +9467,7 @@
    (use (match_operand 2 "" ""))
    (clobber (reg:SI LR_REGNUM))]
   "TARGET_32BIT
+   && !SIBLING_CALL_P (insn)
    && (GET_CODE (operands[0]) == SYMBOL_REF)
    && !arm_is_long_call_p (SYMBOL_REF_DECL (operands[0]))"
   "*
@@ -8460,6 +9484,7 @@
    (use (match_operand 3 "" ""))
    (clobber (reg:SI LR_REGNUM))]
   "TARGET_32BIT
+   && !SIBLING_CALL_P (insn)
    && (GET_CODE (operands[1]) == SYMBOL_REF)
    && !arm_is_long_call_p (SYMBOL_REF_DECL (operands[1]))"
   "*
@@ -8505,6 +9530,10 @@
   "TARGET_32BIT"
   "
   {
+    if (!REG_P (XEXP (operands[0], 0))
+       && (GET_CODE (XEXP (operands[0], 0)) != SYMBOL_REF))
+     XEXP (operands[0], 0) = force_reg (SImode, XEXP (operands[0], 0));
+
     if (operands[2] == NULL_RTX)
       operands[2] = const0_rtx;
   }"
@@ -8519,47 +9548,67 @@
   "TARGET_32BIT"
   "
   {
+    if (!REG_P (XEXP (operands[1], 0)) &&
+       (GET_CODE (XEXP (operands[1],0)) != SYMBOL_REF))
+     XEXP (operands[1], 0) = force_reg (SImode, XEXP (operands[1], 0));
+
     if (operands[3] == NULL_RTX)
       operands[3] = const0_rtx;
   }"
 )
 
 (define_insn "*sibcall_insn"
- [(call (mem:SI (match_operand:SI 0 "" "X"))
+ [(call (mem:SI (match_operand:SI 0 "call_insn_operand" "Cs,Ss"))
 	(match_operand 1 "" ""))
   (return)
   (use (match_operand 2 "" ""))]
-  "TARGET_32BIT && GET_CODE (operands[0]) == SYMBOL_REF"
+  "TARGET_32BIT && SIBLING_CALL_P (insn)"
   "*
-  return NEED_PLT_RELOC ? \"b%?\\t%a0(PLT)\" : \"b%?\\t%a0\";
+  if (which_alternative == 1)
+    return NEED_PLT_RELOC ? \"b%?\\t%a0(PLT)\" : \"b%?\\t%a0\";
+  else
+    {
+      if (arm_arch5 || arm_arch4t)
+	return \" bx\\t%0\\t%@ indirect register sibling call\";
+      else
+	return \"mov%?\\t%|pc, %0\\t%@ indirect register sibling call\";
+    }
   "
   [(set_attr "type" "call")]
 )
 
 (define_insn "*sibcall_value_insn"
- [(set (match_operand 0 "" "")
-       (call (mem:SI (match_operand:SI 1 "" "X"))
+ [(set (match_operand 0 "s_register_operand" "")
+       (call (mem:SI (match_operand:SI 1 "call_insn_operand" "Cs,Ss"))
 	     (match_operand 2 "" "")))
   (return)
   (use (match_operand 3 "" ""))]
-  "TARGET_32BIT && GET_CODE (operands[1]) == SYMBOL_REF"
+  "TARGET_32BIT && SIBLING_CALL_P (insn)"
   "*
-  return NEED_PLT_RELOC ? \"b%?\\t%a1(PLT)\" : \"b%?\\t%a1\";
+  if (which_alternative == 1)
+   return NEED_PLT_RELOC ? \"b%?\\t%a1(PLT)\" : \"b%?\\t%a1\";
+  else
+    {
+      if (arm_arch5 || arm_arch4t)
+	return \"bx\\t%1\";
+      else
+	return \"mov%?\\t%|pc, %1\\t@ indirect sibling call \";
+    }
   "
   [(set_attr "type" "call")]
 )
 
-(define_expand "return"
-  [(return)]
+(define_expand "<return_str>return"
+  [(returns)]
   "(TARGET_ARM || (TARGET_THUMB2
                    && ARM_FUNC_TYPE (arm_current_func_type ()) == ARM_FT_NORMAL
                    && !IS_STACKALIGN (arm_current_func_type ())))
-    && USE_RETURN_INSN (FALSE)"
+    <return_cond_false>"
   "
   {
     if (TARGET_THUMB2)
       {
-        thumb2_expand_return ();
+        thumb2_expand_return (<return_simple_p>);
         DONE;
       }
   }
@@ -8584,13 +9633,13 @@
    (set_attr "predicable" "yes")]
 )
 
-(define_insn "*cond_return"
+(define_insn "*cond_<return_str>return"
   [(set (pc)
         (if_then_else (match_operator 0 "arm_comparison_operator"
 		       [(match_operand 1 "cc_register" "") (const_int 0)])
-                      (return)
+                      (returns)
                       (pc)))]
-  "TARGET_ARM && USE_RETURN_INSN (TRUE)"
+  "TARGET_ARM  <return_cond_true>"
   "*
   {
     if (arm_ccfsm_state == 2)
@@ -8598,20 +9647,21 @@
         arm_ccfsm_state += 2;
         return \"\";
       }
-    return output_return_instruction (operands[0], true, false, false);
+    return output_return_instruction (operands[0], true, false,
+				      <return_simple_p>);
   }"
   [(set_attr "conds" "use")
    (set_attr "length" "12")
    (set_attr "type" "load1")]
 )
 
-(define_insn "*cond_return_inverted"
+(define_insn "*cond_<return_str>return_inverted"
   [(set (pc)
         (if_then_else (match_operator 0 "arm_comparison_operator"
 		       [(match_operand 1 "cc_register" "") (const_int 0)])
                       (pc)
-		      (return)))]
-  "TARGET_ARM && USE_RETURN_INSN (TRUE)"
+		      (returns)))]
+  "TARGET_ARM <return_cond_true>"
   "*
   {
     if (arm_ccfsm_state == 2)
@@ -8619,7 +9669,8 @@
         arm_ccfsm_state += 2;
         return \"\";
       }
-    return output_return_instruction (operands[0], true, true, false);
+    return output_return_instruction (operands[0], true, true,
+				      <return_simple_p>);
   }"
   [(set_attr "conds" "use")
    (set_attr "length" "12")
@@ -9095,27 +10146,64 @@
    (set_attr "type" "alu_shift,alu_shift_reg")])
 
 
-(define_insn "*and_scc"
+(define_insn_and_split "*and_scc"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(and:SI (match_operator:SI 1 "arm_comparison_operator"
-		 [(match_operand 3 "cc_register" "") (const_int 0)])
-		(match_operand:SI 2 "s_register_operand" "r")))]
+		 [(match_operand 2 "cc_register" "") (const_int 0)])
+		(match_operand:SI 3 "s_register_operand" "r")))]
   "TARGET_ARM"
-  "mov%D1\\t%0, #0\;and%d1\\t%0, %2, #1"
+  "#"   ; "mov%D1\\t%0, #0\;and%d1\\t%0, %3, #1"
+  "&& reload_completed"
+  [(cond_exec (match_dup 5) (set (match_dup 0) (const_int 0)))
+   (cond_exec (match_dup 4) (set (match_dup 0)
+                                 (and:SI (match_dup 3) (const_int 1))))]
+  {
+    enum machine_mode mode = GET_MODE (operands[2]);
+    enum rtx_code rc = GET_CODE (operands[1]);
+
+    /* Note that operands[4] is the same as operands[1],
+       but with VOIDmode as the result. */
+    operands[4] = gen_rtx_fmt_ee (rc, VOIDmode, operands[2], const0_rtx);
+    if (mode == CCFPmode || mode == CCFPEmode)
+      rc = reverse_condition_maybe_unordered (rc);
+    else
+      rc = reverse_condition (rc);
+    operands[5] = gen_rtx_fmt_ee (rc, VOIDmode, operands[2], const0_rtx);
+  }
   [(set_attr "conds" "use")
    (set_attr "insn" "mov")
    (set_attr "length" "8")]
 )
 
-(define_insn "*ior_scc"
+(define_insn_and_split "*ior_scc"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r")
-	(ior:SI (match_operator:SI 2 "arm_comparison_operator"
-		 [(match_operand 3 "cc_register" "") (const_int 0)])
-		(match_operand:SI 1 "s_register_operand" "0,?r")))]
+	(ior:SI (match_operator:SI 1 "arm_comparison_operator"
+		 [(match_operand 2 "cc_register" "") (const_int 0)])
+		(match_operand:SI 3 "s_register_operand" "0,?r")))]
   "TARGET_ARM"
   "@
-   orr%d2\\t%0, %1, #1
-   mov%D2\\t%0, %1\;orr%d2\\t%0, %1, #1"
+   orr%d1\\t%0, %3, #1
+   #"
+  "&& reload_completed
+   && REGNO (operands [0]) != REGNO (operands[3])"
+  ;; && which_alternative == 1
+  ; mov%D1\\t%0, %3\;orr%d1\\t%0, %3, #1
+  [(cond_exec (match_dup 5) (set (match_dup 0) (match_dup 3)))
+   (cond_exec (match_dup 4) (set (match_dup 0)
+                                 (ior:SI (match_dup 3) (const_int 1))))]
+  {
+    enum machine_mode mode = GET_MODE (operands[2]);
+    enum rtx_code rc = GET_CODE (operands[1]);
+
+    /* Note that operands[4] is the same as operands[1],
+       but with VOIDmode as the result. */
+    operands[4] = gen_rtx_fmt_ee (rc, VOIDmode, operands[2], const0_rtx);
+    if (mode == CCFPmode || mode == CCFPEmode)
+      rc = reverse_condition_maybe_unordered (rc);
+    else
+      rc = reverse_condition (rc);
+    operands[5] = gen_rtx_fmt_ee (rc, VOIDmode, operands[2], const0_rtx);
+  }
   [(set_attr "conds" "use")
    (set_attr "length" "4,8")]
 )
@@ -9144,6 +10232,16 @@
 	(eq:SI (match_operand:SI 1 "s_register_operand" "")
 	       (const_int 0)))
    (clobber (reg:CC CC_REGNUM))]
+  "arm_arch5 && TARGET_32BIT"
+  [(set (match_dup 0) (clz:SI (match_dup 1)))
+   (set (match_dup 0) (lshiftrt:SI (match_dup 0) (const_int 5)))]
+)
+
+(define_split
+  [(set (match_operand:SI 0 "s_register_operand" "")
+	(eq:SI (match_operand:SI 1 "s_register_operand" "")
+	       (const_int 0)))
+   (clobber (reg:CC CC_REGNUM))]
   "TARGET_32BIT && reload_completed"
   [(parallel
     [(set (reg:CC CC_REGNUM)
@@ -9184,7 +10282,7 @@
 	      (set (match_dup 0) (const_int 1)))])
 
 (define_insn_and_split "*compare_scc"
-  [(set (match_operand:SI 0 "s_register_operand" "=r,r")
+  [(set (match_operand:SI 0 "s_register_operand" "=Ts,Ts")
 	(match_operator:SI 1 "arm_comparison_operator"
 	 [(match_operand:SI 2 "s_register_operand" "r,r")
 	  (match_operand:SI 3 "arm_add_operand" "rI,L")]))
@@ -9213,29 +10311,87 @@
 
 ;; Attempt to improve the sequence generated by the compare_scc splitters
 ;; not to use conditional execution.
+
+;; Rd = (eq (reg1) (const_int0))  // ARMv5
+;;	clz Rd, reg1
+;;	lsr Rd, Rd, #5
 (define_peephole2
   [(set (reg:CC CC_REGNUM)
 	(compare:CC (match_operand:SI 1 "register_operand" "")
-		    (match_operand:SI 2 "arm_rhs_operand" "")))
+		    (const_int 0)))
+   (cond_exec (ne (reg:CC CC_REGNUM) (const_int 0))
+	      (set (match_operand:SI 0 "register_operand" "") (const_int 0)))
+   (cond_exec (eq (reg:CC CC_REGNUM) (const_int 0))
+	      (set (match_dup 0) (const_int 1)))]
+  "arm_arch5 && TARGET_32BIT && peep2_regno_dead_p (3, CC_REGNUM)"
+  [(set (match_dup 0) (clz:SI (match_dup 1)))
+   (set (match_dup 0) (lshiftrt:SI (match_dup 0) (const_int 5)))]
+)
+
+;; Rd = (eq (reg1) (const_int0))  // !ARMv5
+;;	negs Rd, reg1
+;;	adc  Rd, Rd, reg1
+(define_peephole2
+  [(set (reg:CC CC_REGNUM)
+	(compare:CC (match_operand:SI 1 "register_operand" "")
+		    (const_int 0)))
    (cond_exec (ne (reg:CC CC_REGNUM) (const_int 0))
 	      (set (match_operand:SI 0 "register_operand" "") (const_int 0)))
    (cond_exec (eq (reg:CC CC_REGNUM) (const_int 0))
 	      (set (match_dup 0) (const_int 1)))
-   (match_scratch:SI 3 "r")]
-  "TARGET_32BIT"
+   (match_scratch:SI 2 "r")]
+  "TARGET_32BIT && peep2_regno_dead_p (3, CC_REGNUM)"
   [(parallel
     [(set (reg:CC CC_REGNUM)
-	  (compare:CC (match_dup 1) (match_dup 2)))
-     (set (match_dup 3) (minus:SI (match_dup 1) (match_dup 2)))])
+	  (compare:CC (const_int 0) (match_dup 1)))
+     (set (match_dup 2) (minus:SI (const_int 0) (match_dup 1)))])
+   (set (match_dup 0)
+	(plus:SI (plus:SI (match_dup 1) (match_dup 2))
+		 (geu:SI (reg:CC CC_REGNUM) (const_int 0))))]
+)
+
+;; Rd = (eq (reg1) (reg2/imm))	// ARMv5
+;;	sub  Rd, Reg1, reg2
+;;	clz  Rd, Rd
+;;	lsr  Rd, Rd, #5
+(define_peephole2
+  [(set (reg:CC CC_REGNUM)
+	(compare:CC (match_operand:SI 1 "register_operand" "")
+		    (match_operand:SI 2 "arm_rhs_operand" "")))
+   (cond_exec (ne (reg:CC CC_REGNUM) (const_int 0))
+	      (set (match_operand:SI 0 "register_operand" "") (const_int 0)))
+   (cond_exec (eq (reg:CC CC_REGNUM) (const_int 0))
+	      (set (match_dup 0) (const_int 1)))]
+  "arm_arch5 && TARGET_32BIT && peep2_regno_dead_p (3, CC_REGNUM)"
+  [(set (match_dup 0) (minus:SI (match_dup 1) (match_dup 2)))
+   (set (match_dup 0) (clz:SI (match_dup 0)))
+   (set (match_dup 0) (lshiftrt:SI (match_dup 0) (const_int 5)))]
+)
+
+
+;; Rd = (eq (reg1) (reg2/imm))	// ! ARMv5
+;;	sub  T1, Reg1, reg2
+;;	negs Rd, T1
+;;	adc  Rd, Rd, T1
+(define_peephole2
+  [(set (reg:CC CC_REGNUM)
+	(compare:CC (match_operand:SI 1 "register_operand" "")
+		    (match_operand:SI 2 "arm_rhs_operand" "")))
+   (cond_exec (ne (reg:CC CC_REGNUM) (const_int 0))
+	      (set (match_operand:SI 0 "register_operand" "") (const_int 0)))
+   (cond_exec (eq (reg:CC CC_REGNUM) (const_int 0))
+	      (set (match_dup 0) (const_int 1)))
+   (match_scratch:SI 3 "r")]
+  "TARGET_32BIT && peep2_regno_dead_p (3, CC_REGNUM)"
+  [(set (match_dup 3) (minus:SI (match_dup 1) (match_dup 2)))
    (parallel
     [(set (reg:CC CC_REGNUM)
 	  (compare:CC (const_int 0) (match_dup 3)))
      (set (match_dup 0) (minus:SI (const_int 0) (match_dup 3)))])
-   (parallel
-    [(set (match_dup 0)
-	  (plus:SI (plus:SI (match_dup 0) (match_dup 3))
-		   (geu:SI (reg:CC CC_REGNUM) (const_int 0))))
-     (clobber (reg:CC CC_REGNUM))])])
+   (set (match_dup 0)
+	(plus:SI (plus:SI (match_dup 0) (match_dup 3))
+		 (geu:SI (reg:CC CC_REGNUM) (const_int 0))))]
+)
 
 (define_insn "*cond_move"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r,r")
@@ -9636,7 +10792,7 @@
 )
 
 (define_insn_and_split "*ior_scc_scc"
-  [(set (match_operand:SI 0 "s_register_operand" "=r")
+  [(set (match_operand:SI 0 "s_register_operand" "=Ts")
 	(ior:SI (match_operator:SI 3 "arm_comparison_operator"
 		 [(match_operand:SI 1 "s_register_operand" "r")
 		  (match_operand:SI 2 "arm_add_operand" "rIL")])
@@ -9674,7 +10830,7 @@
 			  [(match_operand:SI 4 "s_register_operand" "r")
 			   (match_operand:SI 5 "arm_add_operand" "rIL")]))
 		 (const_int 0)))
-   (set (match_operand:SI 7 "s_register_operand" "=r")
+   (set (match_operand:SI 7 "s_register_operand" "=Ts")
 	(ior:SI (match_op_dup 3 [(match_dup 1) (match_dup 2)])
 		(match_op_dup 6 [(match_dup 4) (match_dup 5)])))]
   "TARGET_32BIT"
@@ -9692,7 +10848,7 @@
    (set_attr "length" "16")])
 
 (define_insn_and_split "*and_scc_scc"
-  [(set (match_operand:SI 0 "s_register_operand" "=r")
+  [(set (match_operand:SI 0 "s_register_operand" "=Ts")
 	(and:SI (match_operator:SI 3 "arm_comparison_operator"
 		 [(match_operand:SI 1 "s_register_operand" "r")
 		  (match_operand:SI 2 "arm_add_operand" "rIL")])
@@ -9732,7 +10888,7 @@
 			  [(match_operand:SI 4 "s_register_operand" "r")
 			   (match_operand:SI 5 "arm_add_operand" "rIL")]))
 		 (const_int 0)))
-   (set (match_operand:SI 7 "s_register_operand" "=r")
+   (set (match_operand:SI 7 "s_register_operand" "=Ts")
 	(and:SI (match_op_dup 3 [(match_dup 1) (match_dup 2)])
 		(match_op_dup 6 [(match_dup 4) (match_dup 5)])))]
   "TARGET_32BIT"
@@ -9754,7 +10910,7 @@
 ;; need only zero the value if false (if true, then the value is already
 ;; correct).
 (define_insn_and_split "*and_scc_scc_nodom"
-  [(set (match_operand:SI 0 "s_register_operand" "=&r,&r,&r")
+  [(set (match_operand:SI 0 "s_register_operand" "=&Ts,&Ts,&Ts")
 	(and:SI (match_operator:SI 3 "arm_comparison_operator"
 		 [(match_operand:SI 1 "s_register_operand" "r,r,0")
 		  (match_operand:SI 2 "arm_add_operand" "rIL,0,rIL")])
@@ -9822,24 +10978,75 @@
   "")
 ;; ??? The conditional patterns above need checking for Thumb-2 usefulness
 
-(define_insn "*negscc"
+(define_insn_and_split "*negscc"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(neg:SI (match_operator 3 "arm_comparison_operator"
 		 [(match_operand:SI 1 "s_register_operand" "r")
 		  (match_operand:SI 2 "arm_rhs_operand" "rI")])))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_ARM"
-  "*
-  if (GET_CODE (operands[3]) == LT && operands[2] == const0_rtx)
-    return \"mov\\t%0, %1, asr #31\";
-
-  if (GET_CODE (operands[3]) == NE)
-    return \"subs\\t%0, %1, %2\;mvnne\\t%0, #0\";
+  "#"
+  "&& reload_completed"
+  [(const_int 0)]
+  {
+    rtx cc_reg = gen_rtx_REG (CCmode, CC_REGNUM);
 
-  output_asm_insn (\"cmp\\t%1, %2\", operands);
-  output_asm_insn (\"mov%D3\\t%0, #0\", operands);
-  return \"mvn%d3\\t%0, #0\";
-  "
+    if (GET_CODE (operands[3]) == LT && operands[2] == const0_rtx)
+       {
+         /* Emit mov\\t%0, %1, asr #31 */
+         emit_insn (gen_rtx_SET (VOIDmode,
+                                 operands[0],
+                                 gen_rtx_ASHIFTRT (SImode,
+                                                   operands[1],
+                                                   GEN_INT (31))));
+         DONE;
+       }
+     else if (GET_CODE (operands[3]) == NE)
+       {
+        /* Emit subs\\t%0, %1, %2\;mvnne\\t%0, #0 */
+        if (CONST_INT_P (operands[2]))
+          emit_insn (gen_cmpsi2_addneg (operands[0], operands[1], operands[2],
+                                        GEN_INT (- INTVAL (operands[2]))));
+        else
+          emit_insn (gen_subsi3_compare (operands[0], operands[1], operands[2]));
+
+        emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                      gen_rtx_NE (SImode,
+                                                  cc_reg,
+                                                  const0_rtx),
+                                      gen_rtx_SET (SImode,
+                                                   operands[0],
+                                                   GEN_INT (~0))));
+        DONE;
+      }
+    else
+      {
+        /* Emit: cmp\\t%1, %2\;mov%D3\\t%0, #0\;mvn%d3\\t%0, #0 */
+        emit_insn (gen_rtx_SET (VOIDmode,
+                                cc_reg,
+                                gen_rtx_COMPARE (CCmode, operands[1], operands[2])));
+        enum rtx_code rc = GET_CODE (operands[3]);
+
+        rc = reverse_condition (rc);
+        emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                      gen_rtx_fmt_ee (rc,
+                                                      VOIDmode,
+                                                      cc_reg,
+                                                      const0_rtx),
+                                      gen_rtx_SET (VOIDmode, operands[0], const0_rtx)));
+        rc = GET_CODE (operands[3]);
+        emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                      gen_rtx_fmt_ee (rc,
+                                                      VOIDmode,
+                                                      cc_reg,
+                                                      const0_rtx),
+                                      gen_rtx_SET (VOIDmode,
+                                                   operands[0],
+                                                   GEN_INT (~0))));
+        DONE;
+      }
+     FAIL;
+  }
   [(set_attr "conds" "clob")
    (set_attr "length" "12")]
 )
@@ -11550,7 +12757,8 @@
                                   false, true))"
   "ldrd%?\t%0, %3, [%1, %2]"
   [(set_attr "type" "load2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb2_ldrd_base"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
@@ -11564,7 +12772,8 @@
                                   operands[1], 0, false, true))"
   "ldrd%?\t%0, %2, [%1]"
   [(set_attr "type" "load2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb2_ldrd_base_neg"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
@@ -11578,7 +12787,8 @@
                                   operands[1], -4, false, true))"
   "ldrd%?\t%0, %2, [%1, #-4]"
   [(set_attr "type" "load2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb2_strd"
   [(set (mem:SI (plus:SI (match_operand:SI 0 "s_register_operand" "rk")
@@ -11595,7 +12805,8 @@
                                   false, false))"
   "strd%?\t%2, %4, [%0, %1]"
   [(set_attr "type" "store2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb2_strd_base"
   [(set (mem:SI (match_operand:SI 0 "s_register_operand" "rk"))
@@ -11609,7 +12820,8 @@
                                   operands[0], 0, false, false))"
   "strd%?\t%1, %2, [%0]"
   [(set_attr "type" "store2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb2_strd_base_neg"
   [(set (mem:SI (plus:SI (match_operand:SI 0 "s_register_operand" "rk")
@@ -11623,8 +12835,12 @@
                                   operands[0], -4, false, false))"
   "strd%?\t%1, %2, [%0, #-4]"
   [(set_attr "type" "store2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
+
 
+;; Load the load/store double peephole optimizations.
+(include "ldrdstrd.md")
 
 ;; Load the load/store multiple patterns
 (include "ldmstm.md")
diff --git a/gcc/config/arm/arm.opt b/gcc/config/arm/arm.opt
index e778407..b9ae2b0 100644
--- a/gcc/config/arm/arm.opt
+++ b/gcc/config/arm/arm.opt
@@ -239,6 +239,10 @@ mword-relocations
 Target Report Var(target_word_relocations) Init(TARGET_DEFAULT_WORD_RELOCATIONS)
 Only generate absolute relocations on word sized values.
 
+mrestrict-it
+Target Report Var(arm_restrict_it) Init(2)
+Generate IT blocks appropriate for ARMv8.
+
 mfix-cortex-m3-ldrd
 Target Report Var(fix_cm3_ldrd) Init(2)
 Avoid overlapping destination and address registers on LDRD instructions
@@ -247,3 +251,7 @@ that may trigger Cortex-M3 errata.
 munaligned-access
 Target Report Var(unaligned_access) Init(2)
 Enable unaligned word and halfword accesses to packed data.
+
+mneon-for-64bits
+Target Report RejectNegative Var(use_neon_for_64bits) Init(0)
+Use Neon to perform 64-bits operations rather than core registers.
diff --git a/gcc/config/arm/arm1020e.md b/gcc/config/arm/arm1020e.md
index ab65978..94e8c35 100644
--- a/gcc/config/arm/arm1020e.md
+++ b/gcc/config/arm/arm1020e.md
@@ -96,7 +96,7 @@
 ;; until after the memory stage.
 (define_insn_reservation "1020mult1" 2
  (and (eq_attr "tune" "arm1020e,arm1022e")
-      (eq_attr "insn" "smulxy,smulwy"))
+      (eq_attr "type" "smulxy,smulwy"))
  "1020a_e,1020a_m,1020a_w")
 
 ;; The "smlaxy" and "smlawx" instructions require two iterations through
@@ -104,7 +104,7 @@
 ;; the execute stage.
 (define_insn_reservation "1020mult2" 2
  (and (eq_attr "tune" "arm1020e,arm1022e")
-      (eq_attr "insn" "smlaxy,smlalxy,smlawx"))
+      (eq_attr "type" "smlaxy,smlalxy,smlawx"))
  "1020a_e*2,1020a_m,1020a_w")
 
 ;; The "smlalxy", "mul", and "mla" instructions require two iterations
@@ -112,7 +112,7 @@
 ;; the memory stage.
 (define_insn_reservation "1020mult3" 3
  (and (eq_attr "tune" "arm1020e,arm1022e")
-      (eq_attr "insn" "smlalxy,mul,mla"))
+      (eq_attr "type" "smlalxy,mul,mla"))
  "1020a_e*2,1020a_m,1020a_w")
 
 ;; The "muls" and "mlas" instructions loop in the execute stage for
@@ -120,7 +120,7 @@
 ;; available after three iterations.
 (define_insn_reservation "1020mult4" 3
  (and (eq_attr "tune" "arm1020e,arm1022e")
-      (eq_attr "insn" "muls,mlas"))
+      (eq_attr "type" "muls,mlas"))
  "1020a_e*4,1020a_m,1020a_w")
 
 ;; Long multiply instructions that produce two registers of
@@ -135,7 +135,7 @@
 ;; available after the memory cycle.
 (define_insn_reservation "1020mult5" 4
  (and (eq_attr "tune" "arm1020e,arm1022e")
-      (eq_attr "insn" "umull,umlal,smull,smlal"))
+      (eq_attr "type" "umull,umlal,smull,smlal"))
  "1020a_e*3,1020a_m,1020a_w")
 
 ;; The "umulls", "umlals", "smulls", and "smlals" instructions loop in
@@ -143,7 +143,7 @@
 ;; The value result is available after four iterations.
 (define_insn_reservation "1020mult6" 4
  (and (eq_attr "tune" "arm1020e,arm1022e")
-      (eq_attr "insn" "umulls,umlals,smulls,smlals"))
+      (eq_attr "type" "umulls,umlals,smulls,smlals"))
  "1020a_e*5,1020a_m,1020a_w")
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
diff --git a/gcc/config/arm/arm1026ejs.md b/gcc/config/arm/arm1026ejs.md
index 3fa4bd0..67b985c 100644
--- a/gcc/config/arm/arm1026ejs.md
+++ b/gcc/config/arm/arm1026ejs.md
@@ -96,7 +96,7 @@
 ;; until after the memory stage.
 (define_insn_reservation "mult1" 2
  (and (eq_attr "tune" "arm1026ejs")
-      (eq_attr "insn" "smulxy,smulwy"))
+      (eq_attr "type" "smulxy,smulwy"))
  "a_e,a_m,a_w")
 
 ;; The "smlaxy" and "smlawx" instructions require two iterations through
@@ -104,7 +104,7 @@
 ;; the execute stage.
 (define_insn_reservation "mult2" 2
  (and (eq_attr "tune" "arm1026ejs")
-      (eq_attr "insn" "smlaxy,smlalxy,smlawx"))
+      (eq_attr "type" "smlaxy,smlalxy,smlawx"))
  "a_e*2,a_m,a_w")
 
 ;; The "smlalxy", "mul", and "mla" instructions require two iterations
@@ -112,7 +112,7 @@
 ;; the memory stage.
 (define_insn_reservation "mult3" 3
  (and (eq_attr "tune" "arm1026ejs")
-      (eq_attr "insn" "smlalxy,mul,mla"))
+      (eq_attr "type" "smlalxy,mul,mla"))
  "a_e*2,a_m,a_w")
 
 ;; The "muls" and "mlas" instructions loop in the execute stage for
@@ -120,7 +120,7 @@
 ;; available after three iterations.
 (define_insn_reservation "mult4" 3
  (and (eq_attr "tune" "arm1026ejs")
-      (eq_attr "insn" "muls,mlas"))
+      (eq_attr "type" "muls,mlas"))
  "a_e*4,a_m,a_w")
 
 ;; Long multiply instructions that produce two registers of
@@ -135,7 +135,7 @@
 ;; available after the memory cycle.
 (define_insn_reservation "mult5" 4
  (and (eq_attr "tune" "arm1026ejs")
-      (eq_attr "insn" "umull,umlal,smull,smlal"))
+      (eq_attr "type" "umull,umlal,smull,smlal"))
  "a_e*3,a_m,a_w")
 
 ;; The "umulls", "umlals", "smulls", and "smlals" instructions loop in
@@ -143,7 +143,7 @@
 ;; The value result is available after four iterations.
 (define_insn_reservation "mult6" 4
  (and (eq_attr "tune" "arm1026ejs")
-      (eq_attr "insn" "umulls,umlals,smulls,smlals"))
+      (eq_attr "type" "umulls,umlals,smulls,smlals"))
  "a_e*5,a_m,a_w")
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
diff --git a/gcc/config/arm/arm1136jfs.md b/gcc/config/arm/arm1136jfs.md
index b5802e0..3030182 100644
--- a/gcc/config/arm/arm1136jfs.md
+++ b/gcc/config/arm/arm1136jfs.md
@@ -129,13 +129,13 @@
 ;; Multiply and multiply-accumulate results are available after four stages.
 (define_insn_reservation "11_mult1" 4
  (and (eq_attr "tune" "arm1136js,arm1136jfs")
-      (eq_attr "insn" "mul,mla"))
+      (eq_attr "type" "mul,mla"))
  "e_1*2,e_2,e_3,e_wb")
 
 ;; The *S variants set the condition flags, which requires three more cycles.
 (define_insn_reservation "11_mult2" 4
  (and (eq_attr "tune" "arm1136js,arm1136jfs")
-      (eq_attr "insn" "muls,mlas"))
+      (eq_attr "type" "muls,mlas"))
  "e_1*2,e_2,e_3,e_wb")
 
 (define_bypass 3 "11_mult1,11_mult2"
@@ -160,13 +160,13 @@
 ;; the two multiply-accumulate instructions.
 (define_insn_reservation "11_mult3" 5
  (and (eq_attr "tune" "arm1136js,arm1136jfs")
-      (eq_attr "insn" "smull,umull,smlal,umlal"))
+      (eq_attr "type" "smull,umull,smlal,umlal"))
  "e_1*3,e_2,e_3,e_wb*2")
 
 ;; The *S variants set the condition flags, which requires three more cycles.
 (define_insn_reservation "11_mult4" 5
  (and (eq_attr "tune" "arm1136js,arm1136jfs")
-      (eq_attr "insn" "smulls,umulls,smlals,umlals"))
+      (eq_attr "type" "smulls,umulls,smlals,umlals"))
  "e_1*3,e_2,e_3,e_wb*2")
 
 (define_bypass 4 "11_mult3,11_mult4"
@@ -190,7 +190,8 @@
 ;; cycles.
 (define_insn_reservation "11_mult5" 3
  (and (eq_attr "tune" "arm1136js,arm1136jfs")
-      (eq_attr "insn" "smulxy,smlaxy,smulwy,smlawy,smuad,smuadx,smlad,smladx,smusd,smusdx,smlsd,smlsdx"))
+      (eq_attr "type" "smulxy,smlaxy,smulwy,smlawy,smuad,smuadx,smlad,smladx,\
+                       smusd,smusdx,smlsd,smlsdx"))
  "e_1,e_2,e_3,e_wb")
 
 (define_bypass 2 "11_mult5"
@@ -211,14 +212,14 @@
 ;; The same idea, then the 32-bit result is added to a 64-bit quantity.
 (define_insn_reservation "11_mult6" 4
  (and (eq_attr "tune" "arm1136js,arm1136jfs")
-      (eq_attr "insn" "smlalxy"))
+      (eq_attr "type" "smlalxy"))
  "e_1*2,e_2,e_3,e_wb*2")
 
 ;; Signed 32x32 multiply, then the most significant 32 bits are extracted
 ;; and are available after the memory stage.
 (define_insn_reservation "11_mult7" 4
  (and (eq_attr "tune" "arm1136js,arm1136jfs")
-      (eq_attr "insn" "smmul,smmulr"))
+      (eq_attr "type" "smmul,smmulr"))
  "e_1*2,e_2,e_3,e_wb")
 
 (define_bypass 3 "11_mult6,11_mult7"
diff --git a/gcc/config/arm/arm926ejs.md b/gcc/config/arm/arm926ejs.md
index 1fc82d3..4db404e 100644
--- a/gcc/config/arm/arm926ejs.md
+++ b/gcc/config/arm/arm926ejs.md
@@ -81,32 +81,32 @@
 
 (define_insn_reservation "9_mult1" 3
  (and (eq_attr "tune" "arm926ejs")
-      (eq_attr "insn" "smlalxy,mul,mla"))
+      (eq_attr "type" "smlalxy,mul,mla"))
  "e*2,m,w")
 
 (define_insn_reservation "9_mult2" 4
  (and (eq_attr "tune" "arm926ejs")
-      (eq_attr "insn" "muls,mlas"))
+      (eq_attr "type" "muls,mlas"))
  "e*3,m,w")
 
 (define_insn_reservation "9_mult3" 4
  (and (eq_attr "tune" "arm926ejs")
-      (eq_attr "insn" "umull,umlal,smull,smlal"))
+      (eq_attr "type" "umull,umlal,smull,smlal"))
  "e*3,m,w")
 
 (define_insn_reservation "9_mult4" 5
  (and (eq_attr "tune" "arm926ejs")
-      (eq_attr "insn" "umulls,umlals,smulls,smlals"))
+      (eq_attr "type" "umulls,umlals,smulls,smlals"))
  "e*4,m,w")
 
 (define_insn_reservation "9_mult5" 2
  (and (eq_attr "tune" "arm926ejs")
-      (eq_attr "insn" "smulxy,smlaxy,smlawx"))
+      (eq_attr "type" "smulxy,smlaxy,smlawx"))
  "e,m,w")
 
 (define_insn_reservation "9_mult6" 3
  (and (eq_attr "tune" "arm926ejs")
-      (eq_attr "insn" "smlalxy"))
+      (eq_attr "type" "smlalxy"))
  "e*2,m,w")
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
diff --git a/gcc/config/arm/arm_neon_builtins.def b/gcc/config/arm/arm_neon_builtins.def
new file mode 100644
index 0000000..5bf6d31
--- /dev/null
+++ b/gcc/config/arm/arm_neon_builtins.def
@@ -0,0 +1,210 @@
+/* NEON builtin definitions for ARM.
+   Copyright (C) 2013
+   Free Software Foundation, Inc.
+   Contributed by ARM Ltd.
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify it
+   under the terms of the GNU General Public License as published
+   by the Free Software Foundation; either version 3, or (at your
+   option) any later version.
+
+   GCC is distributed in the hope that it will be useful, but WITHOUT
+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+   or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+   License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with GCC; see the file COPYING3.  If not see
+   <http://www.gnu.org/licenses/>.  */
+
+VAR10 (BINOP, vadd,
+	v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR3 (BINOP, vaddl, v8qi, v4hi, v2si),
+VAR3 (BINOP, vaddw, v8qi, v4hi, v2si),
+VAR6 (BINOP, vhadd, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR8 (BINOP, vqadd, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR3 (BINOP, vaddhn, v8hi, v4si, v2di),
+VAR8 (BINOP, vmul, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR8 (TERNOP, vmla, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR3 (TERNOP, vmlal, v8qi, v4hi, v2si),
+VAR2 (TERNOP, vfma, v2sf, v4sf),
+VAR2 (TERNOP, vfms, v2sf, v4sf),
+VAR8 (TERNOP, vmls, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR3 (TERNOP, vmlsl, v8qi, v4hi, v2si),
+VAR4 (BINOP, vqdmulh, v4hi, v2si, v8hi, v4si),
+VAR2 (TERNOP, vqdmlal, v4hi, v2si),
+VAR2 (TERNOP, vqdmlsl, v4hi, v2si),
+VAR3 (BINOP, vmull, v8qi, v4hi, v2si),
+VAR2 (SCALARMULL, vmull_n, v4hi, v2si),
+VAR2 (LANEMULL, vmull_lane, v4hi, v2si),
+VAR2 (SCALARMULL, vqdmull_n, v4hi, v2si),
+VAR2 (LANEMULL, vqdmull_lane, v4hi, v2si),
+VAR4 (SCALARMULH, vqdmulh_n, v4hi, v2si, v8hi, v4si),
+VAR4 (LANEMULH, vqdmulh_lane, v4hi, v2si, v8hi, v4si),
+VAR2 (BINOP, vqdmull, v4hi, v2si),
+VAR8 (BINOP, vshl, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR8 (BINOP, vqshl, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR8 (SHIFTIMM, vshr_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR3 (SHIFTIMM, vshrn_n, v8hi, v4si, v2di),
+VAR3 (SHIFTIMM, vqshrn_n, v8hi, v4si, v2di),
+VAR3 (SHIFTIMM, vqshrun_n, v8hi, v4si, v2di),
+VAR8 (SHIFTIMM, vshl_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR8 (SHIFTIMM, vqshl_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR8 (SHIFTIMM, vqshlu_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR3 (SHIFTIMM, vshll_n, v8qi, v4hi, v2si),
+VAR8 (SHIFTACC, vsra_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR10 (BINOP, vsub, v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR3 (BINOP, vsubl, v8qi, v4hi, v2si),
+VAR3 (BINOP, vsubw, v8qi, v4hi, v2si),
+VAR8 (BINOP, vqsub, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR6 (BINOP, vhsub, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR3 (BINOP, vsubhn, v8hi, v4si, v2di),
+VAR8 (BINOP, vceq, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR8 (BINOP, vcge, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR6 (BINOP, vcgeu, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR8 (BINOP, vcgt, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR6 (BINOP, vcgtu, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR2 (BINOP, vcage, v2sf, v4sf),
+VAR2 (BINOP, vcagt, v2sf, v4sf),
+VAR6 (BINOP, vtst, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR8 (BINOP, vabd, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR3 (BINOP, vabdl, v8qi, v4hi, v2si),
+VAR6 (TERNOP, vaba, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR3 (TERNOP, vabal, v8qi, v4hi, v2si),
+VAR8 (BINOP, vmax, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR8 (BINOP, vmin, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR4 (BINOP, vpadd, v8qi, v4hi, v2si, v2sf),
+VAR6 (UNOP, vpaddl, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR6 (BINOP, vpadal, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR4 (BINOP, vpmax, v8qi, v4hi, v2si, v2sf),
+VAR4 (BINOP, vpmin, v8qi, v4hi, v2si, v2sf),
+VAR2 (BINOP, vrecps, v2sf, v4sf),
+VAR2 (BINOP, vrsqrts, v2sf, v4sf),
+VAR8 (SHIFTINSERT, vsri_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR8 (SHIFTINSERT, vsli_n, v8qi, v4hi, v2si, di, v16qi, v8hi, v4si, v2di),
+VAR8 (UNOP, vabs, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR6 (UNOP, vqabs, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR8 (UNOP, vneg, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR6 (UNOP, vqneg, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR6 (UNOP, vcls, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR6 (UNOP, vclz, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+VAR2 (UNOP, vcnt, v8qi, v16qi),
+VAR4 (UNOP, vrecpe, v2si, v2sf, v4si, v4sf),
+VAR4 (UNOP, vrsqrte, v2si, v2sf, v4si, v4sf),
+VAR6 (UNOP, vmvn, v8qi, v4hi, v2si, v16qi, v8hi, v4si),
+  /* FIXME: vget_lane supports more variants than this!  */
+VAR10 (GETLANE, vget_lane,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (SETLANE, vset_lane,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR5 (CREATE, vcreate, v8qi, v4hi, v2si, v2sf, di),
+VAR10 (DUP, vdup_n,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (DUPLANE, vdup_lane,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR5 (COMBINE, vcombine, v8qi, v4hi, v2si, v2sf, di),
+VAR5 (SPLIT, vget_high, v16qi, v8hi, v4si, v4sf, v2di),
+VAR5 (SPLIT, vget_low, v16qi, v8hi, v4si, v4sf, v2di),
+VAR3 (UNOP, vmovn, v8hi, v4si, v2di),
+VAR3 (UNOP, vqmovn, v8hi, v4si, v2di),
+VAR3 (UNOP, vqmovun, v8hi, v4si, v2di),
+VAR3 (UNOP, vmovl, v8qi, v4hi, v2si),
+VAR6 (LANEMUL, vmul_lane, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR6 (LANEMAC, vmla_lane, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR2 (LANEMAC, vmlal_lane, v4hi, v2si),
+VAR2 (LANEMAC, vqdmlal_lane, v4hi, v2si),
+VAR6 (LANEMAC, vmls_lane, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR2 (LANEMAC, vmlsl_lane, v4hi, v2si),
+VAR2 (LANEMAC, vqdmlsl_lane, v4hi, v2si),
+VAR6 (SCALARMUL, vmul_n, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR6 (SCALARMAC, vmla_n, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR2 (SCALARMAC, vmlal_n, v4hi, v2si),
+VAR2 (SCALARMAC, vqdmlal_n, v4hi, v2si),
+VAR6 (SCALARMAC, vmls_n, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR2 (SCALARMAC, vmlsl_n, v4hi, v2si),
+VAR2 (SCALARMAC, vqdmlsl_n, v4hi, v2si),
+VAR10 (BINOP, vext,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR8 (UNOP, vrev64, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR4 (UNOP, vrev32, v8qi, v4hi, v16qi, v8hi),
+VAR2 (UNOP, vrev16, v8qi, v16qi),
+VAR4 (CONVERT, vcvt, v2si, v2sf, v4si, v4sf),
+VAR4 (FIXCONV, vcvt_n, v2si, v2sf, v4si, v4sf),
+VAR10 (SELECT, vbsl,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR2 (RINT, vrintn, v2sf, v4sf),
+VAR2 (RINT, vrinta, v2sf, v4sf),
+VAR2 (RINT, vrintp, v2sf, v4sf),
+VAR2 (RINT, vrintm, v2sf, v4sf),
+VAR2 (RINT, vrintz, v2sf, v4sf),
+VAR2 (RINT, vrintx, v2sf, v4sf),
+VAR1 (VTBL, vtbl1, v8qi),
+VAR1 (VTBL, vtbl2, v8qi),
+VAR1 (VTBL, vtbl3, v8qi),
+VAR1 (VTBL, vtbl4, v8qi),
+VAR1 (VTBX, vtbx1, v8qi),
+VAR1 (VTBX, vtbx2, v8qi),
+VAR1 (VTBX, vtbx3, v8qi),
+VAR1 (VTBX, vtbx4, v8qi),
+VAR8 (RESULTPAIR, vtrn, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR8 (RESULTPAIR, vzip, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR8 (RESULTPAIR, vuzp, v8qi, v4hi, v2si, v2sf, v16qi, v8hi, v4si, v4sf),
+VAR5 (REINTERP, vreinterpretv8qi, v8qi, v4hi, v2si, v2sf, di),
+VAR5 (REINTERP, vreinterpretv4hi, v8qi, v4hi, v2si, v2sf, di),
+VAR5 (REINTERP, vreinterpretv2si, v8qi, v4hi, v2si, v2sf, di),
+VAR5 (REINTERP, vreinterpretv2sf, v8qi, v4hi, v2si, v2sf, di),
+VAR5 (REINTERP, vreinterpretdi, v8qi, v4hi, v2si, v2sf, di),
+VAR5 (REINTERP, vreinterpretv16qi, v16qi, v8hi, v4si, v4sf, v2di),
+VAR5 (REINTERP, vreinterpretv8hi, v16qi, v8hi, v4si, v4sf, v2di),
+VAR5 (REINTERP, vreinterpretv4si, v16qi, v8hi, v4si, v4sf, v2di),
+VAR5 (REINTERP, vreinterpretv4sf, v16qi, v8hi, v4si, v4sf, v2di),
+VAR5 (REINTERP, vreinterpretv2di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (LOAD1, vld1,
+         v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (LOAD1LANE, vld1_lane,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (LOAD1, vld1_dup,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (STORE1, vst1,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (STORE1LANE, vst1_lane,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR9 (LOADSTRUCT,
+	vld2, v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
+VAR7 (LOADSTRUCTLANE, vld2_lane,
+	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR5 (LOADSTRUCT, vld2_dup, v8qi, v4hi, v2si, v2sf, di),
+VAR9 (STORESTRUCT, vst2,
+	v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
+VAR7 (STORESTRUCTLANE, vst2_lane,
+	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR9 (LOADSTRUCT,
+	vld3, v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
+VAR7 (LOADSTRUCTLANE, vld3_lane,
+	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR5 (LOADSTRUCT, vld3_dup, v8qi, v4hi, v2si, v2sf, di),
+VAR9 (STORESTRUCT, vst3,
+	v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
+VAR7 (STORESTRUCTLANE, vst3_lane,
+	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR9 (LOADSTRUCT, vld4,
+	v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
+VAR7 (LOADSTRUCTLANE, vld4_lane,
+	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR5 (LOADSTRUCT, vld4_dup, v8qi, v4hi, v2si, v2sf, di),
+VAR9 (STORESTRUCT, vst4,
+	v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf),
+VAR7 (STORESTRUCTLANE, vst4_lane,
+	v8qi, v4hi, v2si, v2sf, v8hi, v4si, v4sf),
+VAR10 (LOGICBINOP, vand,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (LOGICBINOP, vorr,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (BINOP, veor,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (LOGICBINOP, vbic,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di),
+VAR10 (LOGICBINOP, vorn,
+	 v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di)
diff --git a/gcc/config/arm/bpabi.h b/gcc/config/arm/bpabi.h
index bee429f..ff89633 100644
--- a/gcc/config/arm/bpabi.h
+++ b/gcc/config/arm/bpabi.h
@@ -60,6 +60,7 @@
    |mcpu=cortex-a7                                      \
    |mcpu=cortex-a8|mcpu=cortex-a9|mcpu=cortex-a15       \
    |mcpu=marvell-pj4					\
+   |mcpu=cortex-a53					\
    |mcpu=generic-armv7-a                                \
    |march=armv7-m|mcpu=cortex-m3                        \
    |march=armv7e-m|mcpu=cortex-m4                       \
@@ -71,6 +72,7 @@
   " %{mbig-endian:%{march=armv7-a|mcpu=cortex-a5        \
    |mcpu=cortex-a7                                      \
    |mcpu=cortex-a8|mcpu=cortex-a9|mcpu=cortex-a15       \
+   |mcpu=cortex-a53					\
    |mcpu=marvell-pj4					\
    |mcpu=generic-armv7-a                                \
    |march=armv7-m|mcpu=cortex-m3                        \
@@ -89,11 +91,15 @@
 #define SUBTARGET_EXTRA_LINK_SPEC ""
 #endif
 
+/* Split out the EABI common values so other targets can use it.  */
+#define EABI_LINK_SPEC \
+  TARGET_FIX_V4BX_SPEC BE8_LINK_SPEC
+
 /* The generic link spec in elf.h does not support shared libraries.  */
 #define BPABI_LINK_SPEC \
   "%{mbig-endian:-EB} %{mlittle-endian:-EL} "		\
   "%{static:-Bstatic} %{shared:-shared} %{symbolic:-Bsymbolic} "	\
-  "-X" SUBTARGET_EXTRA_LINK_SPEC TARGET_FIX_V4BX_SPEC BE8_LINK_SPEC
+  "-X" SUBTARGET_EXTRA_LINK_SPEC EABI_LINK_SPEC
 
 #undef  LINK_SPEC
 #define LINK_SPEC BPABI_LINK_SPEC
diff --git a/gcc/config/arm/constraints.md b/gcc/config/arm/constraints.md
index 775f8af..251d497 100644
--- a/gcc/config/arm/constraints.md
+++ b/gcc/config/arm/constraints.md
@@ -21,7 +21,7 @@
 ;; The following register constraints have been used:
 ;; - in ARM/Thumb-2 state: t, w, x, y, z
 ;; - in Thumb state: h, b
-;; - in both states: l, c, k
+;; - in both states: l, c, k, q
 ;; In ARM state, 'l' is an alias for 'r'
 ;; 'f' and 'v' were previously used for FPA and MAVERICK registers.
 
@@ -86,6 +86,9 @@
 (define_register_constraint "k" "STACK_REG"
  "@internal The stack register.")
 
+(define_register_constraint "q" "(TARGET_ARM && TARGET_LDRD) ? CORE_REGS : GENERAL_REGS"
+  "@internal In ARM state with LDRD support, core registers, otherwise general registers.")
+
 (define_register_constraint "b" "TARGET_THUMB ? BASE_REGS : NO_REGS"
  "@internal
   Thumb only.  The union of the low registers and the stack register.")
@@ -93,6 +96,9 @@
 (define_register_constraint "c" "CC_REG"
  "@internal The condition code register.")
 
+(define_register_constraint "Cs" "CALLER_SAVE_REGS"
+ "@internal The caller save registers.  Useful for sibcalls.")
+
 (define_constraint "I"
  "In ARM/Thumb-2 state a constant that can be used as an immediate value in a
   Data Processing instruction.  In Thumb-1 state a constant in the range
@@ -248,6 +254,24 @@
  (and (match_code "const_int")
       (match_test "TARGET_32BIT && const_ok_for_dimode_op (ival, PLUS)")))
 
+(define_constraint "De"
+ "@internal
+  In ARM/Thumb-2 state a const_int that can be used by insn anddi."
+ (and (match_code "const_int")
+      (match_test "TARGET_32BIT && const_ok_for_dimode_op (ival, AND)")))
+
+(define_constraint "Df"
+ "@internal
+  In ARM/Thumb-2 state a const_int that can be used by insn iordi."
+ (and (match_code "const_int")
+      (match_test "TARGET_32BIT && const_ok_for_dimode_op (ival, IOR)")))
+
+(define_constraint "Dg"
+ "@internal
+  In ARM/Thumb-2 state a const_int that can be used by insn xordi."
+ (and (match_code "const_int")
+      (match_test "TARGET_32BIT && const_ok_for_dimode_op (ival, XOR)")))
+
 (define_constraint "Di"
  "@internal
   In ARM/Thumb-2 state a const_int or const_double where both the high
@@ -305,6 +329,9 @@
   (and (match_code "const_double")
        (match_test "TARGET_32BIT && TARGET_VFP && vfp3_const_double_for_fract_bits (op)")))
 
+(define_register_constraint "Ts" "(arm_restrict_it) ? LO_REGS : GENERAL_REGS"
+ "For arm_restrict_it the core registers @code{r0}-@code{r7}.  GENERAL_REGS otherwise.")
+
 (define_memory_constraint "Ua"
  "@internal
   An address valid for loading/storing register exclusive"
@@ -334,21 +361,21 @@
   In ARM/Thumb-2 state a valid address for Neon doubleword vector
   load/store instructions."
  (and (match_code "mem")
-      (match_test "TARGET_32BIT && neon_vector_mem_operand (op, 0)")))
+      (match_test "TARGET_32BIT && neon_vector_mem_operand (op, 0, true)")))
 
 (define_memory_constraint "Um"
  "@internal
   In ARM/Thumb-2 state a valid address for Neon element and structure
   load/store instructions."
  (and (match_code "mem")
-      (match_test "TARGET_32BIT && neon_vector_mem_operand (op, 2)")))
+      (match_test "TARGET_32BIT && neon_vector_mem_operand (op, 2, true)")))
 
 (define_memory_constraint "Us"
  "@internal
   In ARM/Thumb-2 state a valid address for non-offset loads/stores of
   quad-word values in four ARM registers."
  (and (match_code "mem")
-      (match_test "TARGET_32BIT && neon_vector_mem_operand (op, 1)")))
+      (match_test "TARGET_32BIT && neon_vector_mem_operand (op, 1, true)")))
 
 (define_memory_constraint "Uq"
  "@internal
@@ -391,3 +418,9 @@
 ;; Additionally, we used to have a Q constraint in Thumb state, but
 ;; this wasn't really a valid memory constraint.  Again, all uses of
 ;; this now seem to have been removed.
+
+(define_constraint "Ss"
+ "@internal
+  Ss is a symbol reference."
+ (match_code "symbol_ref")
+)
diff --git a/gcc/config/arm/cortex-a15.md b/gcc/config/arm/cortex-a15.md
index f0c1985..981d055 100644
--- a/gcc/config/arm/cortex-a15.md
+++ b/gcc/config/arm/cortex-a15.md
@@ -87,28 +87,26 @@
 ;; 32-bit multiplies
 (define_insn_reservation "cortex_a15_mult32" 3
   (and (eq_attr "tune" "cortexa15")
-       (and (eq_attr "type" "mult")
-	    (and (eq_attr "neon_type" "none")
-		 (eq_attr "mul64" "no"))))
+       (and (eq_attr "mul32" "yes")
+	    (eq_attr "neon_type" "none")))
   "ca15_issue1,ca15_mx")
 
 ;; 64-bit multiplies
 (define_insn_reservation "cortex_a15_mult64" 4
   (and (eq_attr "tune" "cortexa15")
-       (and (eq_attr "type" "mult")
-	    (and (eq_attr "neon_type" "none")
-		 (eq_attr "mul64" "yes"))))
+       (and (eq_attr "mul64" "yes")
+	    (eq_attr "neon_type" "none")))
   "ca15_issue1,ca15_mx*2")
 
 ;; Integer divide
 (define_insn_reservation "cortex_a15_udiv" 9
   (and (eq_attr "tune" "cortexa15")
-       (eq_attr "insn" "udiv"))
+       (eq_attr "type" "udiv"))
   "ca15_issue1,ca15_mx")
 
 (define_insn_reservation "cortex_a15_sdiv" 10
   (and (eq_attr "tune" "cortexa15")
-       (eq_attr "insn" "sdiv"))
+       (eq_attr "type" "sdiv"))
   "ca15_issue1,ca15_mx")
 
 ;; Block all issue pipes for a cycle
diff --git a/gcc/config/arm/cortex-a5.md b/gcc/config/arm/cortex-a5.md
index 41a2c37..963d5ba 100644
--- a/gcc/config/arm/cortex-a5.md
+++ b/gcc/config/arm/cortex-a5.md
@@ -80,7 +80,8 @@
 
 (define_insn_reservation "cortex_a5_mul" 2
   (and (eq_attr "tune" "cortexa5")
-       (eq_attr "type" "mult"))
+       (ior (eq_attr "mul32" "yes")
+	    (eq_attr "mul64" "yes")))
   "cortex_a5_ex1")
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
diff --git a/gcc/config/arm/cortex-a53.md b/gcc/config/arm/cortex-a53.md
new file mode 100644
index 0000000..e67fe55
--- /dev/null
+++ b/gcc/config/arm/cortex-a53.md
@@ -0,0 +1,297 @@
+;; ARM Cortex-A53 pipeline description
+;; Copyright (C) 2013 Free Software Foundation, Inc.
+;;
+;; Contributed by ARM Ltd.
+;;
+;; This file is part of GCC.
+;;
+;; GCC is free software; you can redistribute it and/or modify it
+;; under the terms of the GNU General Public License as published by
+;; the Free Software Foundation; either version 3, or (at your option)
+;; any later version.
+;;
+;; GCC is distributed in the hope that it will be useful, but
+;; WITHOUT ANY WARRANTY; without even the implied warranty of
+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+;; General Public License for more details.
+;;
+;; You should have received a copy of the GNU General Public License
+;; along with GCC; see the file COPYING3.  If not see
+;; <http://www.gnu.org/licenses/>.
+
+(define_automaton "cortex_a53")
+
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; Functional units.
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+
+;; There are two main integer execution pipelines, described as
+;; slot 0 and issue slot 1.
+
+(define_cpu_unit "cortex_a53_slot0" "cortex_a53")
+(define_cpu_unit "cortex_a53_slot1" "cortex_a53")
+
+(define_reservation "cortex_a53_slot_any" "cortex_a53_slot0|cortex_a53_slot1")
+(define_reservation "cortex_a53_single_issue" "cortex_a53_slot0+cortex_a53_slot1")
+
+;; The load/store pipeline.  Load/store instructions can dual-issue from
+;; either pipeline, but two load/stores cannot simultaneously issue.
+
+(define_cpu_unit "cortex_a53_ls" "cortex_a53")
+
+;; The store pipeline.  Shared between both execution pipelines.
+
+(define_cpu_unit "cortex_a53_store" "cortex_a53")
+
+;; The branch pipeline.  Branches can dual-issue with other instructions
+;; (except when those instructions take multiple cycles to issue).
+
+(define_cpu_unit "cortex_a53_branch" "cortex_a53")
+
+;; The integer divider.
+
+(define_cpu_unit "cortex_a53_idiv" "cortex_a53")
+
+;; The floating-point add pipeline used to model the usage
+;; of the add pipeline by fmac instructions.
+
+(define_cpu_unit "cortex_a53_fpadd_pipe" "cortex_a53")
+
+;; Floating-point div/sqrt (long latency, out-of-order completion).
+
+(define_cpu_unit "cortex_a53_fp_div_sqrt" "cortex_a53")
+
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; ALU instructions.
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+
+(define_insn_reservation "cortex_a53_alu" 2
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "alu_reg,simple_alu_imm"))
+  "cortex_a53_slot_any")
+
+(define_insn_reservation "cortex_a53_alu_shift" 2
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "alu_shift,alu_shift_reg"))
+  "cortex_a53_slot_any")
+
+;; Forwarding path for unshifted operands.
+
+(define_bypass 1 "cortex_a53_alu,cortex_a53_alu_shift"
+  "cortex_a53_alu")
+
+(define_bypass 1 "cortex_a53_alu,cortex_a53_alu_shift"
+  "cortex_a53_alu_shift"
+  "arm_no_early_alu_shift_dep")
+
+;; The multiplier pipeline can forward results so there's no need to specify
+;; bypasses. Multiplies can only single-issue currently.
+
+(define_insn_reservation "cortex_a53_mul" 3
+  (and (eq_attr "tune" "cortexa53")
+       (ior (eq_attr "mul32" "yes")
+            (eq_attr "mul64" "yes")))
+  "cortex_a53_single_issue")
+
+;; A multiply with a single-register result or an MLA, followed by an
+;; MLA with an accumulator dependency, has its result forwarded so two
+;; such instructions can issue back-to-back.
+
+(define_bypass 1 "cortex_a53_mul"
+               "cortex_a53_mul"
+               "arm_mac_accumulator_is_mul_result")
+
+;; Punt with a high enough latency for divides.
+(define_insn_reservation "cortex_a53_udiv" 8
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "udiv"))
+  "(cortex_a53_slot0+cortex_a53_idiv),cortex_a53_idiv*7")
+
+(define_insn_reservation "cortex_a53_sdiv" 9
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "sdiv"))
+  "(cortex_a53_slot0+cortex_a53_idiv),cortex_a53_idiv*8")
+
+
+(define_bypass 2 "cortex_a53_mul,cortex_a53_udiv,cortex_a53_sdiv"
+               "cortex_a53_alu")
+(define_bypass 2 "cortex_a53_mul,cortex_a53_udiv,cortex_a53_sdiv"
+               "cortex_a53_alu_shift"
+               "arm_no_early_alu_shift_dep")
+
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; Load/store instructions.
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+
+;; Address-generation happens in the issue stage.
+
+(define_insn_reservation "cortex_a53_load1" 3
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "load_byte,load1"))
+  "cortex_a53_slot_any+cortex_a53_ls")
+
+(define_insn_reservation "cortex_a53_store1" 2
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "store1"))
+  "cortex_a53_slot_any+cortex_a53_ls+cortex_a53_store")
+
+(define_insn_reservation "cortex_a53_load2" 3
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "load2"))
+  "cortex_a53_single_issue+cortex_a53_ls")
+
+(define_insn_reservation "cortex_a53_store2" 2
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "store2"))
+  "cortex_a53_single_issue+cortex_a53_ls+cortex_a53_store")
+
+(define_insn_reservation "cortex_a53_load3plus" 4
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "load3,load4"))
+  "(cortex_a53_single_issue+cortex_a53_ls)*2")
+
+(define_insn_reservation "cortex_a53_store3plus" 3
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "store3,store4"))
+  "(cortex_a53_single_issue+cortex_a53_ls+cortex_a53_store)*2")
+
+;; Load/store addresses are required early in Issue.
+(define_bypass 3 "cortex_a53_load1,cortex_a53_load2,cortex_a53_load3plus,cortex_a53_alu,cortex_a53_alu_shift"
+                 "cortex_a53_load*"
+                 "arm_early_load_addr_dep")
+(define_bypass 3 "cortex_a53_load1,cortex_a53_load2,cortex_a53_load3plus,cortex_a53_alu,cortex_a53_alu_shift"
+                 "cortex_a53_store*"
+                 "arm_early_store_addr_dep")
+
+;; Load data can forward in the ALU pipeline
+(define_bypass 2 "cortex_a53_load1,cortex_a53_load2"
+               "cortex_a53_alu")
+(define_bypass 2 "cortex_a53_load1,cortex_a53_load2"
+               "cortex_a53_alu_shift"
+               "arm_no_early_alu_shift_dep")
+
+;; ALU ops can forward to stores.
+(define_bypass 0 "cortex_a53_alu,cortex_a53_alu_shift"
+                 "cortex_a53_store1,cortex_a53_store2,cortex_a53_store3plus"
+                 "arm_no_early_store_addr_dep")
+
+(define_bypass 1 "cortex_a53_mul,cortex_a53_udiv,cortex_a53_sdiv,cortex_a53_load1,cortex_a53_load2,cortex_a53_load3plus"
+                 "cortex_a53_store1,cortex_a53_store2,cortex_a53_store3plus"
+                 "arm_no_early_store_addr_dep")
+
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; Branches.
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+
+;; Currently models all branches as dual-issuable from either execution
+;; slot, which isn't true for all cases. We still need to model indirect
+;; branches.
+
+(define_insn_reservation "cortex_a53_branch" 0
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "branch,call"))
+  "cortex_a53_slot_any+cortex_a53_branch")
+
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; Floating-point arithmetic.
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+
+(define_insn_reservation "cortex_a53_fpalu" 4
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "ffariths, fadds, ffarithd, faddd, fcpys, fmuls, f_cvt,\
+			fcmps, fcmpd"))
+  "cortex_a53_slot0+cortex_a53_fpadd_pipe")
+
+(define_insn_reservation "cortex_a53_fconst" 2
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "fconsts,fconstd"))
+  "cortex_a53_slot0+cortex_a53_fpadd_pipe")
+
+(define_insn_reservation "cortex_a53_fpmul" 4
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "fmuls,fmuld"))
+  "cortex_a53_slot0")
+
+;; For single-precision multiply-accumulate, the add (accumulate) is issued after
+;; the multiply completes. Model that accordingly.
+
+(define_insn_reservation "cortex_a53_fpmac" 8
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "fmacs,fmacd,ffmas,ffmad"))
+  "cortex_a53_slot0, nothing*3, cortex_a53_fpadd_pipe")
+
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; Floating-point divide/square root instructions.
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; fsqrt really takes one cycle less, but that is not modelled.
+
+(define_insn_reservation "cortex_a53_fdivs" 14
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "fdivs"))
+  "cortex_a53_slot0, cortex_a53_fp_div_sqrt * 13")
+
+(define_insn_reservation "cortex_a53_fdivd" 29
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "fdivd"))
+  "cortex_a53_slot0, cortex_a53_fp_div_sqrt * 28")
+
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; VFP to/from core transfers.
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+
+(define_insn_reservation "cortex_a53_r2f" 4
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "r_2_f"))
+  "cortex_a53_slot0")
+
+(define_insn_reservation "cortex_a53_f2r" 2
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "f_2_r"))
+  "cortex_a53_slot0")
+
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; VFP flag transfer.
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+
+(define_insn_reservation "cortex_a53_f_flags" 4
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "f_flag"))
+  "cortex_a53_slot0")
+
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+;; VFP load/store.
+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
+
+(define_insn_reservation "cortex_a53_f_loads" 4
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "f_loads"))
+  "cortex_a53_slot0")
+
+(define_insn_reservation "cortex_a53_f_loadd" 5
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "f_loadd"))
+  "cortex_a53_slot0")
+
+(define_insn_reservation "cortex_a53_f_stores" 0
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "f_stores"))
+  "cortex_a53_slot0")
+
+(define_insn_reservation "cortex_a53_f_stored" 0
+  (and (eq_attr "tune" "cortexa53")
+       (eq_attr "type" "f_stored"))
+  "cortex_a53_slot0")
+
+;; Load-to-use for floating-point values has a penalty of one cycle,
+;; i.e. a latency of two.
+
+(define_bypass 2 "cortex_a53_f_loads"
+                 "cortex_a53_fpalu, cortex_a53_fpmac, cortex_a53_fpmul,\
+		  cortex_a53_fdivs, cortex_a53_fdivd,\
+		  cortex_a53_f2r")
+
+(define_bypass 2 "cortex_a53_f_loadd"
+                 "cortex_a53_fpalu, cortex_a53_fpmac, cortex_a53_fpmul,\
+		  cortex_a53_fdivs, cortex_a53_fdivd,\
+		  cortex_a53_f2r")
+
diff --git a/gcc/config/arm/cortex-a7.md b/gcc/config/arm/cortex-a7.md
index 3750f74..960174f 100644
--- a/gcc/config/arm/cortex-a7.md
+++ b/gcc/config/arm/cortex-a7.md
@@ -127,8 +127,9 @@
 
 (define_insn_reservation "cortex_a7_mul" 2
   (and (eq_attr "tune" "cortexa7")
-       (and (eq_attr "type" "mult")
-            (eq_attr "neon_type" "none")))
+       (and (eq_attr "neon_type" "none")
+            (ior (eq_attr "mul32" "yes")
+                 (eq_attr "mul64" "yes"))))
   "cortex_a7_both")
 
 ;; Forward the result of a multiply operation to the accumulator 
@@ -140,7 +141,7 @@
 ;; The latency depends on the operands, so we use an estimate here.
 (define_insn_reservation "cortex_a7_idiv" 5
   (and (eq_attr "tune" "cortexa7")
-       (eq_attr "insn" "udiv,sdiv"))
+       (eq_attr "type" "udiv,sdiv"))
   "cortex_a7_both*5")
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
diff --git a/gcc/config/arm/cortex-a8.md b/gcc/config/arm/cortex-a8.md
index bd1132a..8d3e987 100644
--- a/gcc/config/arm/cortex-a8.md
+++ b/gcc/config/arm/cortex-a8.md
@@ -139,22 +139,22 @@
 
 (define_insn_reservation "cortex_a8_mul" 6
   (and (eq_attr "tune" "cortexa8")
-       (eq_attr "insn" "mul,smulxy,smmul"))
+       (eq_attr "type" "mul,smulxy,smmul"))
   "cortex_a8_multiply_2")
 
 (define_insn_reservation "cortex_a8_mla" 6
   (and (eq_attr "tune" "cortexa8")
-       (eq_attr "insn" "mla,smlaxy,smlawy,smmla,smlad,smlsd"))
+       (eq_attr "type" "mla,smlaxy,smlawy,smmla,smlad,smlsd"))
   "cortex_a8_multiply_2")
 
 (define_insn_reservation "cortex_a8_mull" 7
   (and (eq_attr "tune" "cortexa8")
-       (eq_attr "insn" "smull,umull,smlal,umlal,umaal,smlalxy"))
+       (eq_attr "type" "smull,umull,smlal,umlal,umaal,smlalxy"))
   "cortex_a8_multiply_3")
 
 (define_insn_reservation "cortex_a8_smulwy" 5
   (and (eq_attr "tune" "cortexa8")
-       (eq_attr "insn" "smulwy,smuad,smusd"))
+       (eq_attr "type" "smulwy,smuad,smusd"))
   "cortex_a8_multiply")
 
 ;; smlald and smlsld are multiply-accumulate instructions but do not
@@ -162,7 +162,7 @@
 ;; cannot go in cortex_a8_mla above.  (See below for bypass details.)
 (define_insn_reservation "cortex_a8_smlald" 6
   (and (eq_attr "tune" "cortexa8")
-       (eq_attr "insn" "smlald,smlsld"))
+       (eq_attr "type" "smlald,smlsld"))
   "cortex_a8_multiply_2")
 
 ;; A multiply with a single-register result or an MLA, followed by an
diff --git a/gcc/config/arm/cortex-a9.md b/gcc/config/arm/cortex-a9.md
index abbaa8d..05c114d 100644
--- a/gcc/config/arm/cortex-a9.md
+++ b/gcc/config/arm/cortex-a9.md
@@ -130,29 +130,29 @@ cortex_a9_p1_e2 + cortex_a9_p0_e1 + cortex_a9_p1_e1")
 ;; We get 16*16 multiply / mac results in 3 cycles.
 (define_insn_reservation "cortex_a9_mult16" 3
   (and (eq_attr "tune" "cortexa9")
-       (eq_attr "insn" "smulxy"))
+       (eq_attr "type" "smulxy"))
        "cortex_a9_mult16")
 
 ;; The 16*16 mac is slightly different that it
 ;; reserves M1 and M2 in the same cycle.
 (define_insn_reservation "cortex_a9_mac16" 3
   (and (eq_attr "tune" "cortexa9")
-       (eq_attr "insn" "smlaxy"))
+       (eq_attr "type" "smlaxy"))
   "cortex_a9_mac16")
 
 (define_insn_reservation "cortex_a9_multiply" 4
   (and (eq_attr "tune" "cortexa9")
-       (eq_attr "insn" "mul,smmul,smmulr"))
+       (eq_attr "type" "mul,smmul,smmulr"))
        "cortex_a9_mult")
 
 (define_insn_reservation "cortex_a9_mac" 4
   (and (eq_attr "tune" "cortexa9")
-       (eq_attr "insn" "mla,smmla"))
+       (eq_attr "type" "mla,smmla"))
        "cortex_a9_mac")
 
 (define_insn_reservation "cortex_a9_multiply_long" 5
   (and (eq_attr "tune" "cortexa9")
-       (eq_attr "insn" "smull,umull,smulls,umulls,smlal,smlals,umlal,umlals"))
+       (eq_attr "type" "smull,umull,smulls,umulls,smlal,smlals,umlal,umlals"))
        "cortex_a9_mult_long")
 
 ;; An instruction with a result in E2 can be forwarded
diff --git a/gcc/config/arm/cortex-m4-fpu.md b/gcc/config/arm/cortex-m4-fpu.md
index a1945be..4ce3f10 100644
--- a/gcc/config/arm/cortex-m4-fpu.md
+++ b/gcc/config/arm/cortex-m4-fpu.md
@@ -18,10 +18,14 @@
 ;; along with GCC; see the file COPYING3.  If not see
 ;; <http://www.gnu.org/licenses/>.
 
-;; Use an artifial unit to model FPU.
-(define_cpu_unit "cortex_m4_v" "cortex_m4")
+;; Use two artificial units to model FPU.
+(define_cpu_unit "cortex_m4_v_a" "cortex_m4")
+(define_cpu_unit "cortex_m4_v_b" "cortex_m4")
 
+(define_reservation "cortex_m4_v" "cortex_m4_v_a+cortex_m4_v_b")
 (define_reservation "cortex_m4_ex_v" "cortex_m4_ex+cortex_m4_v")
+(define_reservation "cortex_m4_exa_va" "cortex_m4_a+cortex_m4_v_a")
+(define_reservation "cortex_m4_exb_vb" "cortex_m4_b+cortex_m4_v_b")
 
 ;; Integer instructions following VDIV or VSQRT complete out-of-order.
 (define_insn_reservation "cortex_m4_fdivs" 15
@@ -44,10 +48,12 @@
        (eq_attr "type" "fmuls"))
   "cortex_m4_ex_v")
 
+;; Integer instructions following multiply-accumulate instructions
+;; complete out-of-order.
 (define_insn_reservation "cortex_m4_fmacs" 4
   (and (eq_attr "tune" "cortexm4")
        (eq_attr "type" "fmacs,ffmas"))
-  "cortex_m4_ex_v*3")
+  "cortex_m4_ex_v,cortex_m4_v*2")
 
 (define_insn_reservation "cortex_m4_ffariths" 1
   (and (eq_attr "tune" "cortexm4")
@@ -77,12 +83,12 @@
 (define_insn_reservation "cortex_m4_f_load" 2
   (and (eq_attr "tune" "cortexm4")
        (eq_attr "type" "f_loads"))
-  "cortex_m4_ex_v*2")
+  "cortex_m4_exa_va,cortex_m4_exb_vb")
 
-(define_insn_reservation "cortex_m4_f_store" 2
+(define_insn_reservation "cortex_m4_f_store" 1
   (and (eq_attr "tune" "cortexm4")
        (eq_attr "type" "f_stores"))
-  "cortex_m4_ex_v*2")
+  "cortex_m4_exa_va")
 
 (define_insn_reservation "cortex_m4_f_loadd" 3
   (and (eq_attr "tune" "cortexm4")
diff --git a/gcc/config/arm/cortex-m4.md b/gcc/config/arm/cortex-m4.md
index 187867b..dc3a329 100644
--- a/gcc/config/arm/cortex-m4.md
+++ b/gcc/config/arm/cortex-m4.md
@@ -31,7 +31,10 @@
 ;; ALU and multiply is one cycle.
 (define_insn_reservation "cortex_m4_alu" 1
   (and (eq_attr "tune" "cortexm4")
-       (eq_attr "type" "alu_reg,simple_alu_imm,simple_alu_shift,alu_shift,alu_shift_reg,mult"))
+       (ior (eq_attr "type" "alu_reg,simple_alu_imm,simple_alu_shift,\
+                             alu_shift,alu_shift_reg")
+	    (ior (eq_attr "mul32" "yes")
+		 (eq_attr "mul64" "yes"))))
   "cortex_m4_ex")
 
 ;; Byte, half-word and word load is two cycles.
@@ -84,6 +87,10 @@
        (eq_attr "type" "store4"))
   "cortex_m4_ex*5")
 
+(define_bypass 1 "cortex_m4_load1"
+                 "cortex_m4_store1_1,cortex_m4_store1_2"
+                 "arm_no_early_store_addr_dep")
+
 ;; If the address of load or store depends on the result of the preceding
 ;; instruction, the latency is increased by one.
 
diff --git a/gcc/config/arm/cortex-r4.md b/gcc/config/arm/cortex-r4.md
index 84e4a3a..6d37079 100644
--- a/gcc/config/arm/cortex-r4.md
+++ b/gcc/config/arm/cortex-r4.md
@@ -128,32 +128,32 @@
 
 (define_insn_reservation "cortex_r4_mul_4" 4
   (and (eq_attr "tune_cortexr4" "yes")
-       (eq_attr "insn" "mul,smmul"))
+       (eq_attr "type" "mul,smmul"))
   "cortex_r4_mul_2")
 
 (define_insn_reservation "cortex_r4_mul_3" 3
   (and (eq_attr "tune_cortexr4" "yes")
-       (eq_attr "insn" "smulxy,smulwy,smuad,smusd"))
+       (eq_attr "type" "smulxy,smulwy,smuad,smusd"))
   "cortex_r4_mul")
 
 (define_insn_reservation "cortex_r4_mla_4" 4
   (and (eq_attr "tune_cortexr4" "yes")
-       (eq_attr "insn" "mla,smmla"))
+       (eq_attr "type" "mla,smmla"))
   "cortex_r4_mul_2")
 
 (define_insn_reservation "cortex_r4_mla_3" 3
   (and (eq_attr "tune_cortexr4" "yes")
-       (eq_attr "insn" "smlaxy,smlawy,smlad,smlsd"))
+       (eq_attr "type" "smlaxy,smlawy,smlad,smlsd"))
   "cortex_r4_mul")
 
 (define_insn_reservation "cortex_r4_smlald" 3
   (and (eq_attr "tune_cortexr4" "yes")
-       (eq_attr "insn" "smlald,smlsld"))
+       (eq_attr "type" "smlald,smlsld"))
   "cortex_r4_mul")
 
 (define_insn_reservation "cortex_r4_mull" 4
   (and (eq_attr "tune_cortexr4" "yes")
-       (eq_attr "insn" "smull,umull,umlal,umaal"))
+       (eq_attr "type" "smull,umull,umlal,umaal"))
   "cortex_r4_mul_2")
 
 ;; A multiply or an MLA with a single-register result, followed by an
@@ -196,12 +196,12 @@
 ;; This gives a latency of nine for udiv and ten for sdiv.
 (define_insn_reservation "cortex_r4_udiv" 9
   (and (eq_attr "tune_cortexr4" "yes")
-       (eq_attr "insn" "udiv"))
+       (eq_attr "type" "udiv"))
   "cortex_r4_div_9")
 
 (define_insn_reservation "cortex_r4_sdiv" 10
   (and (eq_attr "tune_cortexr4" "yes")
-       (eq_attr "insn" "sdiv"))
+       (eq_attr "type" "sdiv"))
   "cortex_r4_div_10")
 
 ;; Branches.  We assume correct prediction.
diff --git a/gcc/config/arm/elf.h b/gcc/config/arm/elf.h
index 5e21a08..96fadeb 100644
--- a/gcc/config/arm/elf.h
+++ b/gcc/config/arm/elf.h
@@ -51,8 +51,7 @@
 #undef SUBSUBTARGET_EXTRA_SPECS
 #define SUBSUBTARGET_EXTRA_SPECS
 
-#ifndef ASM_SPEC
-#define ASM_SPEC "\
+#define DEFAULT_ASM_SPEC "\
 %{mbig-endian:-EB} \
 %{mlittle-endian:-EL} \
 %(asm_cpu_spec) \
@@ -61,6 +60,9 @@
 %{mthumb-interwork:-mthumb-interwork} \
 %{mfloat-abi=*} %{mfpu=*} \
 %(subtarget_extra_asm_spec)"
+
+#ifndef ASM_SPEC
+#define ASM_SPEC DEFAULT_ASM_SPEC
 #endif
 
 /* The ARM uses @ are a comment character so we need to redefine
diff --git a/gcc/config/arm/fa526.md b/gcc/config/arm/fa526.md
index e03894a..efc6a1d 100644
--- a/gcc/config/arm/fa526.md
+++ b/gcc/config/arm/fa526.md
@@ -76,12 +76,12 @@
 
 (define_insn_reservation "526_mult1" 2
  (and (eq_attr "tune" "fa526")
-      (eq_attr "insn" "smlalxy,smulxy,smlaxy,smlalxy"))
+      (eq_attr "type" "smlalxy,smulxy,smlaxy,smlalxy"))
  "fa526_core")
 
 (define_insn_reservation "526_mult2" 5
  (and (eq_attr "tune" "fa526")
-      (eq_attr "insn" "mul,mla,muls,mlas,umull,umlal,smull,smlal,umulls,\
+      (eq_attr "type" "mul,mla,muls,mlas,umull,umlal,smull,smlal,umulls,\
                        umlals,smulls,smlals,smlawx"))
  "fa526_core*4")
 
diff --git a/gcc/config/arm/fa606te.md b/gcc/config/arm/fa606te.md
index d53617a..dec26c5 100644
--- a/gcc/config/arm/fa606te.md
+++ b/gcc/config/arm/fa606te.md
@@ -71,22 +71,22 @@
 
 (define_insn_reservation "606te_mult1" 2
  (and (eq_attr "tune" "fa606te")
-      (eq_attr "insn" "smlalxy"))
+      (eq_attr "type" "smlalxy"))
  "fa606te_core")
 
 (define_insn_reservation "606te_mult2" 3
  (and (eq_attr "tune" "fa606te")
-      (eq_attr "insn" "smlaxy,smulxy,smulwy,smlawy"))
+      (eq_attr "type" "smlaxy,smulxy,smulwy,smlawy"))
  "fa606te_core*2")
 
 (define_insn_reservation "606te_mult3" 4
  (and (eq_attr "tune" "fa606te")
-      (eq_attr "insn" "mul,mla,muls,mlas"))
+      (eq_attr "type" "mul,mla,muls,mlas"))
  "fa606te_core*3")
 
 (define_insn_reservation "606te_mult4" 5
  (and (eq_attr "tune" "fa606te")
-      (eq_attr "insn" "umull,umlal,smull,smlal,umulls,umlals,smulls,smlals"))
+      (eq_attr "type" "umull,umlal,smull,smlal,umulls,umlals,smulls,smlals"))
  "fa606te_core*4")
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
diff --git a/gcc/config/arm/fa626te.md b/gcc/config/arm/fa626te.md
index 690cb46..818ad60 100644
--- a/gcc/config/arm/fa626te.md
+++ b/gcc/config/arm/fa626te.md
@@ -82,22 +82,22 @@
 
 (define_insn_reservation "626te_mult1" 2
  (and (eq_attr "tune" "fa626,fa626te")
-      (eq_attr "insn" "smulwy,smlawy,smulxy,smlaxy"))
+      (eq_attr "type" "smulwy,smlawy,smulxy,smlaxy"))
  "fa626te_core")
 
 (define_insn_reservation "626te_mult2" 2
  (and (eq_attr "tune" "fa626,fa626te")
-      (eq_attr "insn" "mul,mla"))
+      (eq_attr "type" "mul,mla"))
  "fa626te_core")
 
 (define_insn_reservation "626te_mult3" 3
  (and (eq_attr "tune" "fa626,fa626te")
-      (eq_attr "insn" "muls,mlas,smull,smlal,umull,umlal,smlalxy,smlawx"))
+      (eq_attr "type" "muls,mlas,smull,smlal,umull,umlal,smlalxy,smlawx"))
  "fa626te_core*2")
 
 (define_insn_reservation "626te_mult4" 4
  (and (eq_attr "tune" "fa626,fa626te")
-      (eq_attr "insn" "smulls,smlals,umulls,umlals"))
+      (eq_attr "type" "smulls,smlals,umulls,umlals"))
  "fa626te_core*3")
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
diff --git a/gcc/config/arm/fa726te.md b/gcc/config/arm/fa726te.md
index 07ab018..8790b03 100644
--- a/gcc/config/arm/fa726te.md
+++ b/gcc/config/arm/fa726te.md
@@ -115,7 +115,7 @@
 
 (define_insn_reservation "726te_mult_op" 3
  (and (eq_attr "tune" "fa726te")
-      (eq_attr "insn" "smlalxy,mul,mla,muls,mlas,umull,umlal,smull,smlal,\
+      (eq_attr "type" "smlalxy,mul,mla,muls,mlas,umull,umlal,smull,smlal,\
                        umulls,umlals,smulls,smlals,smlawx,smulxy,smlaxy"))
  "fa726te_issue+fa726te_mac_pipe")
 
diff --git a/gcc/config/arm/fmp626.md b/gcc/config/arm/fmp626.md
index 8691450..f3b7dad 100644
--- a/gcc/config/arm/fmp626.md
+++ b/gcc/config/arm/fmp626.md
@@ -77,22 +77,22 @@
 
 (define_insn_reservation "mp626_mult1" 2
  (and (eq_attr "tune" "fmp626")
-      (eq_attr "insn" "smulwy,smlawy,smulxy,smlaxy"))
+      (eq_attr "type" "smulwy,smlawy,smulxy,smlaxy"))
  "fmp626_core")
 
 (define_insn_reservation "mp626_mult2" 2
  (and (eq_attr "tune" "fmp626")
-      (eq_attr "insn" "mul,mla"))
+      (eq_attr "type" "mul,mla"))
  "fmp626_core")
 
 (define_insn_reservation "mp626_mult3" 3
  (and (eq_attr "tune" "fmp626")
-      (eq_attr "insn" "muls,mlas,smull,smlal,umull,umlal,smlalxy,smlawx"))
+      (eq_attr "type" "muls,mlas,smull,smlal,umull,umlal,smlalxy,smlawx"))
  "fmp626_core*2")
 
 (define_insn_reservation "mp626_mult4" 4
  (and (eq_attr "tune" "fmp626")
-      (eq_attr "insn" "smulls,smlals,umulls,umlals"))
+      (eq_attr "type" "smulls,smlals,umulls,umlals"))
  "fmp626_core*3")
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
diff --git a/gcc/config/arm/iterators.md b/gcc/config/arm/iterators.md
index b3ad42b..d84929f 100644
--- a/gcc/config/arm/iterators.md
+++ b/gcc/config/arm/iterators.md
@@ -496,3 +496,11 @@
 (define_int_attr nvrint_variant [(UNSPEC_NVRINTZ "z") (UNSPEC_NVRINTP "p")
                                 (UNSPEC_NVRINTA "a") (UNSPEC_NVRINTM "m")
                                 (UNSPEC_NVRINTX "x") (UNSPEC_NVRINTN "n")])
+;; Both kinds of return insn.
+(define_code_iterator returns [return simple_return])
+(define_code_attr return_str [(return "") (simple_return "simple_")])
+(define_code_attr return_simple_p [(return "false") (simple_return "true")])
+(define_code_attr return_cond_false [(return " && USE_RETURN_INSN (FALSE)")
+                               (simple_return " && use_simple_return_p ()")])
+(define_code_attr return_cond_true [(return " && USE_RETURN_INSN (TRUE)")
+                               (simple_return " && use_simple_return_p ()")])
diff --git a/gcc/config/arm/iwmmxt.md b/gcc/config/arm/iwmmxt.md
index 9e79454..f1f0a5c 100644
--- a/gcc/config/arm/iwmmxt.md
+++ b/gcc/config/arm/iwmmxt.md
@@ -18,12 +18,12 @@
 ;; along with GCC; see the file COPYING3.  If not see
 ;; <http://www.gnu.org/licenses/>.
 
-;; Register numbers
+;; Register numbers. Need to sync with FIRST_IWMMXT_GR_REGNUM in arm.h
 (define_constants
-  [(WCGR0           43)
-   (WCGR1           44)
-   (WCGR2           45)
-   (WCGR3           46)
+  [(WCGR0           96)
+   (WCGR1           97)
+   (WCGR2           98)
+   (WCGR3           99)
   ]
 )
 
@@ -33,7 +33,7 @@
   "TARGET_REALLY_IWMMXT"
   "tbcstb%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tbcst")]
+   (set_attr "type" "wmmx_tbcst")]
 )
 
 (define_insn "tbcstv4hi"
@@ -42,7 +42,7 @@
   "TARGET_REALLY_IWMMXT"
   "tbcsth%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tbcst")]
+   (set_attr "type" "wmmx_tbcst")]
 )
 
 (define_insn "tbcstv2si"
@@ -51,7 +51,7 @@
   "TARGET_REALLY_IWMMXT"
   "tbcstw%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tbcst")]
+   (set_attr "type" "wmmx_tbcst")]
 )
 
 (define_insn "iwmmxt_iordi3"
@@ -65,7 +65,7 @@
    #"
   [(set_attr "predicable" "yes")
    (set_attr "length" "4,8,8")
-   (set_attr "wtype" "wor,none,none")]
+   (set_attr "type" "wmmx_wor,*,*")]
 )
 
 (define_insn "iwmmxt_xordi3"
@@ -79,7 +79,7 @@
    #"
   [(set_attr "predicable" "yes")
    (set_attr "length" "4,8,8")
-   (set_attr "wtype" "wxor,none,none")]
+   (set_attr "type" "wmmx_wxor,*,*")]
 )
 
 (define_insn "iwmmxt_anddi3"
@@ -93,7 +93,7 @@
    #"
   [(set_attr "predicable" "yes")
    (set_attr "length" "4,8,8")
-   (set_attr "wtype" "wand,none,none")]
+   (set_attr "type" "wmmx_wand,*,*")]
 )
 
 (define_insn "iwmmxt_nanddi3"
@@ -103,7 +103,7 @@
   "TARGET_REALLY_IWMMXT"
   "wandn%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wandn")]
+   (set_attr "type" "wmmx_wandn")]
 )
 
 (define_insn "*iwmmxt_arm_movdi"
@@ -155,10 +155,9 @@
                                  (const_int 8)
                                  (const_int 4))]
                               (const_int 4)))
-   (set_attr "type" "*,*,*,load2,store2,*,*,*,*,*,r_2_f,f_2_r,ffarithd,f_loadd,f_stored")
+   (set_attr "type" "*,*,*,load2,store2,wmmx_wmov,wmmx_tmcrr,wmmx_tmrrc,wmmx_wldr,wmmx_wstr,r_2_f,f_2_r,ffarithd,f_loadd,f_stored")
    (set_attr "arm_pool_range" "*,*,*,1020,*,*,*,*,*,*,*,*,*,1020,*")
-   (set_attr "arm_neg_pool_range" "*,*,*,1008,*,*,*,*,*,*,*,*,*,1008,*")
-   (set_attr "wtype" "*,*,*,*,*,wmov,tmcrr,tmrrc,wldr,wstr,*,*,*,*,*")]
+   (set_attr "arm_neg_pool_range" "*,*,*,1008,*,*,*,*,*,*,*,*,*,1008,*")]
 )
 
 (define_insn "*iwmmxt_movsi_insn"
@@ -188,7 +187,7 @@
      default:
        gcc_unreachable ();
      }"
-  [(set_attr "type"           "*,*,*,*,load1,store1,*,*,*,*,r_2_f,f_2_r,fcpys,f_loads,f_stores")
+  [(set_attr "type"           "*,*,*,*,load1,store1,wmmx_tmcr,wmmx_tmrc,wmmx_wldr,wmmx_wstr,r_2_f,f_2_r,fcpys,f_loads,f_stores")
    (set_attr "length"         "*,*,*,*,*,        *,*,*,  16,     *,*,*,*,*,*")
    (set_attr "pool_range"     "*,*,*,*,4096,     *,*,*,1024,     *,*,*,*,1020,*")
    (set_attr "neg_pool_range" "*,*,*,*,4084,     *,*,*,   *,  1012,*,*,*,1008,*")
@@ -200,8 +199,7 @@
    ;; Also - we have to pretend that these insns clobber the condition code
    ;; bits as otherwise arm_final_prescan_insn() will try to conditionalize
    ;; them.
-   (set_attr "conds" "clob")
-   (set_attr "wtype" "*,*,*,*,*,*,tmcr,tmrc,wldr,wstr,*,*,*,*,*")]
+   (set_attr "conds" "clob")]
 )
 
 ;; Because iwmmxt_movsi_insn is not predicable, we provide the
@@ -249,10 +247,9 @@
    }"
   [(set_attr "predicable" "yes")
    (set_attr "length"         "4,     4,   4,4,4,8,   8,8")
-   (set_attr "type"           "*,*,*,*,*,*,load1,store1")
+   (set_attr "type"           "wmmx_wmov,wmmx_wstr,wmmx_wldr,wmmx_tmrrc,wmmx_tmcrr,*,load1,store1")
    (set_attr "pool_range"     "*,     *, 256,*,*,*, 256,*")
-   (set_attr "neg_pool_range" "*,     *, 244,*,*,*, 244,*")
-   (set_attr "wtype"          "wmov,wstr,wldr,tmrrc,tmcrr,*,*,*")]
+   (set_attr "neg_pool_range" "*,     *, 244,*,*,*, 244,*")]
 )
 
 (define_expand "iwmmxt_setwcgr0"
@@ -318,7 +315,7 @@
   "TARGET_REALLY_IWMMXT"
   "wand\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wand")]
+   (set_attr "type" "wmmx_wand")]
 )
 
 (define_insn "*ior<mode>3_iwmmxt"
@@ -328,7 +325,7 @@
   "TARGET_REALLY_IWMMXT"
   "wor\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wor")]
+   (set_attr "type" "wmmx_wor")]
 )
 
 (define_insn "*xor<mode>3_iwmmxt"
@@ -338,7 +335,7 @@
   "TARGET_REALLY_IWMMXT"
   "wxor\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wxor")]
+   (set_attr "type" "wmmx_wxor")]
 )
 
 
@@ -351,7 +348,7 @@
   "TARGET_REALLY_IWMMXT"
   "wadd<MMX_char>%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wadd")]
+   (set_attr "type" "wmmx_wadd")]
 )
 
 (define_insn "ssaddv8qi3"
@@ -361,7 +358,7 @@
   "TARGET_REALLY_IWMMXT"
   "waddbss%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wadd")]
+   (set_attr "type" "wmmx_wadd")]
 )
 
 (define_insn "ssaddv4hi3"
@@ -371,7 +368,7 @@
   "TARGET_REALLY_IWMMXT"
   "waddhss%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wadd")]
+   (set_attr "type" "wmmx_wadd")]
 )
 
 (define_insn "ssaddv2si3"
@@ -381,7 +378,7 @@
   "TARGET_REALLY_IWMMXT"
   "waddwss%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wadd")]
+   (set_attr "type" "wmmx_wadd")]
 )
 
 (define_insn "usaddv8qi3"
@@ -391,7 +388,7 @@
   "TARGET_REALLY_IWMMXT"
   "waddbus%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wadd")]
+   (set_attr "type" "wmmx_wadd")]
 )
 
 (define_insn "usaddv4hi3"
@@ -401,7 +398,7 @@
   "TARGET_REALLY_IWMMXT"
   "waddhus%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wadd")]
+   (set_attr "type" "wmmx_wadd")]
 )
 
 (define_insn "usaddv2si3"
@@ -411,7 +408,7 @@
   "TARGET_REALLY_IWMMXT"
   "waddwus%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wadd")]
+   (set_attr "type" "wmmx_wadd")]
 )
 
 (define_insn "*sub<mode>3_iwmmxt"
@@ -421,7 +418,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsub<MMX_char>%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsub")]
+   (set_attr "type" "wmmx_wsub")]
 )
 
 (define_insn "sssubv8qi3"
@@ -431,7 +428,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsubbss%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsub")]
+   (set_attr "type" "wmmx_wsub")]
 )
 
 (define_insn "sssubv4hi3"
@@ -441,7 +438,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsubhss%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsub")]
+   (set_attr "type" "wmmx_wsub")]
 )
 
 (define_insn "sssubv2si3"
@@ -451,7 +448,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsubwss%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsub")]
+   (set_attr "type" "wmmx_wsub")]
 )
 
 (define_insn "ussubv8qi3"
@@ -461,7 +458,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsubbus%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsub")]
+   (set_attr "type" "wmmx_wsub")]
 )
 
 (define_insn "ussubv4hi3"
@@ -471,7 +468,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsubhus%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsub")]
+   (set_attr "type" "wmmx_wsub")]
 )
 
 (define_insn "ussubv2si3"
@@ -481,7 +478,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsubwus%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsub")]
+   (set_attr "type" "wmmx_wsub")]
 )
 
 (define_insn "*mulv4hi3_iwmmxt"
@@ -491,7 +488,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulul%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmul")]
+   (set_attr "type" "wmmx_wmul")]
 )
 
 (define_insn "smulv4hi3_highpart"
@@ -504,7 +501,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulsm%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmul")]
+   (set_attr "type" "wmmx_wmul")]
 )
 
 (define_insn "umulv4hi3_highpart"
@@ -517,7 +514,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulum%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmul")]
+   (set_attr "type" "wmmx_wmul")]
 )
 
 (define_insn "iwmmxt_wmacs"
@@ -528,7 +525,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmacs%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmac")]
+   (set_attr "type" "wmmx_wmac")]
 )
 
 (define_insn "iwmmxt_wmacsz"
@@ -538,7 +535,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmacsz%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmac")]
+   (set_attr "type" "wmmx_wmac")]
 )
 
 (define_insn "iwmmxt_wmacu"
@@ -549,7 +546,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmacu%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmac")]
+   (set_attr "type" "wmmx_wmac")]
 )
 
 (define_insn "iwmmxt_wmacuz"
@@ -559,7 +556,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmacuz%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmac")]
+   (set_attr "type" "wmmx_wmac")]
 )
 
 ;; Same as xordi3, but don't show input operands so that we don't think
@@ -570,7 +567,7 @@
   "TARGET_REALLY_IWMMXT"
   "wxor%?\\t%0, %0, %0"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wxor")]
+   (set_attr "type" "wmmx_wxor")]
 )
 
 ;; Seems like cse likes to generate these, so we have to support them.
@@ -584,7 +581,7 @@
   "TARGET_REALLY_IWMMXT"
   "wxor%?\\t%0, %0, %0"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wxor")]
+   (set_attr "type" "wmmx_wxor")]
 )
 
 (define_insn "iwmmxt_clrv4hi"
@@ -594,7 +591,7 @@
   "TARGET_REALLY_IWMMXT"
   "wxor%?\\t%0, %0, %0"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wxor")]
+   (set_attr "type" "wmmx_wxor")]
 )
 
 (define_insn "iwmmxt_clrv2si"
@@ -603,7 +600,7 @@
   "TARGET_REALLY_IWMMXT"
   "wxor%?\\t%0, %0, %0"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wxor")]
+   (set_attr "type" "wmmx_wxor")]
 )
 
 ;; Unsigned averages/sum of absolute differences
@@ -627,7 +624,7 @@
   "TARGET_REALLY_IWMMXT"
   "wavg2br%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wavg2")]
+   (set_attr "type" "wmmx_wavg2")]
 )
 
 (define_insn "iwmmxt_uavgrndv4hi3"
@@ -645,7 +642,7 @@
   "TARGET_REALLY_IWMMXT"
   "wavg2hr%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wavg2")]
+   (set_attr "type" "wmmx_wavg2")]
 )
 
 (define_insn "iwmmxt_uavgv8qi3"
@@ -658,7 +655,7 @@
   "TARGET_REALLY_IWMMXT"
   "wavg2b%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wavg2")]
+   (set_attr "type" "wmmx_wavg2")]
 )
 
 (define_insn "iwmmxt_uavgv4hi3"
@@ -671,7 +668,7 @@
   "TARGET_REALLY_IWMMXT"
   "wavg2h%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wavg2")]
+   (set_attr "type" "wmmx_wavg2")]
 )
 
 ;; Insert/extract/shuffle
@@ -690,7 +687,7 @@
    }
    "
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tinsr")]
+   (set_attr "type" "wmmx_tinsr")]
 )
 
 (define_insn "iwmmxt_tinsrh"
@@ -707,7 +704,7 @@
    }
    "
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tinsr")]
+   (set_attr "type" "wmmx_tinsr")]
 )
 
 (define_insn "iwmmxt_tinsrw"
@@ -724,7 +721,7 @@
    }
    "
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tinsr")]
+   (set_attr "type" "wmmx_tinsr")]
 )
 
 (define_insn "iwmmxt_textrmub"
@@ -735,7 +732,7 @@
   "TARGET_REALLY_IWMMXT"
   "textrmub%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "textrm")]
+   (set_attr "type" "wmmx_textrm")]
 )
 
 (define_insn "iwmmxt_textrmsb"
@@ -746,7 +743,7 @@
   "TARGET_REALLY_IWMMXT"
   "textrmsb%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "textrm")]
+   (set_attr "type" "wmmx_textrm")]
 )
 
 (define_insn "iwmmxt_textrmuh"
@@ -757,7 +754,7 @@
   "TARGET_REALLY_IWMMXT"
   "textrmuh%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "textrm")]
+   (set_attr "type" "wmmx_textrm")]
 )
 
 (define_insn "iwmmxt_textrmsh"
@@ -768,7 +765,7 @@
   "TARGET_REALLY_IWMMXT"
   "textrmsh%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "textrm")]
+   (set_attr "type" "wmmx_textrm")]
 )
 
 ;; There are signed/unsigned variants of this instruction, but they are
@@ -780,7 +777,7 @@
   "TARGET_REALLY_IWMMXT"
   "textrmsw%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "textrm")]
+   (set_attr "type" "wmmx_textrm")]
 )
 
 (define_insn "iwmmxt_wshufh"
@@ -790,7 +787,7 @@
   "TARGET_REALLY_IWMMXT"
   "wshufh%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wshufh")]
+   (set_attr "type" "wmmx_wshufh")]
 )
 
 ;; Mask-generating comparisons
@@ -812,7 +809,7 @@
   "TARGET_REALLY_IWMMXT"
   "wcmpeqb%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wcmpeq")]
+   (set_attr "type" "wmmx_wcmpeq")]
 )
 
 (define_insn "eqv4hi3"
@@ -823,7 +820,7 @@
   "TARGET_REALLY_IWMMXT"
   "wcmpeqh%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wcmpeq")]
+   (set_attr "type" "wmmx_wcmpeq")]
 )
 
 (define_insn "eqv2si3"
@@ -835,7 +832,7 @@
   "TARGET_REALLY_IWMMXT"
   "wcmpeqw%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wcmpeq")]
+   (set_attr "type" "wmmx_wcmpeq")]
 )
 
 (define_insn "gtuv8qi3"
@@ -846,7 +843,7 @@
   "TARGET_REALLY_IWMMXT"
   "wcmpgtub%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wcmpgt")]
+   (set_attr "type" "wmmx_wcmpgt")]
 )
 
 (define_insn "gtuv4hi3"
@@ -857,7 +854,7 @@
   "TARGET_REALLY_IWMMXT"
   "wcmpgtuh%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wcmpgt")]
+   (set_attr "type" "wmmx_wcmpgt")]
 )
 
 (define_insn "gtuv2si3"
@@ -868,7 +865,7 @@
   "TARGET_REALLY_IWMMXT"
   "wcmpgtuw%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wcmpgt")]
+   (set_attr "type" "wmmx_wcmpgt")]
 )
 
 (define_insn "gtv8qi3"
@@ -879,7 +876,7 @@
   "TARGET_REALLY_IWMMXT"
   "wcmpgtsb%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wcmpgt")]
+   (set_attr "type" "wmmx_wcmpgt")]
 )
 
 (define_insn "gtv4hi3"
@@ -890,7 +887,7 @@
   "TARGET_REALLY_IWMMXT"
   "wcmpgtsh%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wcmpgt")]
+   (set_attr "type" "wmmx_wcmpgt")]
 )
 
 (define_insn "gtv2si3"
@@ -901,7 +898,7 @@
   "TARGET_REALLY_IWMMXT"
   "wcmpgtsw%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wcmpgt")]
+   (set_attr "type" "wmmx_wcmpgt")]
 )
 
 ;; Max/min insns
@@ -913,7 +910,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmaxs<MMX_char>%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmax")]
+   (set_attr "type" "wmmx_wmax")]
 )
 
 (define_insn "*umax<mode>3_iwmmxt"
@@ -923,7 +920,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmaxu<MMX_char>%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmax")]
+   (set_attr "type" "wmmx_wmax")]
 )
 
 (define_insn "*smin<mode>3_iwmmxt"
@@ -933,7 +930,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmins<MMX_char>%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmin")]
+   (set_attr "type" "wmmx_wmin")]
 )
 
 (define_insn "*umin<mode>3_iwmmxt"
@@ -943,7 +940,7 @@
   "TARGET_REALLY_IWMMXT"
   "wminu<MMX_char>%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmin")]
+   (set_attr "type" "wmmx_wmin")]
 )
 
 ;; Pack/unpack insns.
@@ -956,7 +953,7 @@
   "TARGET_REALLY_IWMMXT"
   "wpackhss%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wpack")]
+   (set_attr "type" "wmmx_wpack")]
 )
 
 (define_insn "iwmmxt_wpackwss"
@@ -967,7 +964,7 @@
   "TARGET_REALLY_IWMMXT"
   "wpackwss%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wpack")]
+   (set_attr "type" "wmmx_wpack")]
 )
 
 (define_insn "iwmmxt_wpackdss"
@@ -978,7 +975,7 @@
   "TARGET_REALLY_IWMMXT"
   "wpackdss%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wpack")]
+   (set_attr "type" "wmmx_wpack")]
 )
 
 (define_insn "iwmmxt_wpackhus"
@@ -989,7 +986,7 @@
   "TARGET_REALLY_IWMMXT"
   "wpackhus%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wpack")]
+   (set_attr "type" "wmmx_wpack")]
 )
 
 (define_insn "iwmmxt_wpackwus"
@@ -1000,7 +997,7 @@
   "TARGET_REALLY_IWMMXT"
   "wpackwus%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wpack")]
+   (set_attr "type" "wmmx_wpack")]
 )
 
 (define_insn "iwmmxt_wpackdus"
@@ -1011,7 +1008,7 @@
   "TARGET_REALLY_IWMMXT"
   "wpackdus%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wpack")]
+   (set_attr "type" "wmmx_wpack")]
 )
 
 (define_insn "iwmmxt_wunpckihb"
@@ -1039,7 +1036,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckihb%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckih")]
+   (set_attr "type" "wmmx_wunpckih")]
 )
 
 (define_insn "iwmmxt_wunpckihh"
@@ -1059,7 +1056,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckihh%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckih")]
+   (set_attr "type" "wmmx_wunpckih")]
 )
 
 (define_insn "iwmmxt_wunpckihw"
@@ -1075,7 +1072,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckihw%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckih")]
+   (set_attr "type" "wmmx_wunpckih")]
 )
 
 (define_insn "iwmmxt_wunpckilb"
@@ -1103,7 +1100,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckilb%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckil")]
+   (set_attr "type" "wmmx_wunpckil")]
 )
 
 (define_insn "iwmmxt_wunpckilh"
@@ -1123,7 +1120,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckilh%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckil")]
+   (set_attr "type" "wmmx_wunpckil")]
 )
 
 (define_insn "iwmmxt_wunpckilw"
@@ -1139,7 +1136,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckilw%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckil")]
+   (set_attr "type" "wmmx_wunpckil")]
 )
 
 (define_insn "iwmmxt_wunpckehub"
@@ -1151,7 +1148,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckehub%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckeh")]
+   (set_attr "type" "wmmx_wunpckeh")]
 )
 
 (define_insn "iwmmxt_wunpckehuh"
@@ -1162,7 +1159,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckehuh%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckeh")]
+   (set_attr "type" "wmmx_wunpckeh")]
 )
 
 (define_insn "iwmmxt_wunpckehuw"
@@ -1173,7 +1170,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckehuw%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckeh")]
+   (set_attr "type" "wmmx_wunpckeh")]
 )
 
 (define_insn "iwmmxt_wunpckehsb"
@@ -1185,7 +1182,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckehsb%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckeh")]
+   (set_attr "type" "wmmx_wunpckeh")]
 )
 
 (define_insn "iwmmxt_wunpckehsh"
@@ -1196,7 +1193,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckehsh%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckeh")]
+   (set_attr "type" "wmmx_wunpckeh")]
 )
 
 (define_insn "iwmmxt_wunpckehsw"
@@ -1207,7 +1204,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckehsw%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckeh")]
+   (set_attr "type" "wmmx_wunpckeh")]
 )
 
 (define_insn "iwmmxt_wunpckelub"
@@ -1219,7 +1216,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckelub%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckel")]
+   (set_attr "type" "wmmx_wunpckel")]
 )
 
 (define_insn "iwmmxt_wunpckeluh"
@@ -1230,7 +1227,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckeluh%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckel")]
+   (set_attr "type" "wmmx_wunpckel")]
 )
 
 (define_insn "iwmmxt_wunpckeluw"
@@ -1241,7 +1238,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckeluw%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckel")]
+   (set_attr "type" "wmmx_wunpckel")]
 )
 
 (define_insn "iwmmxt_wunpckelsb"
@@ -1253,7 +1250,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckelsb%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckel")]
+   (set_attr "type" "wmmx_wunpckel")]
 )
 
 (define_insn "iwmmxt_wunpckelsh"
@@ -1264,7 +1261,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckelsh%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckel")]
+   (set_attr "type" "wmmx_wunpckel")]
 )
 
 (define_insn "iwmmxt_wunpckelsw"
@@ -1275,7 +1272,7 @@
   "TARGET_REALLY_IWMMXT"
   "wunpckelsw%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wunpckel")]
+   (set_attr "type" "wmmx_wunpckel")]
 )
 
 ;; Shifts
@@ -1298,7 +1295,7 @@
   "
   [(set_attr "predicable" "yes")
    (set_attr "arch" "*, iwmmxt2")
-   (set_attr "wtype" "wror, wror")]
+   (set_attr "type" "wmmx_wror, wmmx_wror")]
 )
 
 (define_insn "ashr<mode>3_iwmmxt"
@@ -1319,7 +1316,7 @@
   "
   [(set_attr "predicable" "yes")
    (set_attr "arch" "*, iwmmxt2")
-   (set_attr "wtype" "wsra, wsra")]
+   (set_attr "type" "wmmx_wsra, wmmx_wsra")]
 )
 
 (define_insn "lshr<mode>3_iwmmxt"
@@ -1340,7 +1337,7 @@
   "
   [(set_attr "predicable" "yes")
    (set_attr "arch" "*, iwmmxt2")
-   (set_attr "wtype" "wsrl, wsrl")]
+   (set_attr "type" "wmmx_wsrl, wmmx_wsrl")]
 )
 
 (define_insn "ashl<mode>3_iwmmxt"
@@ -1361,7 +1358,7 @@
   "
   [(set_attr "predicable" "yes")
    (set_attr "arch" "*, iwmmxt2")
-   (set_attr "wtype" "wsll, wsll")]
+   (set_attr "type" "wmmx_wsll, wmmx_wsll")]
 )
 
 (define_insn "ror<mode>3_di"
@@ -1382,7 +1379,7 @@
   "
   [(set_attr "predicable" "yes")
    (set_attr "arch" "*, iwmmxt2")
-   (set_attr "wtype" "wror, wror")]
+   (set_attr "type" "wmmx_wror, wmmx_wror")]
 )
 
 (define_insn "ashr<mode>3_di"
@@ -1403,7 +1400,7 @@
   "
   [(set_attr "predicable" "yes")
    (set_attr "arch" "*, iwmmxt2")
-   (set_attr "wtype" "wsra, wsra")]
+   (set_attr "type" "wmmx_wsra, wmmx_wsra")]
 )
 
 (define_insn "lshr<mode>3_di"
@@ -1424,7 +1421,7 @@
   "
   [(set_attr "predicable" "yes")
    (set_attr "arch" "*, iwmmxt2")
-   (set_attr "wtype" "wsrl, wsrl")]
+   (set_attr "type" "wmmx_wsrl, wmmx_wsrl")]
 )
 
 (define_insn "ashl<mode>3_di"
@@ -1445,7 +1442,7 @@
   "
   [(set_attr "predicable" "yes")
    (set_attr "arch" "*, iwmmxt2")
-   (set_attr "wtype" "wsll, wsll")]
+   (set_attr "type" "wmmx_wsll, wmmx_wsll")]
 )
 
 (define_insn "iwmmxt_wmadds"
@@ -1464,7 +1461,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmadds%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmadd")]
+   (set_attr "type" "wmmx_wmadd")]
 )
 
 (define_insn "iwmmxt_wmaddu"
@@ -1483,7 +1480,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmaddu%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmadd")]
+   (set_attr "type" "wmmx_wmadd")]
 )
 
 (define_insn "iwmmxt_tmia"
@@ -1496,7 +1493,7 @@
   "TARGET_REALLY_IWMMXT"
   "tmia%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tmia")]
+   (set_attr "type" "wmmx_tmia")]
 )
 
 (define_insn "iwmmxt_tmiaph"
@@ -1514,7 +1511,7 @@
   "TARGET_REALLY_IWMMXT"
   "tmiaph%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tmiaph")]
+   (set_attr "type" "wmmx_tmiaph")]
 )
 
 (define_insn "iwmmxt_tmiabb"
@@ -1527,7 +1524,7 @@
   "TARGET_REALLY_IWMMXT"
   "tmiabb%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tmiaxy")]
+   (set_attr "type" "wmmx_tmiaxy")]
 )
 
 (define_insn "iwmmxt_tmiatb"
@@ -1544,7 +1541,7 @@
   "TARGET_REALLY_IWMMXT"
   "tmiatb%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tmiaxy")]
+   (set_attr "type" "wmmx_tmiaxy")]
 )
 
 (define_insn "iwmmxt_tmiabt"
@@ -1561,7 +1558,7 @@
   "TARGET_REALLY_IWMMXT"
   "tmiabt%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tmiaxy")]
+   (set_attr "type" "wmmx_tmiaxy")]
 )
 
 (define_insn "iwmmxt_tmiatt"
@@ -1580,7 +1577,7 @@
   "TARGET_REALLY_IWMMXT"
   "tmiatt%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tmiaxy")]
+   (set_attr "type" "wmmx_tmiaxy")]
 )
 
 (define_insn "iwmmxt_tmovmskb"
@@ -1589,7 +1586,7 @@
   "TARGET_REALLY_IWMMXT"
   "tmovmskb%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tmovmsk")]
+   (set_attr "type" "wmmx_tmovmsk")]
 )
 
 (define_insn "iwmmxt_tmovmskh"
@@ -1598,7 +1595,7 @@
   "TARGET_REALLY_IWMMXT"
   "tmovmskh%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tmovmsk")]
+   (set_attr "type" "wmmx_tmovmsk")]
 )
 
 (define_insn "iwmmxt_tmovmskw"
@@ -1607,7 +1604,7 @@
   "TARGET_REALLY_IWMMXT"
   "tmovmskw%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tmovmsk")]
+   (set_attr "type" "wmmx_tmovmsk")]
 )
 
 (define_insn "iwmmxt_waccb"
@@ -1616,7 +1613,7 @@
   "TARGET_REALLY_IWMMXT"
   "waccb%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wacc")]
+   (set_attr "type" "wmmx_wacc")]
 )
 
 (define_insn "iwmmxt_wacch"
@@ -1625,7 +1622,7 @@
   "TARGET_REALLY_IWMMXT"
   "wacch%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wacc")]
+   (set_attr "type" "wmmx_wacc")]
 )
 
 (define_insn "iwmmxt_waccw"
@@ -1634,7 +1631,7 @@
   "TARGET_REALLY_IWMMXT"
   "waccw%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wacc")]
+   (set_attr "type" "wmmx_wacc")]
 )
 
 ;; use unspec here to prevent 8 * imm to be optimized by cse
@@ -1651,7 +1648,7 @@
   "TARGET_REALLY_IWMMXT"
   "waligni%?\\t%0, %1, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "waligni")]
+   (set_attr "type" "wmmx_waligni")]
 )
 
 (define_insn "iwmmxt_walignr"
@@ -1666,7 +1663,7 @@
   "TARGET_REALLY_IWMMXT"
   "walignr%U3%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "walignr")]
+   (set_attr "type" "wmmx_walignr")]
 )
 
 (define_insn "iwmmxt_walignr0"
@@ -1681,7 +1678,7 @@
   "TARGET_REALLY_IWMMXT"
   "walignr0%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "walignr")]
+   (set_attr "type" "wmmx_walignr")]
 )
 
 (define_insn "iwmmxt_walignr1"
@@ -1696,7 +1693,7 @@
   "TARGET_REALLY_IWMMXT"
   "walignr1%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "walignr")]
+   (set_attr "type" "wmmx_walignr")]
 )
 
 (define_insn "iwmmxt_walignr2"
@@ -1711,7 +1708,7 @@
   "TARGET_REALLY_IWMMXT"
   "walignr2%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "walignr")]
+   (set_attr "type" "wmmx_walignr")]
 )
 
 (define_insn "iwmmxt_walignr3"
@@ -1726,7 +1723,7 @@
   "TARGET_REALLY_IWMMXT"
   "walignr3%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "walignr")]
+   (set_attr "type" "wmmx_walignr")]
 )
 
 (define_insn "iwmmxt_wsadb"
@@ -1738,7 +1735,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsadb%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsad")]
+   (set_attr "type" "wmmx_wsad")]
 )
 
 (define_insn "iwmmxt_wsadh"
@@ -1750,7 +1747,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsadh%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsad")]
+   (set_attr "type" "wmmx_wsad")]
 )
 
 (define_insn "iwmmxt_wsadbz"
@@ -1760,7 +1757,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsadbz%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsad")]
+   (set_attr "type" "wmmx_wsad")]
 )
 
 (define_insn "iwmmxt_wsadhz"
@@ -1770,7 +1767,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsadhz%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsad")]
+   (set_attr "type" "wmmx_wsad")]
 )
 
 (include "iwmmxt2.md")
diff --git a/gcc/config/arm/iwmmxt2.md b/gcc/config/arm/iwmmxt2.md
index 5e44658..27a45f9 100644
--- a/gcc/config/arm/iwmmxt2.md
+++ b/gcc/config/arm/iwmmxt2.md
@@ -24,7 +24,7 @@
   "TARGET_REALLY_IWMMXT"
   "wabs<MMX_char>%?\\t%0, %1"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wabs")]
+   (set_attr "type" "wmmx_wabs")]
 )
 
 (define_insn "iwmmxt_wabsdiffb"
@@ -37,7 +37,7 @@
  "TARGET_REALLY_IWMMXT"
  "wabsdiffb%?\\t%0, %1, %2"
  [(set_attr "predicable" "yes")
-  (set_attr "wtype" "wabsdiff")]
+  (set_attr "type" "wmmx_wabsdiff")]
 )
 
 (define_insn "iwmmxt_wabsdiffh"
@@ -50,7 +50,7 @@
   "TARGET_REALLY_IWMMXT"
   "wabsdiffh%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wabsdiff")]
+   (set_attr "type" "wmmx_wabsdiff")]
 )
 
 (define_insn "iwmmxt_wabsdiffw"
@@ -63,7 +63,7 @@
  "TARGET_REALLY_IWMMXT"
  "wabsdiffw%?\\t%0, %1, %2"
  [(set_attr "predicable" "yes")
-  (set_attr "wtype" "wabsdiff")]
+  (set_attr "type" "wmmx_wabsdiff")]
 )
 
 (define_insn "iwmmxt_waddsubhx"
@@ -81,7 +81,7 @@
   "TARGET_REALLY_IWMMXT"
   "waddsubhx%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "waddsubhx")]
+   (set_attr "type" "wmmx_waddsubhx")]
 )
 
 (define_insn "iwmmxt_wsubaddhx"
@@ -99,7 +99,7 @@
   "TARGET_REALLY_IWMMXT"
   "wsubaddhx%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wsubaddhx")]
+   (set_attr "type" "wmmx_wsubaddhx")]
 )
 
 (define_insn "addc<mode>3"
@@ -111,7 +111,7 @@
   "TARGET_REALLY_IWMMXT"
   "wadd<MMX_char>c%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wadd")]
+   (set_attr "type" "wmmx_wadd")]
 )
 
 (define_insn "iwmmxt_avg4"
@@ -143,7 +143,7 @@
   "TARGET_REALLY_IWMMXT"
   "wavg4%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wavg4")]
+   (set_attr "type" "wmmx_wavg4")]
 )
 
 (define_insn "iwmmxt_avg4r"
@@ -175,7 +175,7 @@
   "TARGET_REALLY_IWMMXT"
   "wavg4r%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wavg4")]
+   (set_attr "type" "wmmx_wavg4")]
 )
 
 (define_insn "iwmmxt_wmaddsx"
@@ -194,7 +194,7 @@
  "TARGET_REALLY_IWMMXT"
   "wmaddsx%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-	(set_attr "wtype" "wmadd")]
+	(set_attr "type" "wmmx_wmadd")]
 )
 
 (define_insn "iwmmxt_wmaddux"
@@ -213,7 +213,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmaddux%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmadd")]
+   (set_attr "type" "wmmx_wmadd")]
 )
 
 (define_insn "iwmmxt_wmaddsn"
@@ -232,7 +232,7 @@
  "TARGET_REALLY_IWMMXT"
  "wmaddsn%?\\t%0, %1, %2"
  [(set_attr "predicable" "yes")
-  (set_attr "wtype" "wmadd")]
+  (set_attr "type" "wmmx_wmadd")]
 )
 
 (define_insn "iwmmxt_wmaddun"
@@ -251,7 +251,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmaddun%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmadd")]
+   (set_attr "type" "wmmx_wmadd")]
 )
 
 (define_insn "iwmmxt_wmulwsm"
@@ -265,7 +265,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulwsm%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmulw")]
+   (set_attr "type" "wmmx_wmulw")]
 )
 
 (define_insn "iwmmxt_wmulwum"
@@ -279,7 +279,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulwum%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmulw")]
+   (set_attr "type" "wmmx_wmulw")]
 )
 
 (define_insn "iwmmxt_wmulsmr"
@@ -297,7 +297,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulsmr%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmul")]
+   (set_attr "type" "wmmx_wmul")]
 )
 
 (define_insn "iwmmxt_wmulumr"
@@ -316,7 +316,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulumr%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmul")]
+   (set_attr "type" "wmmx_wmul")]
 )
 
 (define_insn "iwmmxt_wmulwsmr"
@@ -333,7 +333,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulwsmr%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmul")]
+   (set_attr "type" "wmmx_wmul")]
 )
 
 (define_insn "iwmmxt_wmulwumr"
@@ -350,7 +350,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulwumr%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmulw")]
+   (set_attr "type" "wmmx_wmulw")]
 )
 
 (define_insn "iwmmxt_wmulwl"
@@ -361,7 +361,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmulwl%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmulw")]
+   (set_attr "type" "wmmx_wmulw")]
 )
 
 (define_insn "iwmmxt_wqmulm"
@@ -371,7 +371,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmulm%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmulm")]
+   (set_attr "type" "wmmx_wqmulm")]
 )
 
 (define_insn "iwmmxt_wqmulwm"
@@ -381,7 +381,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmulwm%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmulwm")]
+   (set_attr "type" "wmmx_wqmulwm")]
 )
 
 (define_insn "iwmmxt_wqmulmr"
@@ -391,7 +391,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmulmr%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmulm")]
+   (set_attr "type" "wmmx_wqmulm")]
 )
 
 (define_insn "iwmmxt_wqmulwmr"
@@ -401,7 +401,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmulwmr%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmulwm")]
+   (set_attr "type" "wmmx_wqmulwm")]
 )
 
 (define_insn "iwmmxt_waddbhusm"
@@ -417,7 +417,7 @@
   "TARGET_REALLY_IWMMXT"
   "waddbhusm%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "waddbhus")]
+   (set_attr "type" "wmmx_waddbhus")]
 )
 
 (define_insn "iwmmxt_waddbhusl"
@@ -433,7 +433,7 @@
   "TARGET_REALLY_IWMMXT"
   "waddbhusl%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "waddbhus")]
+   (set_attr "type" "wmmx_waddbhus")]
 )
 
 (define_insn "iwmmxt_wqmiabb"
@@ -446,7 +446,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmiabb%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmiaxy")]
+   (set_attr "type" "wmmx_wqmiaxy")]
 )
 
 (define_insn "iwmmxt_wqmiabt"
@@ -459,7 +459,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmiabt%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmiaxy")]
+   (set_attr "type" "wmmx_wqmiaxy")]
 )
 
 (define_insn "iwmmxt_wqmiatb"
@@ -472,7 +472,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmiatb%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmiaxy")]
+   (set_attr "type" "wmmx_wqmiaxy")]
 )
 
 (define_insn "iwmmxt_wqmiatt"
@@ -485,7 +485,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmiatt%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmiaxy")]
+   (set_attr "type" "wmmx_wqmiaxy")]
 )
 
 (define_insn "iwmmxt_wqmiabbn"
@@ -498,7 +498,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmiabbn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmiaxy")]
+   (set_attr "type" "wmmx_wqmiaxy")]
 )
 
 (define_insn "iwmmxt_wqmiabtn"
@@ -511,7 +511,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmiabtn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmiaxy")]
+   (set_attr "type" "wmmx_wqmiaxy")]
 )
 
 (define_insn "iwmmxt_wqmiatbn"
@@ -524,7 +524,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmiatbn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmiaxy")]
+   (set_attr "type" "wmmx_wqmiaxy")]
 )
 
 (define_insn "iwmmxt_wqmiattn"
@@ -537,7 +537,7 @@
   "TARGET_REALLY_IWMMXT"
   "wqmiattn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wqmiaxy")]
+   (set_attr "type" "wmmx_wqmiaxy")]
 )
 
 (define_insn "iwmmxt_wmiabb"
@@ -561,7 +561,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiabb%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiaxy")]
+   (set_attr "type" "wmmx_wmiaxy")]
 )
 
 (define_insn "iwmmxt_wmiabt"
@@ -585,7 +585,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiabt%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiaxy")]
+   (set_attr "type" "wmmx_wmiaxy")]
 )
 
 (define_insn "iwmmxt_wmiatb"
@@ -609,7 +609,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiatb%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiaxy")]
+   (set_attr "type" "wmmx_wmiaxy")]
 )
 
 (define_insn "iwmmxt_wmiatt"
@@ -633,7 +633,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiatt%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiaxy")]
+   (set_attr "type" "wmmx_wmiaxy")]
 )
 
 (define_insn "iwmmxt_wmiabbn"
@@ -657,7 +657,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiabbn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiaxy")]
+   (set_attr "type" "wmmx_wmiaxy")]
 )
 
 (define_insn "iwmmxt_wmiabtn"
@@ -681,7 +681,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiabtn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiaxy")]
+   (set_attr "type" "wmmx_wmiaxy")]
 )
 
 (define_insn "iwmmxt_wmiatbn"
@@ -705,7 +705,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiatbn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiaxy")]
+   (set_attr "type" "wmmx_wmiaxy")]
 )
 
 (define_insn "iwmmxt_wmiattn"
@@ -729,7 +729,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiattn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiaxy")]
+   (set_attr "type" "wmmx_wmiaxy")]
 )
 
 (define_insn "iwmmxt_wmiawbb"
@@ -742,7 +742,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiawbb%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiawxy")]
+   (set_attr "type" "wmmx_wmiawxy")]
 )
 
 (define_insn "iwmmxt_wmiawbt"
@@ -755,7 +755,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiawbt%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiawxy")]
+   (set_attr "type" "wmmx_wmiawxy")]
 )
 
 (define_insn "iwmmxt_wmiawtb"
@@ -768,7 +768,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiawtb%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiawxy")]
+   (set_attr "type" "wmmx_wmiawxy")]
 )
 
 (define_insn "iwmmxt_wmiawtt"
@@ -781,7 +781,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiawtt%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiawxy")]
+   (set_attr "type" "wmmx_wmiawxy")]
 )
 
 (define_insn "iwmmxt_wmiawbbn"
@@ -794,7 +794,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiawbbn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiawxy")]
+   (set_attr "type" "wmmx_wmiawxy")]
 )
 
 (define_insn "iwmmxt_wmiawbtn"
@@ -807,7 +807,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiawbtn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiawxy")]
+   (set_attr "type" "wmmx_wmiawxy")]
 )
 
 (define_insn "iwmmxt_wmiawtbn"
@@ -820,7 +820,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiawtbn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiawxy")]
+   (set_attr "type" "wmmx_wmiawxy")]
 )
 
 (define_insn "iwmmxt_wmiawttn"
@@ -833,7 +833,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmiawttn%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmiawxy")]
+   (set_attr "type" "wmmx_wmiawxy")]
 )
 
 (define_insn "iwmmxt_wmerge"
@@ -858,7 +858,7 @@
   "TARGET_REALLY_IWMMXT"
   "wmerge%?\\t%0, %1, %2, %3"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "wmerge")]
+   (set_attr "type" "wmmx_wmerge")]
 )
 
 (define_insn "iwmmxt_tandc<mode>3"
@@ -868,7 +868,7 @@
   "TARGET_REALLY_IWMMXT"
   "tandc<MMX_char>%?\\t r15"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "tandc")]
+   (set_attr "type" "wmmx_tandc")]
 )
 
 (define_insn "iwmmxt_torc<mode>3"
@@ -878,7 +878,7 @@
   "TARGET_REALLY_IWMMXT"
   "torc<MMX_char>%?\\t r15"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "torc")]
+   (set_attr "type" "wmmx_torc")]
 )
 
 (define_insn "iwmmxt_torvsc<mode>3"
@@ -888,7 +888,7 @@
   "TARGET_REALLY_IWMMXT"
   "torvsc<MMX_char>%?\\t r15"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "torvsc")]
+   (set_attr "type" "wmmx_torvsc")]
 )
 
 (define_insn "iwmmxt_textrc<mode>3"
@@ -899,5 +899,5 @@
   "TARGET_REALLY_IWMMXT"
   "textrc<MMX_char>%?\\t r15, %0"
   [(set_attr "predicable" "yes")
-   (set_attr "wtype" "textrc")]
+   (set_attr "type" "wmmx_textrc")]
 )
diff --git a/gcc/config/arm/ldmstm.md b/gcc/config/arm/ldmstm.md
index 8ebdfc8..ad137d4 100644
--- a/gcc/config/arm/ldmstm.md
+++ b/gcc/config/arm/ldmstm.md
@@ -37,7 +37,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 4"
   "ldm%(ia%)\t%5, {%1, %2, %3, %4}"
   [(set_attr "type" "load4")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb_ldm4_ia"
   [(match_parallel 0 "load_multiple_operation"
@@ -74,7 +75,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 5"
   "ldm%(ia%)\t%5!, {%1, %2, %3, %4}"
   [(set_attr "type" "load4")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb_ldm4_ia_update"
   [(match_parallel 0 "load_multiple_operation"
@@ -108,7 +110,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 4"
   "stm%(ia%)\t%5, {%1, %2, %3, %4}"
   [(set_attr "type" "store4")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*stm4_ia_update"
   [(match_parallel 0 "store_multiple_operation"
@@ -125,7 +128,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 5"
   "stm%(ia%)\t%5!, {%1, %2, %3, %4}"
   [(set_attr "type" "store4")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb_stm4_ia_update"
   [(match_parallel 0 "store_multiple_operation"
@@ -302,7 +306,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 4"
   "ldm%(db%)\t%5, {%1, %2, %3, %4}"
   [(set_attr "type" "load4")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*ldm4_db_update"
   [(match_parallel 0 "load_multiple_operation"
@@ -323,7 +328,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 5"
   "ldm%(db%)\t%5!, {%1, %2, %3, %4}"
   [(set_attr "type" "load4")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*stm4_db"
   [(match_parallel 0 "store_multiple_operation"
@@ -338,7 +344,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 4"
   "stm%(db%)\t%5, {%1, %2, %3, %4}"
   [(set_attr "type" "store4")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*stm4_db_update"
   [(match_parallel 0 "store_multiple_operation"
@@ -355,7 +362,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 5"
   "stm%(db%)\t%5!, {%1, %2, %3, %4}"
   [(set_attr "type" "store4")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_peephole2
   [(set (match_operand:SI 0 "s_register_operand" "")
@@ -477,7 +485,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 3"
   "ldm%(ia%)\t%4, {%1, %2, %3}"
   [(set_attr "type" "load3")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb_ldm3_ia"
   [(match_parallel 0 "load_multiple_operation"
@@ -508,7 +517,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 4"
   "ldm%(ia%)\t%4!, {%1, %2, %3}"
   [(set_attr "type" "load3")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb_ldm3_ia_update"
   [(match_parallel 0 "load_multiple_operation"
@@ -537,7 +547,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 3"
   "stm%(ia%)\t%4, {%1, %2, %3}"
   [(set_attr "type" "store3")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*stm3_ia_update"
   [(match_parallel 0 "store_multiple_operation"
@@ -552,7 +563,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 4"
   "stm%(ia%)\t%4!, {%1, %2, %3}"
   [(set_attr "type" "store3")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb_stm3_ia_update"
   [(match_parallel 0 "store_multiple_operation"
@@ -704,7 +716,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 3"
   "ldm%(db%)\t%4, {%1, %2, %3}"
   [(set_attr "type" "load3")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*ldm3_db_update"
   [(match_parallel 0 "load_multiple_operation"
@@ -722,7 +735,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 4"
   "ldm%(db%)\t%4!, {%1, %2, %3}"
   [(set_attr "type" "load3")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*stm3_db"
   [(match_parallel 0 "store_multiple_operation"
@@ -735,7 +749,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 3"
   "stm%(db%)\t%4, {%1, %2, %3}"
   [(set_attr "type" "store3")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*stm3_db_update"
   [(match_parallel 0 "store_multiple_operation"
@@ -750,7 +765,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 4"
   "stm%(db%)\t%4!, {%1, %2, %3}"
   [(set_attr "type" "store3")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_peephole2
   [(set (match_operand:SI 0 "s_register_operand" "")
@@ -855,7 +871,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 2"
   "ldm%(ia%)\t%3, {%1, %2}"
   [(set_attr "type" "load2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb_ldm2_ia"
   [(match_parallel 0 "load_multiple_operation"
@@ -880,7 +897,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 3"
   "ldm%(ia%)\t%3!, {%1, %2}"
   [(set_attr "type" "load2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb_ldm2_ia_update"
   [(match_parallel 0 "load_multiple_operation"
@@ -904,7 +922,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 2"
   "stm%(ia%)\t%3, {%1, %2}"
   [(set_attr "type" "store2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*stm2_ia_update"
   [(match_parallel 0 "store_multiple_operation"
@@ -917,7 +936,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 3"
   "stm%(ia%)\t%3!, {%1, %2}"
   [(set_attr "type" "store2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*thumb_stm2_ia_update"
   [(match_parallel 0 "store_multiple_operation"
@@ -1044,7 +1064,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 2"
   "ldm%(db%)\t%3, {%1, %2}"
   [(set_attr "type" "load2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*ldm2_db_update"
   [(match_parallel 0 "load_multiple_operation"
@@ -1059,7 +1080,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 3"
   "ldm%(db%)\t%3!, {%1, %2}"
   [(set_attr "type" "load2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*stm2_db"
   [(match_parallel 0 "store_multiple_operation"
@@ -1070,7 +1092,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 2"
   "stm%(db%)\t%3, {%1, %2}"
   [(set_attr "type" "store2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "*stm2_db_update"
   [(match_parallel 0 "store_multiple_operation"
@@ -1083,7 +1106,8 @@
   "TARGET_32BIT && XVECLEN (operands[0], 0) == 3"
   "stm%(db%)\t%3!, {%1, %2}"
   [(set_attr "type" "store2")
-   (set_attr "predicable" "yes")])
+   (set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_peephole2
   [(set (match_operand:SI 0 "s_register_operand" "")
diff --git a/gcc/config/arm/ldrdstrd.md b/gcc/config/arm/ldrdstrd.md
new file mode 100644
index 0000000..58c883e
--- /dev/null
+++ b/gcc/config/arm/ldrdstrd.md
@@ -0,0 +1,260 @@
+;; ARM ldrd/strd peephole optimizations.
+;;
+;; Copyright (C) 2013 Free Software Foundation, Inc.
+;;
+;; Written by Greta Yorsh <greta.yorsh@arm.com>
+
+;; This file is part of GCC.
+;;
+;; GCC is free software; you can redistribute it and/or modify it
+;; under the terms of the GNU General Public License as published by
+;; the Free Software Foundation; either version 3, or (at your option)
+;; any later version.
+;;
+;; GCC is distributed in the hope that it will be useful, but
+;; WITHOUT ANY WARRANTY; without even the implied warranty of
+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+;; General Public License for more details.
+;;
+;; You should have received a copy of the GNU General Public License
+;; along with GCC; see the file COPYING3.  If not see
+;; <http://www.gnu.org/licenses/>.
+
+;; The following peephole optimizations identify consecutive memory
+;; accesses, and try to rearrange the operands to enable generation of
+;; ldrd/strd.
+
+(define_peephole2 ; ldrd
+  [(set (match_operand:SI 0 "arm_general_register_operand" "")
+        (match_operand:SI 2 "memory_operand" ""))
+   (set (match_operand:SI 1 "arm_general_register_operand" "")
+        (match_operand:SI 3 "memory_operand" ""))]
+  "TARGET_LDRD
+     && current_tune->prefer_ldrd_strd
+     && !optimize_function_for_size_p (cfun)"
+  [(const_int 0)]
+{
+  if (!gen_operands_ldrd_strd (operands, true, false, false))
+    FAIL;
+  else if (TARGET_ARM)
+  {
+    /* In ARM state, the destination registers of LDRD/STRD must be
+       consecutive. We emit DImode access.  */
+    operands[0] = gen_rtx_REG (DImode, REGNO (operands[0]));
+    operands[2] = adjust_address (operands[2], DImode, 0);
+    /* Emit [(set (match_dup 0) (match_dup 2))] */
+    emit_insn (gen_rtx_SET (VOIDmode, operands[0], operands[2]));
+    DONE;
+  }
+  else if (TARGET_THUMB2)
+  {
+    /* Emit the pattern:
+       [(parallel [(set (match_dup 0) (match_dup 2))
+                   (set (match_dup 1) (match_dup 3))])] */
+    rtx t1 = gen_rtx_SET (VOIDmode, operands[0], operands[2]);
+    rtx t2 = gen_rtx_SET (VOIDmode, operands[1], operands[3]);
+    emit_insn (gen_rtx_PARALLEL (VOIDmode, gen_rtvec (2, t1, t2)));
+    DONE;
+  }
+})
+
+(define_peephole2 ; strd
+  [(set (match_operand:SI 2 "memory_operand" "")
+	(match_operand:SI 0 "arm_general_register_operand" ""))
+   (set (match_operand:SI 3 "memory_operand" "")
+	(match_operand:SI 1 "arm_general_register_operand" ""))]
+  "TARGET_LDRD
+     && current_tune->prefer_ldrd_strd
+     && !optimize_function_for_size_p (cfun)"
+  [(const_int 0)]
+{
+  if (!gen_operands_ldrd_strd (operands, false, false, false))
+    FAIL;
+  else if (TARGET_ARM)
+  {
+    /* In ARM state, the destination registers of LDRD/STRD must be
+       consecutive. We emit DImode access.  */
+    operands[0] = gen_rtx_REG (DImode, REGNO (operands[0]));
+    operands[2] = adjust_address (operands[2], DImode, 0);
+    /* Emit [(set (match_dup 2) (match_dup 0))]  */
+    emit_insn (gen_rtx_SET (VOIDmode, operands[2], operands[0]));
+    DONE;
+  }
+  else if (TARGET_THUMB2)
+  {
+    /* Emit the pattern:
+       [(parallel [(set (match_dup 2) (match_dup 0))
+                   (set (match_dup 3) (match_dup 1))])]  */
+    rtx t1 = gen_rtx_SET (VOIDmode, operands[2], operands[0]);
+    rtx t2 = gen_rtx_SET (VOIDmode, operands[3], operands[1]);
+    emit_insn (gen_rtx_PARALLEL (VOIDmode, gen_rtvec (2, t1, t2)));
+    DONE;
+  }
+})
+
+;; The following peepholes reorder registers to enable LDRD/STRD.
+(define_peephole2 ; strd of constants
+  [(set (match_operand:SI 0 "arm_general_register_operand" "")
+        (match_operand:SI 4 "const_int_operand" ""))
+   (set (match_operand:SI 2 "memory_operand" "")
+        (match_dup 0))
+   (set (match_operand:SI 1 "arm_general_register_operand" "")
+        (match_operand:SI 5 "const_int_operand" ""))
+   (set (match_operand:SI 3 "memory_operand" "")
+        (match_dup 1))]
+ "TARGET_LDRD
+  && current_tune->prefer_ldrd_strd
+  && !optimize_function_for_size_p (cfun)"
+  [(const_int 0)]
+{
+  if (!gen_operands_ldrd_strd (operands, false, true, false))
+    FAIL;
+  else if (TARGET_ARM)
+  {
+   rtx tmp = gen_rtx_REG (DImode, REGNO (operands[0]));
+   operands[2] = adjust_address (operands[2], DImode, 0);
+   /* Emit the pattern:
+      [(set (match_dup 0) (match_dup 4))
+      (set (match_dup 1) (match_dup 5))
+      (set (match_dup 2) tmp)]  */
+   emit_insn (gen_rtx_SET (VOIDmode, operands[0], operands[4]));
+   emit_insn (gen_rtx_SET (VOIDmode, operands[1], operands[5]));
+   emit_insn (gen_rtx_SET (VOIDmode, operands[2], tmp));
+   DONE;
+  }
+  else if (TARGET_THUMB2)
+  {
+    /* Emit the pattern:
+       [(set (match_dup 0) (match_dup 4))
+        (set (match_dup 1) (match_dup 5))
+        (parallel [(set (match_dup 2) (match_dup 0))
+                   (set (match_dup 3) (match_dup 1))])]  */
+    emit_insn (gen_rtx_SET (VOIDmode, operands[0], operands[4]));
+    emit_insn (gen_rtx_SET (VOIDmode, operands[1], operands[5]));
+    rtx t1 = gen_rtx_SET (VOIDmode, operands[2], operands[0]);
+    rtx t2 = gen_rtx_SET (VOIDmode, operands[3], operands[1]);
+    emit_insn (gen_rtx_PARALLEL (VOIDmode, gen_rtvec (2, t1, t2)));
+    DONE;
+  }
+})
+
+(define_peephole2 ; strd of constants
+  [(set (match_operand:SI 0 "arm_general_register_operand" "")
+        (match_operand:SI 4 "const_int_operand" ""))
+   (set (match_operand:SI 1 "arm_general_register_operand" "")
+        (match_operand:SI 5 "const_int_operand" ""))
+   (set (match_operand:SI 2 "memory_operand" "")
+        (match_dup 0))
+   (set (match_operand:SI 3 "memory_operand" "")
+        (match_dup 1))]
+ "TARGET_LDRD
+  && current_tune->prefer_ldrd_strd
+  && !optimize_function_for_size_p (cfun)"
+   [(const_int 0)]
+{
+  if (!gen_operands_ldrd_strd (operands, false, true, false))
+     FAIL;
+  else if (TARGET_ARM)
+  {
+   rtx tmp = gen_rtx_REG (DImode, REGNO (operands[0]));
+   operands[2] = adjust_address (operands[2], DImode, 0);
+   /* Emit the pattern
+      [(set (match_dup 0) (match_dup 4))
+       (set (match_dup 1) (match_dup 5))
+       (set (match_dup 2) tmp)]  */
+   emit_insn (gen_rtx_SET (VOIDmode, operands[0], operands[4]));
+   emit_insn (gen_rtx_SET (VOIDmode, operands[1], operands[5]));
+   emit_insn (gen_rtx_SET (VOIDmode, operands[2], tmp));
+   DONE;
+  }
+  else if (TARGET_THUMB2)
+  {
+    /*  Emit the pattern:
+        [(set (match_dup 0) (match_dup 4))
+         (set (match_dup 1) (match_dup 5))
+         (parallel [(set (match_dup 2) (match_dup 0))
+                    (set (match_dup 3) (match_dup 1))])]  */
+    emit_insn (gen_rtx_SET (VOIDmode, operands[0], operands[4]));
+    emit_insn (gen_rtx_SET (VOIDmode, operands[1], operands[5]));
+    rtx t1 = gen_rtx_SET (VOIDmode, operands[2], operands[0]);
+    rtx t2 = gen_rtx_SET (VOIDmode, operands[3], operands[1]);
+    emit_insn (gen_rtx_PARALLEL (VOIDmode, gen_rtvec (2, t1, t2)));
+    DONE;
+  }
+})
+
+;; The following two peephole optimizations are only relevant for ARM
+;; mode where LDRD/STRD require consecutive registers.
+
+(define_peephole2 ; swap the destination registers of two loads
+		  ; before a commutative operation.
+  [(set (match_operand:SI 0 "arm_general_register_operand" "")
+        (match_operand:SI 2 "memory_operand" ""))
+   (set (match_operand:SI 1 "arm_general_register_operand" "")
+        (match_operand:SI 3 "memory_operand" ""))
+   (set (match_operand:SI 4 "arm_general_register_operand" "")
+        (match_operator:SI 5 "commutative_binary_operator"
+			   [(match_operand 6 "arm_general_register_operand" "")
+			    (match_operand 7 "arm_general_register_operand" "") ]))]
+  "TARGET_LDRD && TARGET_ARM
+   && current_tune->prefer_ldrd_strd
+   && !optimize_function_for_size_p (cfun)
+   && (  ((rtx_equal_p(operands[0], operands[6])) && (rtx_equal_p(operands[1], operands[7])))
+        ||((rtx_equal_p(operands[0], operands[7])) && (rtx_equal_p(operands[1], operands[6]))))
+   && (peep2_reg_dead_p (3, operands[0]) || rtx_equal_p (operands[0], operands[4]))
+   && (peep2_reg_dead_p (3, operands[1]) || rtx_equal_p (operands[1], operands[4]))"
+  [(set (match_dup 0) (match_dup 2))
+   (set (match_dup 4) (match_op_dup 5 [(match_dup 6) (match_dup 7)]))]
+  {
+    if (!gen_operands_ldrd_strd (operands, true, false, true))
+     {
+        FAIL;
+     }
+    else
+     {
+        operands[0] = gen_rtx_REG (DImode, REGNO (operands[0]));
+        operands[2] = adjust_address (operands[2], DImode, 0);
+     }
+   }
+)
+
+(define_peephole2 ; swap the destination registers of two loads
+		  ; before a commutative operation that sets the flags.
+  [(set (match_operand:SI 0 "arm_general_register_operand" "")
+        (match_operand:SI 2 "memory_operand" ""))
+   (set (match_operand:SI 1 "arm_general_register_operand" "")
+        (match_operand:SI 3 "memory_operand" ""))
+   (parallel
+      [(set (match_operand:SI 4 "arm_general_register_operand" "")
+	    (match_operator:SI 5 "commutative_binary_operator"
+			       [(match_operand 6 "arm_general_register_operand" "")
+				(match_operand 7 "arm_general_register_operand" "") ]))
+       (clobber (reg:CC CC_REGNUM))])]
+  "TARGET_LDRD && TARGET_ARM
+   && current_tune->prefer_ldrd_strd
+   && !optimize_function_for_size_p (cfun)
+   && (  ((rtx_equal_p(operands[0], operands[6])) && (rtx_equal_p(operands[1], operands[7])))
+       ||((rtx_equal_p(operands[0], operands[7])) && (rtx_equal_p(operands[1], operands[6]))))
+   && (peep2_reg_dead_p (3, operands[0]) || rtx_equal_p (operands[0], operands[4]))
+   && (peep2_reg_dead_p (3, operands[1]) || rtx_equal_p (operands[1], operands[4]))"
+  [(set (match_dup 0) (match_dup 2))
+   (parallel
+      [(set (match_dup 4)
+	    (match_op_dup 5 [(match_dup 6) (match_dup 7)]))
+       (clobber (reg:CC CC_REGNUM))])]
+  {
+    if (!gen_operands_ldrd_strd (operands, true, false, true))
+     {
+        FAIL;
+     }
+    else
+     {
+        operands[0] = gen_rtx_REG (DImode, REGNO (operands[0]));
+        operands[2] = adjust_address (operands[2], DImode, 0);
+     }
+   }
+)
+
+;; TODO: Handle LDRD/STRD with writeback:
+;; (a) memory operands can be POST_INC, POST_DEC, PRE_MODIFY, POST_MODIFY
+;; (b) Patterns may be followed by an update of the base address.
diff --git a/gcc/config/arm/linux-eabi.h b/gcc/config/arm/linux-eabi.h
index 4a425c8..6bf7dbd 100644
--- a/gcc/config/arm/linux-eabi.h
+++ b/gcc/config/arm/linux-eabi.h
@@ -80,22 +80,31 @@
 /* At this point, bpabi.h will have clobbered LINK_SPEC.  We want to
    use the GNU/Linux version, not the generic BPABI version.  */
 #undef  LINK_SPEC
-#define LINK_SPEC BE8_LINK_SPEC						\
+#define LINK_SPEC EABI_LINK_SPEC					\
   LINUX_OR_ANDROID_LD (LINUX_TARGET_LINK_SPEC,				\
 		       LINUX_TARGET_LINK_SPEC " " ANDROID_LINK_SPEC)
 
+#undef  ASAN_CC1_SPEC
+#define ASAN_CC1_SPEC "%{fsanitize=*:-funwind-tables}"
+
 #undef  CC1_SPEC
 #define CC1_SPEC							\
-  LINUX_OR_ANDROID_CC (GNU_USER_TARGET_CC1_SPEC,			\
-		       GNU_USER_TARGET_CC1_SPEC " " ANDROID_CC1_SPEC)
+  LINUX_OR_ANDROID_CC (GNU_USER_TARGET_CC1_SPEC " " ASAN_CC1_SPEC,	\
+		       GNU_USER_TARGET_CC1_SPEC " " ASAN_CC1_SPEC ("-fpic")	\
+		       ANDROID_CC1_SPEC)
 
 #define CC1PLUS_SPEC \
   LINUX_OR_ANDROID_CC ("", ANDROID_CC1PLUS_SPEC)
 
+#undef ASM_SPEC
+#define ASM_SPEC \
+  LINUX_OR_ANDROID_CC (DEFAULT_ASM_SPEC, \
+                       DEFAULT_ASM_SPEC  " " ANDROID_ASM_SPEC)
+
 #undef  LIB_SPEC
 #define LIB_SPEC							\
   LINUX_OR_ANDROID_LD (GNU_USER_TARGET_LIB_SPEC,			\
-		       GNU_USER_TARGET_LIB_SPEC " " ANDROID_LIB_SPEC)
+		       GNU_USER_TARGET_LIB_SPEC_LESS_PTHREAD " " ANDROID_LIB_SPEC)
 
 #undef	STARTFILE_SPEC
 #define STARTFILE_SPEC \
diff --git a/gcc/config/arm/marvell-f-iwmmxt.md b/gcc/config/arm/marvell-f-iwmmxt.md
index 5781776..395549f 100644
--- a/gcc/config/arm/marvell-f-iwmmxt.md
+++ b/gcc/config/arm/marvell-f-iwmmxt.md
@@ -63,52 +63,62 @@
 ;; An attribute appended to instructions for classification
 
 (define_attr "wmmxt_shift" "yes,no"
-  (if_then_else (eq_attr "wtype" "wror, wsll, wsra, wsrl")
+  (if_then_else (eq_attr "type" "wmmx_wror, wmmx_wsll, wmmx_wsra, wmmx_wsrl")
 		(const_string "yes") (const_string "no"))
 )
 
 (define_attr "wmmxt_pack" "yes,no"
-  (if_then_else (eq_attr "wtype" "waligni, walignr, wmerge, wpack, wshufh, wunpckeh, wunpckih, wunpckel, wunpckil")
+  (if_then_else (eq_attr "type" "wmmx_waligni, wmmx_walignr, wmmx_wmerge,\
+                                 wmmx_wpack, wmmx_wshufh, wmmx_wunpckeh,\
+                                 wmmx_wunpckih, wmmx_wunpckel, wmmx_wunpckil")
 		(const_string "yes") (const_string "no"))
 )
 
 (define_attr "wmmxt_mult_c1" "yes,no"
-  (if_then_else (eq_attr "wtype" "wmac, wmadd, wmiaxy, wmiawxy, wmulw, wqmiaxy, wqmulwm")
+  (if_then_else (eq_attr "type" "wmmx_wmac, wmmx_wmadd, wmmx_wmiaxy,\
+                                 wmmx_wmiawxy, wmmx_wmulw, wmmx_wqmiaxy,\
+                                 wmmx_wqmulwm")
 		(const_string "yes") (const_string "no"))
 )
 
 (define_attr "wmmxt_mult_c2" "yes,no"
-  (if_then_else (eq_attr "wtype" "wmul, wqmulm")
+  (if_then_else (eq_attr "type" "wmmx_wmul, wmmx_wqmulm")
 		(const_string "yes") (const_string "no"))
 )
 
 (define_attr "wmmxt_alu_c1" "yes,no"
-  (if_then_else (eq_attr "wtype" "wabs, wabsdiff, wand, wandn, wmov, wor, wxor")
+  (if_then_else (eq_attr "type" "wmmx_wabs, wmmx_wabsdiff, wmmx_wand,\
+                                 wmmx_wandn, wmmx_wmov, wmmx_wor, wmmx_wxor")
 	        (const_string "yes") (const_string "no"))
 )
 
 (define_attr "wmmxt_alu_c2" "yes,no"
-  (if_then_else (eq_attr "wtype" "wacc, wadd, waddsubhx, wavg2, wavg4, wcmpeq, wcmpgt, wmax, wmin, wsub, waddbhus, wsubaddhx")
+  (if_then_else (eq_attr "type" "wmmx_wacc, wmmx_wadd, wmmx_waddsubhx,\
+                                 wmmx_wavg2, wmmx_wavg4, wmmx_wcmpeq,\
+                                 wmmx_wcmpgt, wmmx_wmax, wmmx_wmin,\
+                                 wmmx_wsub, wmmx_waddbhus, wmmx_wsubaddhx")
 		(const_string "yes") (const_string "no"))
 )
 
 (define_attr "wmmxt_alu_c3" "yes,no"
-  (if_then_else (eq_attr "wtype" "wsad")
+  (if_then_else (eq_attr "type" "wmmx_wsad")
 	        (const_string "yes") (const_string "no"))
 )
 
 (define_attr "wmmxt_transfer_c1" "yes,no"
-  (if_then_else (eq_attr "wtype" "tbcst, tinsr, tmcr, tmcrr")
+  (if_then_else (eq_attr "type" "wmmx_tbcst, wmmx_tinsr,\
+                                 wmmx_tmcr, wmmx_tmcrr")
                 (const_string "yes") (const_string "no"))
 )
 
 (define_attr "wmmxt_transfer_c2" "yes,no"
-  (if_then_else (eq_attr "wtype" "textrm, tmovmsk, tmrc, tmrrc")
+  (if_then_else (eq_attr "type" "wmmx_textrm, wmmx_tmovmsk,\
+                                 wmmx_tmrc, wmmx_tmrrc")
 	        (const_string "yes") (const_string "no"))
 )
 
 (define_attr "wmmxt_transfer_c3" "yes,no"
-  (if_then_else (eq_attr "wtype" "tmia, tmiaph, tmiaxy")
+  (if_then_else (eq_attr "type" "wmmx_tmia, wmmx_tmiaph, wmmx_tmiaxy")
 	        (const_string "yes") (const_string "no"))
 )
 
@@ -169,11 +179,11 @@
 
 (define_insn_reservation "marvell_f_iwmmxt_wstr" 0
   (and (eq_attr "marvell_f_iwmmxt" "yes")
-       (eq_attr "wtype" "wstr"))
+       (eq_attr "type" "wmmx_wstr"))
   "mf_iwmmxt_pipeline")
 
 ;There is a forwarding path from MW stage
 (define_insn_reservation "marvell_f_iwmmxt_wldr" 5
   (and (eq_attr "marvell_f_iwmmxt" "yes")
-       (eq_attr "wtype" "wldr"))
+       (eq_attr "type" "wmmx_wldr"))
   "mf_iwmmxt_pipeline")
diff --git a/gcc/config/arm/marvell-pj4.md b/gcc/config/arm/marvell-pj4.md
index 39f4c58..4004fa5 100644
--- a/gcc/config/arm/marvell-pj4.md
+++ b/gcc/config/arm/marvell-pj4.md
@@ -95,10 +95,14 @@
                  "pj4_ir_mul,pj4_ir_div,pj4_core_to_vfp")
 
 (define_insn_reservation "pj4_ir_mul" 3
-  (and (eq_attr "tune" "marvell_pj4") (eq_attr "type" "mult")) "pj4_is,pj4_mul,nothing*2,pj4_cp")
+  (and (eq_attr "tune" "marvell_pj4")
+       (ior (eq_attr "mul32" "yes")
+            (eq_attr "mul64" "yes")))
+                     "pj4_is,pj4_mul,nothing*2,pj4_cp")
 
 (define_insn_reservation "pj4_ir_div" 20
-  (and (eq_attr "tune" "marvell_pj4") (eq_attr "insn" "udiv,sdiv")) "pj4_is,pj4_div*19,pj4_cp")
+  (and (eq_attr "tune" "marvell_pj4") 
+       (eq_attr "type" "udiv,sdiv")) "pj4_is,pj4_div*19,pj4_cp")
 
 ;; Branches and calls.
 
diff --git a/gcc/config/arm/neon.md b/gcc/config/arm/neon.md
index 99fb5e8..fd3a505 100644
--- a/gcc/config/arm/neon.md
+++ b/gcc/config/arm/neon.md
@@ -241,8 +241,8 @@
 })
 
 (define_expand "movmisalign<mode>"
-  [(set (match_operand:VDQX 0 "neon_struct_or_register_operand")
-	(unspec:VDQX [(match_operand:VDQX 1 "neon_struct_or_register_operand")]
+  [(set (match_operand:VDQX 0 "neon_perm_struct_or_reg_operand")
+	(unspec:VDQX [(match_operand:VDQX 1 "neon_perm_struct_or_reg_operand")]
 		     UNSPEC_MISALIGNED_ACCESS))]
   "TARGET_NEON && !BYTES_BIG_ENDIAN"
 {
@@ -255,7 +255,7 @@
 })
 
 (define_insn "*movmisalign<mode>_neon_store"
-  [(set (match_operand:VDX 0 "neon_struct_operand"	       "=Um")
+  [(set (match_operand:VDX 0 "neon_permissive_struct_operand"	"=Um")
 	(unspec:VDX [(match_operand:VDX 1 "s_register_operand" " w")]
 		    UNSPEC_MISALIGNED_ACCESS))]
   "TARGET_NEON && !BYTES_BIG_ENDIAN"
@@ -263,15 +263,16 @@
   [(set_attr "neon_type" "neon_vst1_1_2_regs_vst2_2_regs")])
 
 (define_insn "*movmisalign<mode>_neon_load"
-  [(set (match_operand:VDX 0 "s_register_operand"		"=w")
-	(unspec:VDX [(match_operand:VDX 1 "neon_struct_operand" " Um")]
+  [(set (match_operand:VDX 0 "s_register_operand"			"=w")
+	(unspec:VDX [(match_operand:VDX 1 "neon_permissive_struct_operand"
+									" Um")]
 		    UNSPEC_MISALIGNED_ACCESS))]
   "TARGET_NEON && !BYTES_BIG_ENDIAN"
   "vld1.<V_sz_elem>\t{%P0}, %A1"
   [(set_attr "neon_type" "neon_vld1_1_2_regs")])
 
 (define_insn "*movmisalign<mode>_neon_store"
-  [(set (match_operand:VQX 0 "neon_struct_operand"	       "=Um")
+  [(set (match_operand:VQX 0 "neon_permissive_struct_operand"  "=Um")
 	(unspec:VQX [(match_operand:VQX 1 "s_register_operand" " w")]
 		    UNSPEC_MISALIGNED_ACCESS))]
   "TARGET_NEON && !BYTES_BIG_ENDIAN"
@@ -279,8 +280,9 @@
   [(set_attr "neon_type" "neon_vst1_1_2_regs_vst2_2_regs")])
 
 (define_insn "*movmisalign<mode>_neon_load"
-  [(set (match_operand:VQX 0 "s_register_operand"	         "=w")
-	(unspec:VQX [(match_operand:VQX 1 "neon_struct_operand" " Um")]
+  [(set (match_operand:VQX 0 "s_register_operand"			"=w")
+	(unspec:VQX [(match_operand:VQX 1 "neon_permissive_struct_operand"
+									" Um")]
 		    UNSPEC_MISALIGNED_ACCESS))]
   "TARGET_NEON && !BYTES_BIG_ENDIAN"
   "vld1.<V_sz_elem>\t{%q0}, %A1"
@@ -487,7 +489,7 @@
   [(set_attr "neon_type" "neon_int_1,*,*,neon_int_1,*,*,*")
    (set_attr "conds" "*,clob,clob,*,clob,clob,clob")
    (set_attr "length" "*,8,8,*,8,8,8")
-   (set_attr "arch" "nota8,*,*,onlya8,*,*,*")]
+   (set_attr "arch" "neon_for_64bits,*,*,avoid_neon_for_64bits,*,*,*")]
 )
 
 (define_insn "*sub<mode>3_neon"
@@ -524,7 +526,7 @@
   [(set_attr "neon_type" "neon_int_2,*,*,*,neon_int_2")
    (set_attr "conds" "*,clob,clob,clob,*")
    (set_attr "length" "*,8,8,8,*")
-   (set_attr "arch" "nota8,*,*,*,onlya8")]
+   (set_attr "arch" "neon_for_64bits,*,*,*,avoid_neon_for_64bits")]
 )
 
 (define_insn "*mul<mode>3_neon"
@@ -679,29 +681,6 @@
   [(set_attr "neon_type" "neon_int_1")]
 )
 
-(define_insn "iordi3_neon"
-  [(set (match_operand:DI 0 "s_register_operand" "=w,w,?&r,?&r,?w,?w")
-        (ior:DI (match_operand:DI 1 "s_register_operand" "%w,0,0,r,w,0")
-		(match_operand:DI 2 "neon_logic_op2" "w,Dl,r,r,w,Dl")))]
-  "TARGET_NEON"
-{
-  switch (which_alternative)
-    {
-    case 0: /* fall through */
-    case 4: return "vorr\t%P0, %P1, %P2";
-    case 1: /* fall through */
-    case 5: return neon_output_logic_immediate ("vorr", &operands[2],
-		     DImode, 0, VALID_NEON_QREG_MODE (DImode));
-    case 2: return "#";
-    case 3: return "#";
-    default: gcc_unreachable ();
-    }
-}
-  [(set_attr "neon_type" "neon_int_1,neon_int_1,*,*,neon_int_1,neon_int_1")
-   (set_attr "length" "*,*,8,8,*,*")
-   (set_attr "arch" "nota8,nota8,*,*,onlya8,onlya8")]
-)
-
 ;; The concrete forms of the Neon immediate-logic instructions are vbic and
 ;; vorr. We support the pseudo-instruction vand instead, because that
 ;; corresponds to the canonical form the middle-end expects to use for
@@ -724,29 +703,6 @@
   [(set_attr "neon_type" "neon_int_1")]
 )
 
-(define_insn "anddi3_neon"
-  [(set (match_operand:DI 0 "s_register_operand" "=w,w,?&r,?&r,?w,?w")
-        (and:DI (match_operand:DI 1 "s_register_operand" "%w,0,0,r,w,0")
-		(match_operand:DI 2 "neon_inv_logic_op2" "w,DL,r,r,w,DL")))]
-  "TARGET_NEON"
-{
-  switch (which_alternative)
-    {
-    case 0: /* fall through */
-    case 4: return "vand\t%P0, %P1, %P2";
-    case 1: /* fall through */
-    case 5: return neon_output_logic_immediate ("vand", &operands[2],
-    		     DImode, 1, VALID_NEON_QREG_MODE (DImode));
-    case 2: return "#";
-    case 3: return "#";
-    default: gcc_unreachable ();
-    }
-}
-  [(set_attr "neon_type" "neon_int_1,neon_int_1,*,*,neon_int_1,neon_int_1")
-   (set_attr "length" "*,*,8,8,*,*")
-   (set_attr "arch" "nota8,nota8,*,*,onlya8,onlya8")]
-)
-
 (define_insn "orn<mode>3_neon"
   [(set (match_operand:VDQ 0 "s_register_operand" "=w")
 	(ior:VDQ (not:VDQ (match_operand:VDQ 2 "s_register_operand" "w"))
@@ -828,21 +784,6 @@
   [(set_attr "neon_type" "neon_int_1")]
 )
 
-(define_insn "xordi3_neon"
-  [(set (match_operand:DI 0 "s_register_operand" "=w,?&r,?&r,?w")
-        (xor:DI (match_operand:DI 1 "s_register_operand" "%w,0,r,w")
-	        (match_operand:DI 2 "s_register_operand" "w,r,r,w")))]
-  "TARGET_NEON"
-  "@
-   veor\t%P0, %P1, %P2
-   #
-   #
-   veor\t%P0, %P1, %P2"
-  [(set_attr "neon_type" "neon_int_1,*,*,neon_int_1")
-   (set_attr "length" "*,8,8,*")
-   (set_attr "arch" "nota8,*,*,onlya8")]
-)
-
 (define_insn "one_cmpl<mode>2"
   [(set (match_operand:VDQ 0 "s_register_operand" "=w")
         (not:VDQ (match_operand:VDQ 1 "s_register_operand" "w")))]
@@ -1162,7 +1103,7 @@
       }
     DONE;
   }"
-  [(set_attr "arch" "nota8,nota8,*,*,onlya8,onlya8")
+  [(set_attr "arch" "neon_for_64bits,neon_for_64bits,*,*,avoid_neon_for_64bits,avoid_neon_for_64bits")
    (set_attr "opt" "*,*,speed,speed,*,*")]
 )
 
@@ -1263,7 +1204,7 @@
 
     DONE;
   }"
-  [(set_attr "arch" "nota8,nota8,*,*,onlya8,onlya8")
+  [(set_attr "arch" "neon_for_64bits,neon_for_64bits,*,*,avoid_neon_for_64bits,avoid_neon_for_64bits")
    (set_attr "opt" "*,*,speed,speed,*,*")]
 )
 
@@ -5611,7 +5552,7 @@
    (match_operand:SI 3 "immediate_operand" "")]
   "TARGET_NEON"
 {
-  emit_insn (gen_and<mode>3<V_suf64> (operands[0], operands[1], operands[2]));
+  emit_insn (gen_and<mode>3 (operands[0], operands[1], operands[2]));
   DONE;
 })
 
@@ -5622,7 +5563,7 @@
    (match_operand:SI 3 "immediate_operand" "")]
   "TARGET_NEON"
 {
-  emit_insn (gen_ior<mode>3<V_suf64> (operands[0], operands[1], operands[2]));
+  emit_insn (gen_ior<mode>3 (operands[0], operands[1], operands[2]));
   DONE;
 })
 
@@ -5633,7 +5574,7 @@
    (match_operand:SI 3 "immediate_operand" "")]
   "TARGET_NEON"
 {
-  emit_insn (gen_xor<mode>3<V_suf64> (operands[0], operands[1], operands[2]));
+  emit_insn (gen_xor<mode>3 (operands[0], operands[1], operands[2]));
   DONE;
 })
 
diff --git a/gcc/config/arm/predicates.md b/gcc/config/arm/predicates.md
index f493d82..f4a4515 100644
--- a/gcc/config/arm/predicates.md
+++ b/gcc/config/arm/predicates.md
@@ -31,6 +31,28 @@
 	      || REGNO_REG_CLASS (REGNO (op)) != NO_REGS));
 })
 
+(define_predicate "imm_for_neon_inv_logic_operand"
+  (match_code "const_vector")
+{
+  return (TARGET_NEON
+          && neon_immediate_valid_for_logic (op, mode, 1, NULL, NULL));
+})
+
+(define_predicate "neon_inv_logic_op2"
+  (ior (match_operand 0 "imm_for_neon_inv_logic_operand")
+       (match_operand 0 "s_register_operand")))
+
+(define_predicate "imm_for_neon_logic_operand"
+  (match_code "const_vector")
+{
+  return (TARGET_NEON
+          && neon_immediate_valid_for_logic (op, mode, 0, NULL, NULL));
+})
+
+(define_predicate "neon_logic_op2"
+  (ior (match_operand 0 "imm_for_neon_logic_operand")
+       (match_operand 0 "s_register_operand")))
+
 ;; Any hard register.
 (define_predicate "arm_hard_register_operand"
   (match_code "reg")
@@ -145,6 +167,23 @@
   (ior (match_operand 0 "arm_rhs_operand")
        (match_operand 0 "arm_neg_immediate_operand")))
 
+(define_predicate "arm_anddi_operand_neon"
+  (ior (match_operand 0 "s_register_operand")
+       (and (match_code "const_int")
+	    (match_test "const_ok_for_dimode_op (INTVAL (op), AND)"))
+       (match_operand 0 "neon_inv_logic_op2")))
+
+(define_predicate "arm_iordi_operand_neon"
+  (ior (match_operand 0 "s_register_operand")
+       (and (match_code "const_int")
+	    (match_test "const_ok_for_dimode_op (INTVAL (op), IOR)"))
+       (match_operand 0 "neon_logic_op2")))
+
+(define_predicate "arm_xordi_operand"
+  (ior (match_operand 0 "s_register_operand")
+       (and (match_code "const_int")
+	    (match_test "const_ok_for_dimode_op (INTVAL (op), XOR)"))))
+
 (define_predicate "arm_adddi_operand"
   (ior (match_operand 0 "s_register_operand")
        (and (match_code "const_int")
@@ -270,6 +309,24 @@
 (define_special_predicate "lt_ge_comparison_operator"
   (match_code "lt,ge"))
 
+;; The vsel instruction only accepts the ARM condition codes listed below.
+(define_special_predicate "arm_vsel_comparison_operator"
+  (and (match_operand 0 "expandable_comparison_operator")
+       (match_test "maybe_get_arm_condition_code (op) == ARM_GE
+                    || maybe_get_arm_condition_code (op) == ARM_GT
+                    || maybe_get_arm_condition_code (op) == ARM_EQ
+                    || maybe_get_arm_condition_code (op) == ARM_VS
+                    || maybe_get_arm_condition_code (op) == ARM_LT
+                    || maybe_get_arm_condition_code (op) == ARM_LE
+                    || maybe_get_arm_condition_code (op) == ARM_NE
+                    || maybe_get_arm_condition_code (op) == ARM_VC")))
+
+(define_special_predicate "arm_cond_move_operator"
+  (if_then_else (match_test "arm_restrict_it")
+                (and (match_test "TARGET_FPU_ARMV8")
+                     (match_operand 0 "arm_vsel_comparison_operator"))
+                (match_operand 0 "expandable_comparison_operator")))
+
 (define_special_predicate "noov_comparison_operator"
   (match_code "lt,ge,eq,ne"))
 
@@ -506,28 +563,6 @@
   (ior (match_operand 0 "s_register_operand")
        (match_operand 0 "imm_for_neon_rshift_operand")))
 
-(define_predicate "imm_for_neon_logic_operand"
-  (match_code "const_vector")
-{
-  return (TARGET_NEON
-          && neon_immediate_valid_for_logic (op, mode, 0, NULL, NULL));
-})
-
-(define_predicate "imm_for_neon_inv_logic_operand"
-  (match_code "const_vector")
-{
-  return (TARGET_NEON
-          && neon_immediate_valid_for_logic (op, mode, 1, NULL, NULL));
-})
-
-(define_predicate "neon_logic_op2"
-  (ior (match_operand 0 "imm_for_neon_logic_operand")
-       (match_operand 0 "s_register_operand")))
-
-(define_predicate "neon_inv_logic_op2"
-  (ior (match_operand 0 "imm_for_neon_inv_logic_operand")
-       (match_operand 0 "s_register_operand")))
-
 ;; Predicates for named expanders that overlap multiple ISAs.
 
 (define_predicate "cmpdi_operand"
@@ -605,10 +640,14 @@
 
 (define_predicate "neon_struct_operand"
   (and (match_code "mem")
-       (match_test "TARGET_32BIT && neon_vector_mem_operand (op, 2)")))
+       (match_test "TARGET_32BIT && neon_vector_mem_operand (op, 2, true)")))
 
-(define_predicate "neon_struct_or_register_operand"
-  (ior (match_operand 0 "neon_struct_operand")
+(define_predicate "neon_permissive_struct_operand"
+  (and (match_code "mem")
+       (match_test "TARGET_32BIT && neon_vector_mem_operand (op, 2, false)")))
+
+(define_predicate "neon_perm_struct_or_reg_operand"
+  (ior (match_operand 0 "neon_permissive_struct_operand")
        (match_operand 0 "s_register_operand")))
 
 (define_special_predicate "add_operator"
@@ -617,3 +656,7 @@
 (define_predicate "mem_noofs_operand"
   (and (match_code "mem")
        (match_code "reg" "0")))
+
+(define_predicate "call_insn_operand"
+  (ior (match_code "symbol_ref")
+       (match_operand 0 "s_register_operand")))
diff --git a/gcc/config/arm/sync.md b/gcc/config/arm/sync.md
index 281e51e..8f7bd71 100644
--- a/gcc/config/arm/sync.md
+++ b/gcc/config/arm/sync.md
@@ -65,6 +65,42 @@
    (set_attr "conds" "unconditional")
    (set_attr "predicable" "no")])
 
+(define_insn "atomic_load<mode>"
+  [(set (match_operand:QHSI 0 "register_operand" "=r")
+    (unspec_volatile:QHSI
+      [(match_operand:QHSI 1 "arm_sync_memory_operand" "Q")
+       (match_operand:SI 2 "const_int_operand")]		;; model
+      VUNSPEC_LDA))]
+  "TARGET_HAVE_LDACQ"
+  {
+    enum memmodel model = (enum memmodel) INTVAL (operands[2]);
+    if (model == MEMMODEL_RELAXED
+        || model == MEMMODEL_CONSUME
+        || model == MEMMODEL_RELEASE)
+      return \"ldr<sync_sfx>\\t%0, %1\";
+    else
+      return \"lda<sync_sfx>\\t%0, %1\";
+  }
+)
+
+(define_insn "atomic_store<mode>"
+  [(set (match_operand:QHSI 0 "memory_operand" "=Q")
+    (unspec_volatile:QHSI
+      [(match_operand:QHSI 1 "general_operand" "r")
+       (match_operand:SI 2 "const_int_operand")]		;; model
+      VUNSPEC_STL))]
+  "TARGET_HAVE_LDACQ"
+  {
+    enum memmodel model = (enum memmodel) INTVAL (operands[2]);
+    if (model == MEMMODEL_RELAXED
+        || model == MEMMODEL_CONSUME
+        || model == MEMMODEL_ACQUIRE)
+      return \"str<sync_sfx>\t%1, %0\";
+    else
+      return \"stl<sync_sfx>\t%1, %0\";
+  }
+)
+
 ;; Note that ldrd and vldr are *not* guaranteed to be single-copy atomic,
 ;; even for a 64-bit aligned address.  Instead we use a ldrexd unparied
 ;; with a store.
@@ -88,7 +124,8 @@
 		   UNSPEC_LL))]
   "TARGET_HAVE_LDREXD && ARM_DOUBLEWORD_ALIGN"
   "ldrexd%?\t%0, %H0, %C1"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_expand "atomic_compare_and_swap<mode>"
   [(match_operand:SI 0 "s_register_operand" "")		;; bool out
@@ -325,7 +362,19 @@
 	    VUNSPEC_LL)))]
   "TARGET_HAVE_LDREXBH"
   "ldrex<sync_sfx>%?\t%0, %C1"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
+
+(define_insn "arm_load_acquire_exclusive<mode>"
+  [(set (match_operand:SI 0 "s_register_operand" "=r")
+        (zero_extend:SI
+	  (unspec_volatile:NARROW
+	    [(match_operand:NARROW 1 "mem_noofs_operand" "Ua")]
+	    VUNSPEC_LAX)))]
+  "TARGET_HAVE_LDACQ"
+  "ldaex<sync_sfx>%?\\t%0, %C1"
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "arm_load_exclusivesi"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
@@ -334,7 +383,18 @@
 	  VUNSPEC_LL))]
   "TARGET_HAVE_LDREX"
   "ldrex%?\t%0, %C1"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
+
+(define_insn "arm_load_acquire_exclusivesi"
+  [(set (match_operand:SI 0 "s_register_operand" "=r")
+	(unspec_volatile:SI
+	  [(match_operand:SI 1 "mem_noofs_operand" "Ua")]
+	  VUNSPEC_LAX))]
+  "TARGET_HAVE_LDACQ"
+  "ldaex%?\t%0, %C1"
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "arm_load_exclusivedi"
   [(set (match_operand:DI 0 "s_register_operand" "=r")
@@ -343,7 +403,18 @@
 	  VUNSPEC_LL))]
   "TARGET_HAVE_LDREXD"
   "ldrexd%?\t%0, %H0, %C1"
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
+
+(define_insn "arm_load_acquire_exclusivedi"
+  [(set (match_operand:DI 0 "s_register_operand" "=r")
+	(unspec_volatile:DI
+	  [(match_operand:DI 1 "mem_noofs_operand" "Ua")]
+	  VUNSPEC_LAX))]
+  "TARGET_HAVE_LDACQ && ARM_DOUBLEWORD_ALIGN"
+  "ldaexd%?\t%0, %H0, %C1"
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
 
 (define_insn "arm_store_exclusive<mode>"
   [(set (match_operand:SI 0 "s_register_operand" "=&r")
@@ -367,4 +438,35 @@
       }
     return "strex<sync_sfx>%?\t%0, %2, %C1";
   }
-  [(set_attr "predicable" "yes")])
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
+
+(define_insn "arm_store_release_exclusivedi"
+  [(set (match_operand:SI 0 "s_register_operand" "=&r")
+	(unspec_volatile:SI [(const_int 0)] VUNSPEC_SLX))
+   (set (match_operand:DI 1 "mem_noofs_operand" "=Ua")
+	(unspec_volatile:DI
+	  [(match_operand:DI 2 "s_register_operand" "r")]
+	  VUNSPEC_SLX))]
+  "TARGET_HAVE_LDACQ && ARM_DOUBLEWORD_ALIGN"
+  {
+    rtx value = operands[2];
+    /* See comment in arm_store_exclusive<mode> above.  */
+    gcc_assert ((REGNO (value) & 1) == 0 || TARGET_THUMB2);
+    operands[3] = gen_rtx_REG (SImode, REGNO (value) + 1);
+    return "stlexd%?\t%0, %2, %3, %C1";
+  }
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
+
+(define_insn "arm_store_release_exclusive<mode>"
+  [(set (match_operand:SI 0 "s_register_operand" "=&r")
+	(unspec_volatile:SI [(const_int 0)] VUNSPEC_SLX))
+   (set (match_operand:QHSI 1 "mem_noofs_operand" "=Ua")
+	(unspec_volatile:QHSI
+	  [(match_operand:QHSI 2 "s_register_operand" "r")]
+	  VUNSPEC_SLX))]
+  "TARGET_HAVE_LDACQ"
+  "stlex<sync_sfx>%?\t%0, %2, %C1"
+  [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")])
diff --git a/gcc/config/arm/t-arm b/gcc/config/arm/t-arm
index 96b88de..246f0f5 100644
--- a/gcc/config/arm/t-arm
+++ b/gcc/config/arm/t-arm
@@ -39,6 +39,7 @@ MD_INCLUDES=	$(srcdir)/config/arm/arm1020e.md \
 		$(srcdir)/config/arm/cortex-a8-neon.md \
 		$(srcdir)/config/arm/cortex-a9.md \
 		$(srcdir)/config/arm/cortex-a9-neon.md \
+		$(srcdir)/config/arm/cortex-a53.md \
 		$(srcdir)/config/arm/cortex-m4-fpu.md \
 		$(srcdir)/config/arm/cortex-m4.md \
 		$(srcdir)/config/arm/cortex-r4f.md \
@@ -52,6 +53,7 @@ MD_INCLUDES=	$(srcdir)/config/arm/arm1020e.md \
 		$(srcdir)/config/arm/iwmmxt.md \
 		$(srcdir)/config/arm/iwmmxt2.md \
 		$(srcdir)/config/arm/ldmstm.md \
+		$(srcdir)/config/arm/ldrdstrd.md \
 		$(srcdir)/config/arm/marvell-f-iwmmxt.md \
 		$(srcdir)/config/arm/neon.md \
 		$(srcdir)/config/arm/predicates.md \
@@ -76,15 +78,16 @@ $(srcdir)/config/arm/arm-tables.opt: $(srcdir)/config/arm/genopt.sh \
 	$(SHELL) $(srcdir)/config/arm/genopt.sh $(srcdir)/config/arm > \
 		$(srcdir)/config/arm/arm-tables.opt
 
-arm.o: $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \
-  $(RTL_H) $(TREE_H) $(OBSTACK_H) $(REGS_H) hard-reg-set.h \
+arm.o: $(srcdir)/config/arm/arm.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \
+  $(RTL_H) $(TREE_H) $(HASH_TABLE_H) $(OBSTACK_H) $(REGS_H) hard-reg-set.h \
   insn-config.h conditions.h output.h dumpfile.h \
   $(INSN_ATTR_H) $(FLAGS_H) reload.h $(FUNCTION_H) \
   $(EXPR_H) $(OPTABS_H) $(RECOG_H) $(CGRAPH_H) \
   $(GGC_H) except.h $(C_PRAGMA_H) $(TM_P_H) \
   $(TARGET_H) $(TARGET_DEF_H) debug.h langhooks.h $(DF_H) \
   intl.h libfuncs.h $(PARAMS_H) $(OPTS_H) $(srcdir)/config/arm/arm-cores.def \
-  $(srcdir)/config/arm/arm-arches.def $(srcdir)/config/arm/arm-fpus.def
+  $(srcdir)/config/arm/arm-arches.def $(srcdir)/config/arm/arm-fpus.def \
+  $(srcdir)/config/arm/arm_neon_builtins.def
 
 arm-c.o: $(srcdir)/config/arm/arm-c.c $(CONFIG_H) $(SYSTEM_H) \
     coretypes.h $(TM_H) $(TREE_H) output.h $(C_COMMON_H)
diff --git a/gcc/config/arm/t-arm-elf b/gcc/config/arm/t-arm-elf
index 60747d3..76b0230 100644
--- a/gcc/config/arm/t-arm-elf
+++ b/gcc/config/arm/t-arm-elf
@@ -25,22 +25,27 @@ MULTILIB_MATCHES     =
 #MULTILIB_DIRNAMES    += fa526 fa626 fa606te fa626te fmp626 fa726te
 #MULTILIB_EXCEPTIONS  += *mthumb*/*mcpu=fa526 *mthumb*/*mcpu=fa626
 
-#MULTILIB_OPTIONS      += march=armv7
-#MULTILIB_DIRNAMES     += thumb2
-#MULTILIB_EXCEPTIONS   += march=armv7* marm/*march=armv7*
-#MULTILIB_MATCHES      += march?armv7=march?armv7-a
-#MULTILIB_MATCHES      += march?armv7=march?armv7-r
-#MULTILIB_MATCHES      += march?armv7=march?armv7-m
-#MULTILIB_MATCHES      += march?armv7=mcpu?cortex-a8
-#MULTILIB_MATCHES      += march?armv7=mcpu?cortex-r4
-#MULTILIB_MATCHES      += march?armv7=mcpu?cortex-m3
+# Enable these for ANDROID arm-eabi toolchain
+MULTILIB_OPTIONS      += march=armv7
+MULTILIB_DIRNAMES     += thumb2
+MULTILIB_EXCEPTIONS   += march=armv7* marm/*march=armv7*
+MULTILIB_MATCHES      += march?armv7=march?armv7-a
+MULTILIB_MATCHES      += march?armv7=march?armv7-r
+MULTILIB_MATCHES      += march?armv7=march?armv7-m
+MULTILIB_MATCHES      += march?armv7=mcpu?cortex-a8
+MULTILIB_MATCHES      += march?armv7=mcpu?cortex-r4
+MULTILIB_MATCHES      += march?armv7=mcpu?cortex-m3
+MULTILIB_MATCHES      += march?armv7=mcpu?cortex-m4
 
 # Not quite true.  We can support hard-vfp calling in Thumb2, but how do we
 # express that here?  Also, we really need architecture v5e or later
 # (mcrr etc).
-MULTILIB_OPTIONS       += mfloat-abi=hard
-MULTILIB_DIRNAMES      += fpu
-MULTILIB_EXCEPTIONS    += *mthumb/*mfloat-abi=hard*
+
+# Disable these for ANDROID arm-eabi toolchain
+#MULTILIB_OPTIONS       += mfloat-abi=hard
+#MULTILIB_DIRNAMES      += fpu
+#MULTILIB_EXCEPTIONS    += *mthumb/*mfloat-abi=hard*
+
 #MULTILIB_EXCEPTIONS    += *mcpu=fa526/*mfloat-abi=hard*
 #MULTILIB_EXCEPTIONS    += *mcpu=fa626/*mfloat-abi=hard*
 
diff --git a/gcc/config/arm/thumb2.md b/gcc/config/arm/thumb2.md
index 697350c..cd58374 100644
--- a/gcc/config/arm/thumb2.md
+++ b/gcc/config/arm/thumb2.md
@@ -24,33 +24,7 @@
 ;; changes made in armv5t as "thumb2".  These are considered part
 ;; the 16-bit Thumb-1 instruction set.
 
-(define_insn "*thumb2_incscc"
-  [(set (match_operand:SI 0 "s_register_operand" "=r,r")
-        (plus:SI (match_operator:SI 2 "arm_comparison_operator"
-                    [(match_operand:CC 3 "cc_register" "") (const_int 0)])
-                 (match_operand:SI 1 "s_register_operand" "0,?r")))]
-  "TARGET_THUMB2"
-  "@
-  it\\t%d2\;add%d2\\t%0, %1, #1
-  ite\\t%D2\;mov%D2\\t%0, %1\;add%d2\\t%0, %1, #1"
-  [(set_attr "conds" "use")
-   (set_attr "length" "6,10")]
-)
-
-(define_insn "*thumb2_decscc"
-  [(set (match_operand:SI            0 "s_register_operand" "=r,r")
-        (minus:SI (match_operand:SI  1 "s_register_operand" "0,?r")
-		  (match_operator:SI 2 "arm_comparison_operator"
-                   [(match_operand   3 "cc_register" "") (const_int 0)])))]
-  "TARGET_THUMB2"
-  "@
-   it\\t%d2\;sub%d2\\t%0, %1, #1
-   ite\\t%D2\;mov%D2\\t%0, %1\;sub%d2\\t%0, %1, #1"
-  [(set_attr "conds" "use")
-   (set_attr "length" "6,10")]
-)
-
-;; Thumb-2 only allows shift by constant on data processing instructions 
+;; Thumb-2 only allows shift by constant on data processing instructions
 (define_insn "*thumb_andsi_not_shiftsi_si"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(and:SI (not:SI (match_operator:SI 4 "shift_operator"
@@ -64,81 +38,167 @@
    (set_attr "type" "alu_shift")]
 )
 
-(define_insn "*thumb2_smaxsi3"
+(define_insn_and_split "*thumb2_smaxsi3"
   [(set (match_operand:SI          0 "s_register_operand" "=r,r,r")
 	(smax:SI (match_operand:SI 1 "s_register_operand"  "0,r,?r")
 		 (match_operand:SI 2 "arm_rhs_operand"    "rI,0,rI")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_THUMB2"
-  "@
-   cmp\\t%1, %2\;it\\tlt\;movlt\\t%0, %2
-   cmp\\t%1, %2\;it\\tge\;movge\\t%0, %1
-   cmp\\t%1, %2\;ite\\tge\;movge\\t%0, %1\;movlt\\t%0, %2"
+  "#"
+  ; cmp\\t%1, %2\;it\\tlt\;movlt\\t%0, %2
+  ; cmp\\t%1, %2\;it\\tge\;movge\\t%0, %1
+  ; cmp\\t%1, %2\;ite\\tge\;movge\\t%0, %1\;movlt\\t%0, %2
+  "TARGET_THUMB2"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+        (if_then_else:SI (ge:SI (reg:CC CC_REGNUM) (const_int 0))
+                         (match_dup 1)
+                         (match_dup 2)))]
+  ""
   [(set_attr "conds" "clob")
    (set_attr "length" "10,10,14")]
 )
 
-(define_insn "*thumb2_sminsi3"
+(define_insn_and_split "*thumb2_sminsi3"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r,r")
 	(smin:SI (match_operand:SI 1 "s_register_operand" "0,r,?r")
 		 (match_operand:SI 2 "arm_rhs_operand" "rI,0,rI")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_THUMB2"
-  "@
-   cmp\\t%1, %2\;it\\tge\;movge\\t%0, %2
-   cmp\\t%1, %2\;it\\tlt\;movlt\\t%0, %1
-   cmp\\t%1, %2\;ite\\tlt\;movlt\\t%0, %1\;movge\\t%0, %2"
+  "#"
+   ; cmp\\t%1, %2\;it\\tge\;movge\\t%0, %2
+   ; cmp\\t%1, %2\;it\\tlt\;movlt\\t%0, %1
+   ; cmp\\t%1, %2\;ite\\tlt\;movlt\\t%0, %1\;movge\\t%0, %2"
+  "TARGET_THUMB2"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+        (if_then_else:SI (lt:SI (reg:CC CC_REGNUM) (const_int 0))
+                         (match_dup 1)
+                         (match_dup 2)))]
+  ""
   [(set_attr "conds" "clob")
    (set_attr "length" "10,10,14")]
 )
 
-(define_insn "*thumb32_umaxsi3"
+(define_insn_and_split "*thumb32_umaxsi3"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r,r")
 	(umax:SI (match_operand:SI 1 "s_register_operand" "0,r,?r")
 		 (match_operand:SI 2 "arm_rhs_operand" "rI,0,rI")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_THUMB2"
-  "@
-   cmp\\t%1, %2\;it\\tcc\;movcc\\t%0, %2
-   cmp\\t%1, %2\;it\\tcs\;movcs\\t%0, %1
-   cmp\\t%1, %2\;ite\\tcs\;movcs\\t%0, %1\;movcc\\t%0, %2"
+  "#"
+   ; cmp\\t%1, %2\;it\\tcc\;movcc\\t%0, %2
+   ; cmp\\t%1, %2\;it\\tcs\;movcs\\t%0, %1
+   ; cmp\\t%1, %2\;ite\\tcs\;movcs\\t%0, %1\;movcc\\t%0, %2"
+  "TARGET_THUMB2"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+        (if_then_else:SI (geu:SI (reg:CC CC_REGNUM) (const_int 0))
+                         (match_dup 1)
+                         (match_dup 2)))]
+  ""
   [(set_attr "conds" "clob")
    (set_attr "length" "10,10,14")]
 )
 
-(define_insn "*thumb2_uminsi3"
+(define_insn_and_split "*thumb2_uminsi3"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r,r")
 	(umin:SI (match_operand:SI 1 "s_register_operand" "0,r,?r")
 		 (match_operand:SI 2 "arm_rhs_operand" "rI,0,rI")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_THUMB2"
-  "@
-   cmp\\t%1, %2\;it\\tcs\;movcs\\t%0, %2
-   cmp\\t%1, %2\;it\\tcc\;movcc\\t%0, %1
-   cmp\\t%1, %2\;ite\\tcc\;movcc\\t%0, %1\;movcs\\t%0, %2"
+  "#"
+   ; cmp\\t%1, %2\;it\\tcs\;movcs\\t%0, %2
+   ; cmp\\t%1, %2\;it\\tcc\;movcc\\t%0, %1
+   ; cmp\\t%1, %2\;ite\\tcc\;movcc\\t%0, %1\;movcs\\t%0, %2"
+  "TARGET_THUMB2"
+  [(set (reg:CC CC_REGNUM)
+        (compare:CC (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+        (if_then_else:SI (ltu:SI (reg:CC CC_REGNUM) (const_int 0))
+                         (match_dup 1)
+                         (match_dup 2)))]
+  ""
   [(set_attr "conds" "clob")
    (set_attr "length" "10,10,14")]
 )
 
 ;; Thumb-2 does not have rsc, so use a clever trick with shifter operands.
-(define_insn "*thumb2_negdi2"
+(define_insn_and_split "*thumb2_negdi2"
   [(set (match_operand:DI         0 "s_register_operand" "=&r,r")
 	(neg:DI (match_operand:DI 1 "s_register_operand"  "?r,0")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_THUMB2"
-  "negs\\t%Q0, %Q1\;sbc\\t%R0, %R1, %R1, lsl #1"
+  "#" ; negs\\t%Q0, %Q1\;sbc\\t%R0, %R1, %R1, lsl #1
+  "&& reload_completed"
+  [(parallel [(set (reg:CC CC_REGNUM)
+		   (compare:CC (const_int 0) (match_dup 1)))
+	      (set (match_dup 0) (minus:SI (const_int 0) (match_dup 1)))])
+   (set (match_dup 2) (minus:SI (minus:SI (match_dup 3)
+                                          (ashift:SI (match_dup 3)
+                                                     (const_int 1)))
+                                (ltu:SI (reg:CC_C CC_REGNUM) (const_int 0))))]
+  {
+    operands[2] = gen_highpart (SImode, operands[0]);
+    operands[0] = gen_lowpart (SImode, operands[0]);
+    operands[3] = gen_highpart (SImode, operands[1]);
+    operands[1] = gen_lowpart (SImode, operands[1]);
+  }
   [(set_attr "conds" "clob")
    (set_attr "length" "8")]
 )
 
-(define_insn "*thumb2_abssi2"
+(define_insn_and_split "*thumb2_abssi2"
   [(set (match_operand:SI         0 "s_register_operand" "=r,&r")
 	(abs:SI (match_operand:SI 1 "s_register_operand" "0,r")))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_THUMB2"
-  "@
-   cmp\\t%0, #0\;it\tlt\;rsblt\\t%0, %0, #0
-   eor%?\\t%0, %1, %1, asr #31\;sub%?\\t%0, %0, %1, asr #31"
+  "#"
+   ; cmp\\t%0, #0\;it\tlt\;rsblt\\t%0, %0, #0
+   ; eor%?\\t%0, %1, %1, asr #31\;sub%?\\t%0, %0, %1, asr #31
+  "&& reload_completed"
+  [(const_int 0)]
+  {
+    /* if (which_alternative == 0) */
+    if (REGNO(operands[0]) == REGNO(operands[1]))
+      {
+       rtx cc_reg = gen_rtx_REG (CCmode, CC_REGNUM);
+
+       emit_insn (gen_rtx_SET (VOIDmode,
+                               cc_reg,
+                               gen_rtx_COMPARE (CCmode, operands[0], const0_rtx)));
+       emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                    (gen_rtx_LT (SImode,
+                                                 cc_reg,
+                                                 const0_rtx)),
+                                    (gen_rtx_SET (VOIDmode,
+                                                  operands[0],
+                                                  (gen_rtx_MINUS (SImode,
+                                                                  const0_rtx,
+                                                                  operands[1]))))));
+      }
+    else
+      {
+        emit_insn (gen_rtx_SET (VOIDmode,
+                                operands[0],
+                                gen_rtx_XOR (SImode,
+                                             gen_rtx_ASHIFTRT (SImode,
+                                                               operands[1],
+                                                               GEN_INT (31)),
+                                             operands[1])));
+        emit_insn (gen_rtx_SET (VOIDmode,
+                                operands[0],
+                                gen_rtx_MINUS (SImode,
+                                               operands[0],
+                                               gen_rtx_ASHIFTRT (SImode,
+                                                                 operands[1],
+                                                                 GEN_INT (31)))));
+      }
+    DONE;
+  }
   [(set_attr "conds" "clob,*")
    (set_attr "shift" "1")
    (set_attr "predicable" "no, yes")
@@ -146,14 +206,54 @@
    (set_attr "length" "10,8")]
 )
 
-(define_insn "*thumb2_neg_abssi2"
+(define_insn_and_split "*thumb2_neg_abssi2"
   [(set (match_operand:SI 0 "s_register_operand" "=r,&r")
 	(neg:SI (abs:SI (match_operand:SI 1 "s_register_operand" "0,r"))))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_THUMB2"
-  "@
-   cmp\\t%0, #0\;it\\tgt\;rsbgt\\t%0, %0, #0
-   eor%?\\t%0, %1, %1, asr #31\;rsb%?\\t%0, %0, %1, asr #31"
+  "#"
+   ; cmp\\t%0, #0\;it\\tgt\;rsbgt\\t%0, %0, #0
+   ; eor%?\\t%0, %1, %1, asr #31\;rsb%?\\t%0, %0, %1, asr #31"
+  "&& reload_completed"
+  [(const_int 0)]
+  {
+    /* if (which_alternative == 0) */
+    if (REGNO(operands[0]) == REGNO(operands[1]))
+      {
+       rtx cc_reg = gen_rtx_REG (CCmode, CC_REGNUM);
+
+       emit_insn (gen_rtx_SET (VOIDmode,
+                               cc_reg,
+                               gen_rtx_COMPARE (CCmode, operands[0], const0_rtx)));
+       emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                    (gen_rtx_GT (SImode,
+                                                 cc_reg,
+                                                 const0_rtx)),
+                                    (gen_rtx_SET (VOIDmode,
+                                                  operands[0],
+                                                  (gen_rtx_MINUS (SImode,
+                                                                  const0_rtx,
+                                                                  operands[1]))))));
+      }
+    else
+      {
+        emit_insn (gen_rtx_SET (VOIDmode,
+                                operands[0],
+                                gen_rtx_XOR (SImode,
+                                             gen_rtx_ASHIFTRT (SImode,
+                                                               operands[1],
+                                                               GEN_INT (31)),
+                                             operands[1])));
+        emit_insn (gen_rtx_SET (VOIDmode,
+                                operands[0],
+                                gen_rtx_MINUS (SImode,
+                                               gen_rtx_ASHIFTRT (SImode,
+                                                                 operands[1],
+                                                                 GEN_INT (31)),
+                                               operands[0])));
+      }
+    DONE;
+  }
   [(set_attr "conds" "clob,*")
    (set_attr "shift" "1")
    (set_attr "predicable" "no, yes")
@@ -167,8 +267,8 @@
 ;; regs.  The high register alternatives are not taken into account when
 ;; choosing register preferences in order to reflect their expense.
 (define_insn "*thumb2_movsi_insn"
-  [(set (match_operand:SI 0 "nonimmediate_operand" "=rk,r,r,r,l ,*hk,m,*m")
-	(match_operand:SI 1 "general_operand"	   "rk ,I,K,j,mi,*mi,l,*hk"))]
+  [(set (match_operand:SI 0 "nonimmediate_operand" "=rk,r,l,r,r,l ,*hk,m,*m")
+	(match_operand:SI 1 "general_operand"	   "rk,I,Py,K,j,mi,*mi,l,*hk"))]
   "TARGET_THUMB2 && ! TARGET_IWMMXT
    && !(TARGET_HARD_FLOAT && TARGET_VFP)
    && (   register_operand (operands[0], SImode)
@@ -176,16 +276,19 @@
   "@
    mov%?\\t%0, %1
    mov%?\\t%0, %1
+   mov%?\\t%0, %1
    mvn%?\\t%0, #%B1
    movw%?\\t%0, %1
    ldr%?\\t%0, %1
    ldr%?\\t%0, %1
    str%?\\t%1, %0
    str%?\\t%1, %0"
-  [(set_attr "type" "*,*,simple_alu_imm,*,load1,load1,store1,store1")
+  [(set_attr "type" "*,simple_alu_imm,simple_alu_imm,simple_alu_imm,*,load1,load1,store1,store1")
+   (set_attr "length" "2,4,2,4,4,4,4,4,4")
    (set_attr "predicable" "yes")
-   (set_attr "pool_range" "*,*,*,*,1018,4094,*,*")
-   (set_attr "neg_pool_range" "*,*,*,*,0,0,*,*")]
+   (set_attr "predicable_short_it" "yes,no,yes,no,no,no,no,no,no")
+   (set_attr "pool_range" "*,*,*,*,*,1018,4094,*,*")
+   (set_attr "neg_pool_range" "*,*,*,*,*,0,0,*,*")]
 )
 
 (define_insn "tls_load_dot_plus_four"
@@ -236,54 +339,118 @@
    (set_attr "type" "alu_shift")]
 )
 
-(define_insn "*thumb2_mov_scc"
+(define_insn_and_split "*thumb2_mov_scc"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(match_operator:SI 1 "arm_comparison_operator"
 	 [(match_operand 2 "cc_register" "") (const_int 0)]))]
   "TARGET_THUMB2"
-  "ite\\t%D1\;mov%D1\\t%0, #0\;mov%d1\\t%0, #1"
+  "#"   ; "ite\\t%D1\;mov%D1\\t%0, #0\;mov%d1\\t%0, #1"
+  "TARGET_THUMB2"
+  [(set (match_dup 0)
+        (if_then_else:SI (match_dup 1)
+                         (const_int 1)
+                         (const_int 0)))]
+  ""
   [(set_attr "conds" "use")
    (set_attr "length" "10")]
 )
 
-(define_insn "*thumb2_mov_negscc"
+(define_insn_and_split "*thumb2_mov_negscc"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(neg:SI (match_operator:SI 1 "arm_comparison_operator"
 		 [(match_operand 2 "cc_register" "") (const_int 0)])))]
   "TARGET_THUMB2"
-  "ite\\t%D1\;mov%D1\\t%0, #0\;mvn%d1\\t%0, #0"
+  "#"   ; "ite\\t%D1\;mov%D1\\t%0, #0\;mvn%d1\\t%0, #0"
+  "TARGET_THUMB2"
+  [(set (match_dup 0)
+        (if_then_else:SI (match_dup 1)
+                         (match_dup 3)
+                         (const_int 0)))]
+  {
+    operands[3] = GEN_INT (~0);
+  }
   [(set_attr "conds" "use")
    (set_attr "length" "10")]
 )
 
-(define_insn "*thumb2_mov_notscc"
+(define_insn_and_split "*thumb2_mov_notscc"
   [(set (match_operand:SI 0 "s_register_operand" "=r")
 	(not:SI (match_operator:SI 1 "arm_comparison_operator"
 		 [(match_operand 2 "cc_register" "") (const_int 0)])))]
   "TARGET_THUMB2"
-  "ite\\t%D1\;mvn%D1\\t%0, #0\;mvn%d1\\t%0, #1"
+  "#"   ; "ite\\t%D1\;mvn%D1\\t%0, #0\;mvn%d1\\t%0, #1"
+  "TARGET_THUMB2"
+  [(set (match_dup 0)
+        (if_then_else:SI (match_dup 1)
+                         (match_dup 3)
+                         (match_dup 4)))]
+  {
+    operands[3] = GEN_INT (~1);
+    operands[4] = GEN_INT (~0);
+  }
   [(set_attr "conds" "use")
    (set_attr "length" "10")]
 )
 
-(define_insn "*thumb2_movsicc_insn"
-  [(set (match_operand:SI 0 "s_register_operand" "=r,r,r,r,r,r,r,r")
+(define_insn_and_split "*thumb2_movsicc_insn"
+  [(set (match_operand:SI 0 "s_register_operand" "=l,l,r,r,r,r,r,r,r,r,r,l")
 	(if_then_else:SI
 	 (match_operator 3 "arm_comparison_operator"
 	  [(match_operand 4 "cc_register" "") (const_int 0)])
-	 (match_operand:SI 1 "arm_not_operand" "0,0,rI,K,rI,rI,K,K")
-	 (match_operand:SI 2 "arm_not_operand" "rI,K,0,0,rI,K,rI,K")))]
+	 (match_operand:SI 1 "arm_not_operand" "0 ,Py,0 ,0,rI,K,rI,rI,K ,K,r,lPy")
+	 (match_operand:SI 2 "arm_not_operand" "Py,0 ,rI,K,0 ,0,rI,K ,rI,K,r,lPy")))]
   "TARGET_THUMB2"
   "@
    it\\t%D3\;mov%D3\\t%0, %2
+   it\\t%d3\;mov%d3\\t%0, %1
+   it\\t%D3\;mov%D3\\t%0, %2
    it\\t%D3\;mvn%D3\\t%0, #%B2
    it\\t%d3\;mov%d3\\t%0, %1
    it\\t%d3\;mvn%d3\\t%0, #%B1
-   ite\\t%d3\;mov%d3\\t%0, %1\;mov%D3\\t%0, %2
-   ite\\t%d3\;mov%d3\\t%0, %1\;mvn%D3\\t%0, #%B2
-   ite\\t%d3\;mvn%d3\\t%0, #%B1\;mov%D3\\t%0, %2
-   ite\\t%d3\;mvn%d3\\t%0, #%B1\;mvn%D3\\t%0, #%B2"
-  [(set_attr "length" "6,6,6,6,10,10,10,10")
+   #
+   #
+   #
+   #
+   #
+   #"
+   ; alt 6: ite\\t%d3\;mov%d3\\t%0, %1\;mov%D3\\t%0, %2
+   ; alt 7: ite\\t%d3\;mov%d3\\t%0, %1\;mvn%D3\\t%0, #%B2
+   ; alt 8: ite\\t%d3\;mvn%d3\\t%0, #%B1\;mov%D3\\t%0, %2
+   ; alt 9: ite\\t%d3\;mvn%d3\\t%0, #%B1\;mvn%D3\\t%0, #%B2
+   ; alt 10: ite\\t%d3\;mov%d3\\t%0, %1\;mov%D3\\t%0, %2
+   ; alt 11: ite\\t%d3\;mov%d3\\t%0, %1\;mov%D3\\t%0, %2"
+  "&& reload_completed"
+  [(const_int 0)]
+  {
+    enum rtx_code rev_code;
+    enum machine_mode mode;
+    rtx rev_cond;
+
+    emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                  operands[3],
+                                  gen_rtx_SET (VOIDmode,
+                                               operands[0],
+                                               operands[1])));
+    rev_code = GET_CODE (operands[3]);
+    mode = GET_MODE (operands[4]);
+    if (mode == CCFPmode || mode == CCFPEmode)
+      rev_code = reverse_condition_maybe_unordered (rev_code);
+    else
+      rev_code = reverse_condition (rev_code);
+
+    rev_cond = gen_rtx_fmt_ee (rev_code,
+                               VOIDmode,
+                               gen_rtx_REG (mode, CC_REGNUM),
+                               const0_rtx);
+    emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                  rev_cond,
+                                  gen_rtx_SET (VOIDmode,
+                                               operands[0],
+                                               operands[2])));
+    DONE;
+  }
+  [(set_attr "length" "4,4,6,6,6,6,10,10,10,10,6,6")
+   (set_attr "enabled_for_depr_it" "yes,yes,no,no,no,no,no,no,no,no,yes,yes")
    (set_attr "conds" "use")]
 )
 
@@ -330,29 +497,62 @@
   [(set_attr "conds" "clob")]
 )
 ;; Don't define thumb2_load_indirect_jump because we can't guarantee label
-;; addresses will have the thumb bit set correctly. 
+;; addresses will have the thumb bit set correctly.
 
 
-(define_insn "*thumb2_and_scc"
-  [(set (match_operand:SI 0 "s_register_operand" "=r")
+(define_insn_and_split "*thumb2_and_scc"
+  [(set (match_operand:SI 0 "s_register_operand" "=Ts")
 	(and:SI (match_operator:SI 1 "arm_comparison_operator"
-		 [(match_operand 3 "cc_register" "") (const_int 0)])
-		(match_operand:SI 2 "s_register_operand" "r")))]
+		 [(match_operand 2 "cc_register" "") (const_int 0)])
+		(match_operand:SI 3 "s_register_operand" "r")))]
   "TARGET_THUMB2"
-  "ite\\t%D1\;mov%D1\\t%0, #0\;and%d1\\t%0, %2, #1"
+  "#"   ; "and\\t%0, %3, #1\;it\\t%D1\;mov%D1\\t%0, #0"
+  "&& reload_completed"
+  [(set (match_dup 0)
+        (and:SI (match_dup 3) (const_int 1)))
+   (cond_exec (match_dup 4) (set (match_dup 0) (const_int 0)))]
+  {
+    enum machine_mode mode = GET_MODE (operands[2]);
+    enum rtx_code rc = GET_CODE (operands[1]);
+
+    if (mode == CCFPmode || mode == CCFPEmode)
+      rc = reverse_condition_maybe_unordered (rc);
+    else
+      rc = reverse_condition (rc);
+    operands[4] = gen_rtx_fmt_ee (rc, VOIDmode, operands[2], const0_rtx);
+  }
   [(set_attr "conds" "use")
-   (set_attr "length" "10")]
+   (set (attr "length") (if_then_else (match_test "arm_restrict_it")
+                                      (const_int 8)
+                                      (const_int 10)))]
 )
 
-(define_insn "*thumb2_ior_scc"
+(define_insn_and_split "*thumb2_ior_scc"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r")
-	(ior:SI (match_operator:SI 2 "arm_comparison_operator"
-		 [(match_operand 3 "cc_register" "") (const_int 0)])
-		(match_operand:SI 1 "s_register_operand" "0,?r")))]
+	(ior:SI (match_operator:SI 1 "arm_comparison_operator"
+		 [(match_operand 2 "cc_register" "") (const_int 0)])
+		(match_operand:SI 3 "s_register_operand" "0,?r")))]
   "TARGET_THUMB2"
   "@
-   it\\t%d2\;orr%d2\\t%0, %1, #1
-   ite\\t%D2\;mov%D2\\t%0, %1\;orr%d2\\t%0, %1, #1"
+   it\\t%d1\;orr%d1\\t%0, %3, #1
+   #"
+   ; alt 1: ite\\t%D1\;mov%D1\\t%0, %3\;orr%d1\\t%0, %3, #1
+   "&& reload_completed
+    && REGNO (operands [0]) != REGNO (operands[3])"
+   [(cond_exec (match_dup 5) (set (match_dup 0) (match_dup 3)))
+    (cond_exec (match_dup 4) (set (match_dup 0)
+                                  (ior:SI (match_dup 3) (const_int 1))))]
+  {
+    enum machine_mode mode = GET_MODE (operands[2]);
+    enum rtx_code rc = GET_CODE (operands[1]);
+
+    operands[4] = gen_rtx_fmt_ee (rc, VOIDmode, operands[2], const0_rtx);
+    if (mode == CCFPmode || mode == CCFPEmode)
+      rc = reverse_condition_maybe_unordered (rc);
+    else
+      rc = reverse_condition (rc);
+    operands[5] = gen_rtx_fmt_ee (rc, VOIDmode, operands[2], const0_rtx);
+  }
   [(set_attr "conds" "use")
    (set_attr "length" "6,10")]
 )
@@ -401,7 +601,7 @@
 
 (define_insn "*thumb2_cond_arith"
   [(set (match_operand:SI 0 "s_register_operand" "=r,r")
-        (match_operator:SI 5 "shiftable_operator" 
+        (match_operator:SI 5 "shiftable_operator"
 	 [(match_operator:SI 4 "arm_comparison_operator"
            [(match_operand:SI 2 "s_register_operand" "r,r")
 	    (match_operand:SI 3 "arm_rhs_operand" "rI,rI")])
@@ -459,25 +659,70 @@
    (set_attr "length" "10,14")]
 )
 
-(define_insn "*thumb2_negscc"
-  [(set (match_operand:SI 0 "s_register_operand" "=r")
+(define_insn_and_split "*thumb2_negscc"
+  [(set (match_operand:SI 0 "s_register_operand" "=Ts")
 	(neg:SI (match_operator 3 "arm_comparison_operator"
 		 [(match_operand:SI 1 "s_register_operand" "r")
 		  (match_operand:SI 2 "arm_rhs_operand" "rI")])))
    (clobber (reg:CC CC_REGNUM))]
   "TARGET_THUMB2"
-  "*
-  if (GET_CODE (operands[3]) == LT && operands[2] == const0_rtx)
-    return \"asr\\t%0, %1, #31\";
-
-  if (GET_CODE (operands[3]) == NE)
-    return \"subs\\t%0, %1, %2\;it\\tne\;mvnne\\t%0, #0\";
+  "#"
+  "&& reload_completed"
+  [(const_int 0)]
+  {
+    rtx cc_reg = gen_rtx_REG (CCmode, CC_REGNUM);
 
-  output_asm_insn (\"cmp\\t%1, %2\", operands);
-  output_asm_insn (\"ite\\t%D3\", operands);
-  output_asm_insn (\"mov%D3\\t%0, #0\", operands);
-  return \"mvn%d3\\t%0, #0\";
-  "
+    if (GET_CODE (operands[3]) == LT && operands[2] == const0_rtx)
+      {
+        /* Emit asr\\t%0, %1, #31 */
+        emit_insn (gen_rtx_SET (VOIDmode,
+                                operands[0],
+                                gen_rtx_ASHIFTRT (SImode,
+                                                  operands[1],
+                                                  GEN_INT (31))));
+        DONE;
+      }
+    else if (GET_CODE (operands[3]) == NE && !arm_restrict_it)
+      {
+        /* Emit subs\\t%0, %1, %2\;it\\tne\;mvnne\\t%0, #0 */
+        if (CONST_INT_P (operands[2]))
+          emit_insn (gen_cmpsi2_addneg (operands[0], operands[1], operands[2],
+                                        GEN_INT (- INTVAL (operands[2]))));
+        else
+          emit_insn (gen_subsi3_compare (operands[0], operands[1], operands[2]));
+
+        emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                      gen_rtx_NE (SImode,
+                                                  cc_reg,
+                                                  const0_rtx),
+                                      gen_rtx_SET (SImode,
+                                                   operands[0],
+                                                   GEN_INT (~0))));
+        DONE;
+      }
+    else
+      {
+       /* Emit:  cmp\\t%1, %2\;mvn\\t%0, #0\;it\\t%D3\;mov%D3\\t%0, #0\;*/
+       enum rtx_code rc = reverse_condition (GET_CODE (operands[3]));
+       enum machine_mode mode = SELECT_CC_MODE (rc, operands[1], operands[2]);
+       rtx tmp1 = gen_rtx_REG (mode, CC_REGNUM);
+
+       emit_insn (gen_rtx_SET (VOIDmode,
+                               cc_reg,
+                               gen_rtx_COMPARE (CCmode, operands[1], operands[2])));
+
+       emit_insn (gen_rtx_SET (VOIDmode, operands[0], GEN_INT (~0)));
+
+       emit_insn (gen_rtx_COND_EXEC (VOIDmode,
+                                     gen_rtx_fmt_ee (rc,
+                                                     VOIDmode,
+                                                     tmp1,
+                                                     const0_rtx),
+                                     gen_rtx_SET (VOIDmode, operands[0], const0_rtx)));
+       DONE;
+      }
+    FAIL;
+  }
   [(set_attr "conds" "clob")
    (set_attr "length" "14")]
 )
@@ -823,7 +1068,7 @@
   "mul%!\\t%0, %2, %0"
   [(set_attr "predicable" "yes")
    (set_attr "length" "2")
-   (set_attr "insn" "muls")])
+   (set_attr "type" "muls")])
 
 (define_insn "*thumb2_mulsi_short_compare0"
   [(set (reg:CC_NOOV CC_REGNUM)
@@ -836,7 +1081,7 @@
   "TARGET_THUMB2 && optimize_size"
   "muls\\t%0, %2, %0"
   [(set_attr "length" "2")
-   (set_attr "insn" "muls")])
+   (set_attr "type" "muls")])
 
 (define_insn "*thumb2_mulsi_short_compare0_scratch"
   [(set (reg:CC_NOOV CC_REGNUM)
@@ -848,7 +1093,7 @@
   "TARGET_THUMB2 && optimize_size"
   "muls\\t%0, %2, %0"
   [(set_attr "length" "2")
-   (set_attr "insn" "muls")])
+   (set_attr "type" "muls")])
 
 (define_insn "*thumb2_cbz"
   [(set (pc) (if_then_else
@@ -864,7 +1109,7 @@
   else
     return \"cmp\\t%0, #0\;beq\\t%l1\";
   "
-  [(set (attr "length") 
+  [(set (attr "length")
         (if_then_else
 	    (and (ge (minus (match_dup 1) (pc)) (const_int 2))
 	         (le (minus (match_dup 1) (pc)) (const_int 128))
@@ -887,7 +1132,7 @@
   else
     return \"cmp\\t%0, #0\;bne\\t%l1\";
   "
-  [(set (attr "length") 
+  [(set (attr "length")
         (if_then_else
 	    (and (ge (minus (match_dup 1) (pc)) (const_int 2))
 	         (le (minus (match_dup 1) (pc)) (const_int 128))
diff --git a/gcc/config/arm/uclinux-elf.h b/gcc/config/arm/uclinux-elf.h
index c1fe9f1..74d63df 100644
--- a/gcc/config/arm/uclinux-elf.h
+++ b/gcc/config/arm/uclinux-elf.h
@@ -65,7 +65,7 @@
 
 #undef LINK_GCC_C_SEQUENCE_SPEC
 #define LINK_GCC_C_SEQUENCE_SPEC \
-  "%{static:--start-group} %G %L %{static:--end-group}%{!static:%G}"
+  "%{static:--start-group} %G %L %{static:--end-group}%{!static:%G %L}"
 
 /* Use --as-needed -lgcc_s for eh support.  */
 #ifdef HAVE_LD_AS_NEEDED
diff --git a/gcc/config/arm/unspecs.md b/gcc/config/arm/unspecs.md
index 3985912..c43a6a6 100644
--- a/gcc/config/arm/unspecs.md
+++ b/gcc/config/arm/unspecs.md
@@ -83,6 +83,8 @@
                         ; FPSCR rounding mode and signal inexactness.
   UNSPEC_VRINTA         ; Represent a float to integral float rounding
                         ; towards nearest, ties away from zero.
+  UNSPEC_RRX            ; Rotate Right with Extend shifts register right
+                        ; by one place, with Carry flag shifted into bit[31].
 ])
 
 (define_c_enum "unspec" [
@@ -139,6 +141,10 @@
   VUNSPEC_ATOMIC_OP	; Represent an atomic operation.
   VUNSPEC_LL		; Represent a load-register-exclusive.
   VUNSPEC_SC		; Represent a store-register-exclusive.
+  VUNSPEC_LAX		; Represent a load-register-acquire-exclusive.
+  VUNSPEC_SLX		; Represent a store-register-release-exclusive.
+  VUNSPEC_LDA		; Represent a store-register-acquire.
+  VUNSPEC_STL		; Represent a store-register-release.
 ])
 
 ;; Enumerators for NEON unspecs.
diff --git a/gcc/config/arm/vfp.md b/gcc/config/arm/vfp.md
index 923624f..9ac887e 100644
--- a/gcc/config/arm/vfp.md
+++ b/gcc/config/arm/vfp.md
@@ -18,31 +18,6 @@
 ;; along with GCC; see the file COPYING3.  If not see
 ;; <http://www.gnu.org/licenses/>.  */
 
-;; The VFP "type" attributes differ from those used in the FPA model.
-;; fcpys	Single precision cpy.
-;; ffariths	Single precision abs, neg.
-;; ffarithd	Double precision abs, neg, cpy.
-;; fadds	Single precision add/sub.
-;; faddd	Double precision add/sub.
-;; fconsts	Single precision load immediate.
-;; fconstd	Double precision load immediate.
-;; fcmps	Single precision comparison.
-;; fcmpd	Double precision comparison.
-;; fmuls	Single precision multiply.
-;; fmuld	Double precision multiply.
-;; fmacs	Single precision multiply-accumulate.
-;; fmacd	Double precision multiply-accumulate.
-;; ffmas	Single precision fused multiply-accumulate.
-;; ffmad	Double precision fused multiply-accumulate.
-;; fdivs	Single precision sqrt or division.
-;; fdivd	Double precision sqrt or division.
-;; f_flag	fmstat operation
-;; f_load[sd]	Floating point load from memory.
-;; f_store[sd]	Floating point store to memory.
-;; f_2_r	Transfer vfp to arm reg.
-;; r_2_f	Transfer arm to vfp reg.
-;; f_cvt	Convert floating<->integral
-
 ;; SImode moves
 ;; ??? For now do not allow loading constants into vfp regs.  This causes
 ;; problems because small constants get converted into adds.
@@ -87,53 +62,60 @@
 
 ;; See thumb2.md:thumb2_movsi_insn for an explanation of the split
 ;; high/low register alternatives for loads and stores here.
+;; The l/Py alternative should come after r/I to ensure that the short variant
+;; is chosen with length 2 when the instruction is predicated for
+;; arm_restrict_it.
 (define_insn "*thumb2_movsi_vfp"
-  [(set (match_operand:SI 0 "nonimmediate_operand" "=rk,r,r,r, l,*hk,m, *m,*t, r,*t,*t,  *Uv")
-	(match_operand:SI 1 "general_operand"	   "rk, I,K,j,mi,*mi,l,*hk, r,*t,*t,*Uvi,*t"))]
+  [(set (match_operand:SI 0 "nonimmediate_operand" "=rk,r,l,r,r, l,*hk,m, *m,*t, r,*t,*t,  *Uv")
+	(match_operand:SI 1 "general_operand"	   "rk,I,Py,K,j,mi,*mi,l,*hk, r,*t,*t,*Uvi,*t"))]
   "TARGET_THUMB2 && TARGET_VFP && TARGET_HARD_FLOAT
    && (   s_register_operand (operands[0], SImode)
        || s_register_operand (operands[1], SImode))"
   "*
   switch (which_alternative)
     {
-    case 0: case 1:
-      return \"mov%?\\t%0, %1\";
+    case 0:
+    case 1:
     case 2:
-      return \"mvn%?\\t%0, #%B1\";
+      return \"mov%?\\t%0, %1\";
     case 3:
-      return \"movw%?\\t%0, %1\";
+      return \"mvn%?\\t%0, #%B1\";
     case 4:
+      return \"movw%?\\t%0, %1\";
     case 5:
-      return \"ldr%?\\t%0, %1\";
     case 6:
+      return \"ldr%?\\t%0, %1\";
     case 7:
-      return \"str%?\\t%1, %0\";
     case 8:
-      return \"fmsr%?\\t%0, %1\\t%@ int\";
+      return \"str%?\\t%1, %0\";
     case 9:
-      return \"fmrs%?\\t%0, %1\\t%@ int\";
+      return \"fmsr%?\\t%0, %1\\t%@ int\";
     case 10:
+      return \"fmrs%?\\t%0, %1\\t%@ int\";
+    case 11:
       return \"fcpys%?\\t%0, %1\\t%@ int\";
-    case 11: case 12:
+    case 12: case 13:
       return output_move_vfp (operands);
     default:
       gcc_unreachable ();
     }
   "
   [(set_attr "predicable" "yes")
-   (set_attr "type" "*,*,*,*,load1,load1,store1,store1,r_2_f,f_2_r,fcpys,f_loads,f_stores")
-   (set_attr "neon_type" "*,*,*,*,*,*,*,*,neon_mcr,neon_mrc,neon_vmov,*,*")
-   (set_attr "insn" "mov,mov,mvn,mov,*,*,*,*,*,*,*,*,*")
-   (set_attr "pool_range"     "*,*,*,*,1018,4094,*,*,*,*,*,1018,*")
-   (set_attr "neg_pool_range" "*,*,*,*,   0,   0,*,*,*,*,*,1008,*")]
+   (set_attr "predicable_short_it" "yes,no,yes,no,no,no,no,no,no,no,no,no,no,no")
+   (set_attr "type" "*,*,*,*,*,load1,load1,store1,store1,r_2_f,f_2_r,fcpys,f_loads,f_stores")
+   (set_attr "length" "2,4,2,4,4,4,4,4,4,4,4,4,4,4")
+   (set_attr "neon_type" "*,*,*,*,*,*,*,*,*,neon_mcr,neon_mrc,neon_vmov,*,*")
+   (set_attr "insn" "mov,mov,mov,mvn,mov,*,*,*,*,*,*,*,*,*")
+   (set_attr "pool_range"     "*,*,*,*,*,1018,4094,*,*,*,*,*,1018,*")
+   (set_attr "neg_pool_range" "*,*,*,*,*,   0,   0,*,*,*,*,*,1008,*")]
 )
 
 
 ;; DImode moves
 
 (define_insn "*movdi_vfp"
-  [(set (match_operand:DI 0 "nonimmediate_di_operand" "=r,r,r,r,r,r,m,w,r,w,w, Uv")
-       (match_operand:DI 1 "di_operand"              "r,rDa,Db,Dc,mi,mi,r,r,w,w,Uvi,w"))]
+  [(set (match_operand:DI 0 "nonimmediate_di_operand" "=r,r,r,r,q,q,m,w,r,w,w, Uv")
+       (match_operand:DI 1 "di_operand"              "r,rDa,Db,Dc,mi,mi,q,r,w,w,Uvi,w"))]
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP && arm_tune != cortexa8
    && (   register_operand (operands[0], DImode)
        || register_operand (operands[1], DImode))
@@ -412,6 +394,7 @@
     }
   "
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type"
      "r_2_f,f_2_r,fconsts,f_loads,f_stores,load1,store1,fcpys,*")
    (set_attr "neon_type" "neon_mcr,neon_mrc,*,*,*,*,*,neon_vmov,*")
@@ -420,7 +403,6 @@
    (set_attr "neg_pool_range" "*,*,*,1008,*,0,*,*,*")]
 )
 
-
 ;; DFmode moves
 
 (define_insn "*movdf_vfp"
@@ -550,7 +532,7 @@
 	    [(match_operand 4 "cc_register" "") (const_int 0)])
 	  (match_operand:SF 1 "s_register_operand" "0,t,t,0,?r,?r,0,t,t")
 	  (match_operand:SF 2 "s_register_operand" "t,0,t,?r,0,?r,t,0,t")))]
-  "TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_VFP"
+  "TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_VFP && !arm_restrict_it"
   "@
    it\\t%D3\;fcpys%D3\\t%0, %2
    it\\t%d3\;fcpys%d3\\t%0, %1
@@ -598,7 +580,7 @@
 	    [(match_operand 4 "cc_register" "") (const_int 0)])
 	  (match_operand:DF 1 "s_register_operand" "0,w,w,0,?r,?r,0,w,w")
 	  (match_operand:DF 2 "s_register_operand" "w,0,w,?r,0,?r,w,0,w")))]
-  "TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
+  "TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE && !arm_restrict_it"
   "@
    it\\t%D3\;fcpyd%D3\\t%P0, %P2
    it\\t%d3\;fcpyd%d3\\t%P0, %P1
@@ -624,6 +606,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fabss%?\\t%0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "ffariths")]
 )
 
@@ -633,6 +616,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fabsd%?\\t%P0, %P1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "ffarithd")]
 )
 
@@ -644,6 +628,7 @@
    fnegs%?\\t%0, %1
    eor%?\\t%0, %1, #-2147483648"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "ffariths")]
 )
 
@@ -689,6 +674,7 @@
     }
   "
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "length" "4,4,8")
    (set_attr "type" "ffarithd")]
 )
@@ -703,6 +689,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fadds%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fadds")]
 )
 
@@ -713,6 +700,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "faddd%?\\t%P0, %P1, %P2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "faddd")]
 )
 
@@ -724,6 +712,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fsubs%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fadds")]
 )
 
@@ -734,6 +723,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fsubd%?\\t%P0, %P1, %P2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "faddd")]
 )
 
@@ -747,6 +737,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fdivs%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fdivs")]
 )
 
@@ -757,6 +748,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fdivd%?\\t%P0, %P1, %P2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fdivd")]
 )
 
@@ -770,6 +762,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fmuls%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmuls")]
 )
 
@@ -780,6 +773,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fmuld%?\\t%P0, %P1, %P2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmuld")]
 )
 
@@ -790,6 +784,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fnmuls%?\\t%0, %1, %2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmuls")]
 )
 
@@ -800,6 +795,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fnmuld%?\\t%P0, %P1, %P2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmuld")]
 )
 
@@ -815,6 +811,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fmacs%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmacs")]
 )
 
@@ -826,6 +823,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fmacd%?\\t%P0, %P2, %P3"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmacd")]
 )
 
@@ -838,6 +836,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fmscs%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmacs")]
 )
 
@@ -849,6 +848,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fmscd%?\\t%P0, %P2, %P3"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmacd")]
 )
 
@@ -861,6 +861,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fnmacs%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmacs")]
 )
 
@@ -872,6 +873,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fnmacd%?\\t%P0, %P2, %P3"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmacd")]
 )
 
@@ -886,6 +888,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fnmscs%?\\t%0, %2, %3"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmacs")]
 )
 
@@ -898,6 +901,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fnmscd%?\\t%P0, %P2, %P3"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fmacd")]
 )
 
@@ -911,6 +915,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FMA"
   "vfma%?.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "ffma<vfp_type>")]
 )
 
@@ -923,6 +928,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FMA"
   "vfms%?.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "ffma<vfp_type>")]
 )
 
@@ -934,6 +940,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FMA"
   "vfnms%?.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "ffma<vfp_type>")]
 )
 
@@ -946,6 +953,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FMA"
   "vfnma%?.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "ffma<vfp_type>")]
 )
 
@@ -958,6 +966,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fcvtds%?\\t%P0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -967,6 +976,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fcvtsd%?\\t%0, %P1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -976,6 +986,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FP16"
   "vcvtb%?.f32.f16\\t%0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -985,6 +996,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FP16"
   "vcvtb%?.f16.f32\\t%0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -994,6 +1006,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "ftosizs%?\\t%0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -1003,6 +1016,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "ftosizd%?\\t%0, %P1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -1013,6 +1027,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "ftouizs%?\\t%0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -1022,6 +1037,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "ftouizd%?\\t%0, %P1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -1032,6 +1048,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fsitos%?\\t%0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -1041,6 +1058,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fsitod%?\\t%P0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -1051,6 +1069,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fuitos%?\\t%0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -1060,6 +1079,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fuitod%?\\t%P0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_cvt")]
 )
 
@@ -1072,6 +1092,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP"
   "fsqrts%?\\t%0, %1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fdivs")]
 )
 
@@ -1081,6 +1102,7 @@
   "TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP_DOUBLE"
   "fsqrtd%?\\t%P0, %P1"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fdivd")]
 )
 
@@ -1168,6 +1190,7 @@
    fcmps%?\\t%0, %1
    fcmpzs%?\\t%0"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fcmps")]
 )
 
@@ -1180,6 +1203,7 @@
    fcmpes%?\\t%0, %1
    fcmpezs%?\\t%0"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fcmps")]
 )
 
@@ -1192,6 +1216,7 @@
    fcmpd%?\\t%P0, %P1
    fcmpzd%?\\t%P0"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fcmpd")]
 )
 
@@ -1204,6 +1229,7 @@
    fcmped%?\\t%P0, %P1
    fcmpezd%?\\t%P0"
   [(set_attr "predicable" "yes")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "fcmpd")]
 )
 
@@ -1263,6 +1289,7 @@
   "TARGET_HARD_FLOAT && TARGET_FPU_ARMV8 <vfp_double_cond>"
   "vrint<vrint_variant>%?.<V_if_elem>\\t%<V_reg>0, %<V_reg>1"
   [(set_attr "predicable" "<vrint_predicable>")
+   (set_attr "predicable_short_it" "no")
    (set_attr "type" "f_rint<vfp_type>")]
 )
 
diff --git a/gcc/config/gnu-user.h b/gcc/config/gnu-user.h
index bcdf0e6..a924fce 100644
--- a/gcc/config/gnu-user.h
+++ b/gcc/config/gnu-user.h
@@ -73,10 +73,14 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
 #undef CPLUSPLUS_CPP_SPEC
 #define CPLUSPLUS_CPP_SPEC "-D_GNU_SOURCE %(cpp)"
 
-#define GNU_USER_TARGET_LIB_SPEC \
-  "%{pthread:-lpthread} \
-   %{shared:-lc} \
+#define GNU_USER_TARGET_LIB_SPEC_LESS_PTHREAD \
+   "%{shared:-lc} \
    %{!shared:%{mieee-fp:-lieee} %{profile:-lc_p}%{!profile:-lc}}"
+
+#define GNU_USER_TARGET_LIB_SPEC \
+  "%{pthread:-lpthread} "\
+  GNU_USER_TARGET_LIB_SPEC_LESS_PTHREAD
+
 #undef  LIB_SPEC
 #define LIB_SPEC GNU_USER_TARGET_LIB_SPEC
 
diff --git a/gcc/config/i386/gnu-user.h b/gcc/config/i386/gnu-user.h
index c93d975..2f0a4d7 100644
--- a/gcc/config/i386/gnu-user.h
+++ b/gcc/config/i386/gnu-user.h
@@ -67,7 +67,8 @@ along with GCC; see the file COPYING3.  If not see
 
 #undef  ASM_SPEC
 #define ASM_SPEC \
-  "--32 %{!mno-sse2avx:%{mavx:-msse2avx}} %{msse2avx:%{!mavx:-msse2avx}}"
+  "--32 %{!mno-sse2avx:%{mavx:-msse2avx}} %{msse2avx:%{!mavx:-msse2avx}} " \
+  LINUX_OR_ANDROID_CC ("", ANDROID_ASM_SPEC)
 
 #undef  SUBTARGET_EXTRA_SPECS
 #define SUBTARGET_EXTRA_SPECS \
diff --git a/gcc/config/i386/linux-common.h b/gcc/config/i386/linux-common.h
index 1e8bf6b..51e25b4 100644
--- a/gcc/config/i386/linux-common.h
+++ b/gcc/config/i386/linux-common.h
@@ -30,7 +30,14 @@ along with GCC; see the file COPYING3.  If not see
 #undef CC1_SPEC
 #define CC1_SPEC \
   LINUX_OR_ANDROID_CC (GNU_USER_TARGET_CC1_SPEC, \
-		       GNU_USER_TARGET_CC1_SPEC " " ANDROID_CC1_SPEC)
+                       GNU_USER_TARGET_CC1_SPEC \
+                       " -mstackrealign -msse3" \
+                       " -m32 -fno-short-enums" \
+                       " " \
+                       ANDROID_CC1_SPEC("-fPIC"))
+
+#define CC1PLUS_SPEC \
+  LINUX_OR_ANDROID_CC ("", ANDROID_CC1PLUS_SPEC)
 
 #undef	LINK_SPEC
 #define LINK_SPEC \
@@ -40,7 +47,7 @@ along with GCC; see the file COPYING3.  If not see
 #undef  LIB_SPEC
 #define LIB_SPEC \
   LINUX_OR_ANDROID_LD (GNU_USER_TARGET_LIB_SPEC, \
-		       GNU_USER_TARGET_LIB_SPEC " " ANDROID_LIB_SPEC)
+		       GNU_USER_TARGET_LIB_SPEC_LESS_PTHREAD " " ANDROID_LIB_SPEC)
 
 #undef  STARTFILE_SPEC
 #define STARTFILE_SPEC \
diff --git a/gcc/config/i386/pmm_malloc.h b/gcc/config/i386/pmm_malloc.h
index d64cb38..ee2d1a0 100644
--- a/gcc/config/i386/pmm_malloc.h
+++ b/gcc/config/i386/pmm_malloc.h
@@ -26,6 +26,7 @@
 
 #include <stdlib.h>
 
+#if !defined(__ANDROID__) || defined(HAVE_POSIX_MEMALIGN)
 /* We can't depend on <stdlib.h> since the prototype of posix_memalign
    may not be visible.  */
 #ifndef __cplusplus
@@ -33,6 +34,7 @@ extern int posix_memalign (void **, size_t, size_t);
 #else
 extern "C" int posix_memalign (void **, size_t, size_t) throw ();
 #endif
+#endif
 
 static __inline void *
 _mm_malloc (size_t size, size_t alignment)
@@ -42,10 +44,14 @@ _mm_malloc (size_t size, size_t alignment)
     return malloc (size);
   if (alignment == 2 || (sizeof (void *) == 8 && alignment == 4))
     alignment = sizeof (void *);
+#if !defined(__ANDROID__) || defined(HAVE_POSIX_MEMALIGN)
   if (posix_memalign (&ptr, alignment, size) == 0)
     return ptr;
   else
     return NULL;
+#else
+  return memalign(alignment, size);
+#endif
 }
 
 static __inline void
diff --git a/gcc/config/i386/t-cygming b/gcc/config/i386/t-cygming
index f615ad7..ba076a7 100644
--- a/gcc/config/i386/t-cygming
+++ b/gcc/config/i386/t-cygming
@@ -22,7 +22,7 @@ LIMITS_H_TEST = true
 
 winnt.o: $(srcdir)/config/i386/winnt.c $(CONFIG_H) $(SYSTEM_H) coretypes.h \
   $(TM_H) $(RTL_H) $(REGS_H) hard-reg-set.h output.h $(TREE_H) flags.h \
-  $(TM_P_H) $(HASHTAB_H) $(GGC_H) $(LTO_STREAMER_H)
+  $(TM_P_H) $(HASH_TABLE_H) $(GGC_H) $(LTO_STREAMER_H)
 	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) \
 	$(srcdir)/config/i386/winnt.c
 
diff --git a/gcc/config/i386/t-interix b/gcc/config/i386/t-interix
index 43443e7..4d7b598 100644
--- a/gcc/config/i386/t-interix
+++ b/gcc/config/i386/t-interix
@@ -18,7 +18,7 @@
 
 winnt.o: $(srcdir)/config/i386/winnt.c $(CONFIG_H) $(SYSTEM_H) coretypes.h \
   $(TM_H) $(RTL_H) $(REGS_H) hard-reg-set.h output.h $(TREE_H) flags.h \
-  $(TM_P_H) $(HASHTAB_H) $(GGC_H)
+  $(TM_P_H) $(HASH_TABLE_H) $(GGC_H)
 	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) \
 		$(srcdir)/config/i386/winnt.c
 
diff --git a/gcc/config/i386/winnt.c b/gcc/config/i386/winnt.c
index 7e7c155..f390252 100644
--- a/gcc/config/i386/winnt.c
+++ b/gcc/config/i386/winnt.c
@@ -30,7 +30,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "flags.h"
 #include "tm_p.h"
 #include "diagnostic-core.h"
-#include "hashtab.h"
+#include "hash-table.h"
 #include "langhooks.h"
 #include "ggc.h"
 #include "target.h"
@@ -449,7 +449,7 @@ i386_pe_reloc_rw_mask (void)
 unsigned int
 i386_pe_section_type_flags (tree decl, const char *name, int reloc)
 {
-  static htab_t htab;
+  static hash_table <pointer_hash <unsigned int> > htab;
   unsigned int flags;
   unsigned int **slot;
 
@@ -460,8 +460,8 @@ i386_pe_section_type_flags (tree decl, const char *name, int reloc)
   /* The names we put in the hashtable will always be the unique
      versions given to us by the stringtable, so we can just use
      their addresses as the keys.  */
-  if (!htab)
-    htab = htab_create (31, htab_hash_pointer, htab_eq_pointer, NULL);
+  if (!htab.is_created ())
+    htab.create (31);
 
   if (decl && TREE_CODE (decl) == FUNCTION_DECL)
     flags = SECTION_CODE;
@@ -480,7 +480,7 @@ i386_pe_section_type_flags (tree decl, const char *name, int reloc)
     flags |= SECTION_LINKONCE;
 
   /* See if we already have an entry for this section.  */
-  slot = (unsigned int **) htab_find_slot (htab, name, INSERT);
+  slot = htab.find_slot ((unsigned int *)name, INSERT);
   if (!*slot)
     {
       *slot = (unsigned int *) xmalloc (sizeof (unsigned int));
@@ -680,12 +680,29 @@ i386_pe_maybe_record_exported_symbol (tree decl, const char *name, int is_data)
 
 #ifdef CXX_WRAP_SPEC_LIST
 
+/* Hashtable helpers.  */
+
+struct wrapped_symbol_hasher : typed_noop_remove <char>
+{
+  typedef char value_type;
+  typedef char compare_type;
+  static inline hashval_t hash (const value_type *);
+  static inline bool equal (const value_type *, const compare_type *);
+  static inline void remove (value_type *);
+};
+
+inline hashval_t
+wrapped_symbol_hasher::hash (const value_type *v)
+{
+  return htab_hash_string (v);
+}
+
 /*  Hash table equality helper function.  */
 
-static int
-wrapper_strcmp (const void *x, const void *y)
+inline bool
+wrapped_symbol_hasher::equal (const value_type *x, const compare_type *y)
 {
-  return !strcmp ((const char *) x, (const char *) y);
+  return !strcmp (x, y);
 }
 
 /* Search for a function named TARGET in the list of library wrappers
@@ -699,7 +716,7 @@ static const char *
 i386_find_on_wrapper_list (const char *target)
 {
   static char first_time = 1;
-  static htab_t wrappers;
+  static hash_table <wrapped_symbol_hasher> wrappers;
 
   if (first_time)
     {
@@ -712,8 +729,7 @@ i386_find_on_wrapper_list (const char *target)
       char *bufptr;
       /* Breaks up the char array into separated strings
          strings and enter them into the hash table.  */
-      wrappers = htab_create_alloc (8, htab_hash_string, wrapper_strcmp,
-	0, xcalloc, free);
+      wrappers.create (8);
       for (bufptr = wrapper_list_buffer; *bufptr; ++bufptr)
 	{
 	  char *found = NULL;
@@ -726,12 +742,12 @@ i386_find_on_wrapper_list (const char *target)
 	  if (*bufptr)
 	    *bufptr = 0;
 	  if (found)
-	    *htab_find_slot (wrappers, found, INSERT) = found;
+	    *wrappers.find_slot (found, INSERT) = found;
 	}
       first_time = 0;
     }
 
-  return (const char *) htab_find (wrappers, target);
+  return wrappers.find (target);
 }
 
 #endif /* CXX_WRAP_SPEC_LIST */
diff --git a/gcc/config/ia64/ia64.c b/gcc/config/ia64/ia64.c
index 28e4483..9ad5d15 100644
--- a/gcc/config/ia64/ia64.c
+++ b/gcc/config/ia64/ia64.c
@@ -47,7 +47,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "target-def.h"
 #include "common/common-target.h"
 #include "tm_p.h"
-#include "hashtab.h"
+#include "hash-table.h"
 #include "langhooks.h"
 #include "gimple.h"
 #include "intl.h"
@@ -257,8 +257,6 @@ static struct bundle_state *get_free_bundle_state (void);
 static void free_bundle_state (struct bundle_state *);
 static void initiate_bundle_states (void);
 static void finish_bundle_states (void);
-static unsigned bundle_state_hash (const void *);
-static int bundle_state_eq_p (const void *, const void *);
 static int insert_bundle_state (struct bundle_state *);
 static void initiate_bundle_state_table (void);
 static void finish_bundle_state_table (void);
@@ -8531,18 +8529,21 @@ finish_bundle_states (void)
     }
 }
 
-/* Hash table of the bundle states.  The key is dfa_state and insn_num
-   of the bundle states.  */
+/* Hashtable helpers.  */
 
-static htab_t bundle_state_table;
+struct bundle_state_hasher : typed_noop_remove <bundle_state>
+{
+  typedef bundle_state value_type;
+  typedef bundle_state compare_type;
+  static inline hashval_t hash (const value_type *);
+  static inline bool equal (const value_type *, const compare_type *);
+};
 
 /* The function returns hash of BUNDLE_STATE.  */
 
-static unsigned
-bundle_state_hash (const void *bundle_state)
+inline hashval_t
+bundle_state_hasher::hash (const value_type *state)
 {
-  const struct bundle_state *const state
-    = (const struct bundle_state *) bundle_state;
   unsigned result, i;
 
   for (result = i = 0; i < dfa_state_size; i++)
@@ -8553,19 +8554,20 @@ bundle_state_hash (const void *bundle_state)
 
 /* The function returns nonzero if the bundle state keys are equal.  */
 
-static int
-bundle_state_eq_p (const void *bundle_state_1, const void *bundle_state_2)
+inline bool
+bundle_state_hasher::equal (const value_type *state1,
+			    const compare_type *state2)
 {
-  const struct bundle_state *const state1
-    = (const struct bundle_state *) bundle_state_1;
-  const struct bundle_state *const state2
-    = (const struct bundle_state *) bundle_state_2;
-
   return (state1->insn_num == state2->insn_num
 	  && memcmp (state1->dfa_state, state2->dfa_state,
 		     dfa_state_size) == 0);
 }
 
+/* Hash table of the bundle states.  The key is dfa_state and insn_num
+   of the bundle states.  */
+
+static hash_table <bundle_state_hasher> bundle_state_table;
+
 /* The function inserts the BUNDLE_STATE into the hash table.  The
    function returns nonzero if the bundle has been inserted into the
    table.  The table contains the best bundle state with given key.  */
@@ -8573,39 +8575,35 @@ bundle_state_eq_p (const void *bundle_state_1, const void *bundle_state_2)
 static int
 insert_bundle_state (struct bundle_state *bundle_state)
 {
-  void **entry_ptr;
+  struct bundle_state **entry_ptr;
 
-  entry_ptr = htab_find_slot (bundle_state_table, bundle_state, INSERT);
+  entry_ptr = bundle_state_table.find_slot (bundle_state, INSERT);
   if (*entry_ptr == NULL)
     {
       bundle_state->next = index_to_bundle_states [bundle_state->insn_num];
       index_to_bundle_states [bundle_state->insn_num] = bundle_state;
-      *entry_ptr = (void *) bundle_state;
+      *entry_ptr = bundle_state;
       return TRUE;
     }
-  else if (bundle_state->cost < ((struct bundle_state *) *entry_ptr)->cost
-	   || (bundle_state->cost == ((struct bundle_state *) *entry_ptr)->cost
-	       && (((struct bundle_state *)*entry_ptr)->accumulated_insns_num
+  else if (bundle_state->cost < (*entry_ptr)->cost
+	   || (bundle_state->cost == (*entry_ptr)->cost
+	       && ((*entry_ptr)->accumulated_insns_num
 		   > bundle_state->accumulated_insns_num
-		   || (((struct bundle_state *)
-			*entry_ptr)->accumulated_insns_num
+		   || ((*entry_ptr)->accumulated_insns_num
 		       == bundle_state->accumulated_insns_num
-		       && (((struct bundle_state *)
-			    *entry_ptr)->branch_deviation
+		       && ((*entry_ptr)->branch_deviation
 			   > bundle_state->branch_deviation
-			   || (((struct bundle_state *)
-				*entry_ptr)->branch_deviation
+			   || ((*entry_ptr)->branch_deviation
 			       == bundle_state->branch_deviation
-			       && ((struct bundle_state *)
-				   *entry_ptr)->middle_bundle_stops
+			       && (*entry_ptr)->middle_bundle_stops
 			       > bundle_state->middle_bundle_stops))))))
 
     {
       struct bundle_state temp;
 
-      temp = *(struct bundle_state *) *entry_ptr;
-      *(struct bundle_state *) *entry_ptr = *bundle_state;
-      ((struct bundle_state *) *entry_ptr)->next = temp.next;
+      temp = **entry_ptr;
+      **entry_ptr = *bundle_state;
+      (*entry_ptr)->next = temp.next;
       *bundle_state = temp;
     }
   return FALSE;
@@ -8616,8 +8614,7 @@ insert_bundle_state (struct bundle_state *bundle_state)
 static void
 initiate_bundle_state_table (void)
 {
-  bundle_state_table = htab_create (50, bundle_state_hash, bundle_state_eq_p,
-				    (htab_del) 0);
+  bundle_state_table.create (50);
 }
 
 /* Finish work with the hash table.  */
@@ -8625,7 +8622,7 @@ initiate_bundle_state_table (void)
 static void
 finish_bundle_state_table (void)
 {
-  htab_delete (bundle_state_table);
+  bundle_state_table.dispose ();
 }
 
 
diff --git a/gcc/config/ia64/t-ia64 b/gcc/config/ia64/t-ia64
index 5c3ac64..b009cdf 100644
--- a/gcc/config/ia64/t-ia64
+++ b/gcc/config/ia64/t-ia64
@@ -24,4 +24,5 @@ ia64-c.o: $(srcdir)/config/ia64/ia64-c.c $(CONFIG_H) $(SYSTEM_H) \
 # genattrtab generates very long string literals.
 insn-attrtab.o-warn = -Wno-error
 
-ia64.o: debug.h $(PARAMS_H) sel-sched.h reload.h $(OPTS_H) dumpfile.h
+ia64.o: $(srcdir)/config/ia64/ia64.c debug.h $(PARAMS_H) sel-sched.h reload.h \
+	$(OPTS_H) dumpfile.h $(HASH_TABLE_H)
diff --git a/gcc/config/linux-android.h b/gcc/config/linux-android.h
index 2c87c84..87957e3 100644
--- a/gcc/config/linux-android.h
+++ b/gcc/config/linux-android.h
@@ -38,18 +38,22 @@
   "%{" NOANDROID "|tno-android-ld:" LINUX_SPEC ";:" ANDROID_SPEC "}"
 
 #define ANDROID_LINK_SPEC \
-  "%{shared: -Bsymbolic}"
+  "%{shared: -Bsymbolic} -z noexecstack -z relro -z now"
 
-#define ANDROID_CC1_SPEC						\
+#define ANDROID_CC1_SPEC(ANDROID_PIC_DEFAULT)				\
   "%{!mglibc:%{!muclibc:%{!mbionic: -mbionic}}} "			\
-  "%{!fno-pic:%{!fno-PIC:%{!fpic:%{!fPIC: -fPIC}}}}"
+  "%{!fno-pic:%{!fno-PIC:%{!fpic:%{!fPIC: " ANDROID_PIC_DEFAULT "}}}}"
 
 #define ANDROID_CC1PLUS_SPEC						\
   "%{!fexceptions:%{!fno-exceptions: -fno-exceptions}} "		\
   "%{!frtti:%{!fno-rtti: -fno-rtti}}"
 
+#define ANDROID_ASM_SPEC \
+  "--noexecstack"
+
 #define ANDROID_LIB_SPEC \
-  "%{!static: -ldl}"
+  "%{!static: -ldl} \
+  %{pthread: -lc}"
 
 #define ANDROID_STARTFILE_SPEC						\
   "%{shared: crtbegin_so%O%s;:"						\
diff --git a/gcc/config/mips/gnu-user.h b/gcc/config/mips/gnu-user.h
index aa3cc37..2b4695f 100644
--- a/gcc/config/mips/gnu-user.h
+++ b/gcc/config/mips/gnu-user.h
@@ -36,6 +36,7 @@ along with GCC; see the file COPYING3.  If not see
     /* The GNU C++ standard library requires this.  */		\
     if (c_dialect_cxx ())					\
       builtin_define ("_GNU_SOURCE");				\
+    ANDROID_TARGET_OS_CPP_BUILTINS();				\
   } while (0)
 
 #undef SUBTARGET_CPP_SPEC
@@ -57,6 +58,7 @@ along with GCC; see the file COPYING3.  If not see
 #define GNU_USER_TARGET_LINK_SPEC \
  "%(endian_spec) \
   %{shared:-shared} \
+  %{!EB:%{!meb:-m elf32ltsmip}} %{EB|meb:-m elf32btsmip} \
   %{!shared: \
     %{!static: \
       %{rdynamic:-export-dynamic} \
@@ -67,7 +69,8 @@ along with GCC; see the file COPYING3.  If not see
 
 #undef SUBTARGET_ASM_SPEC
 #define SUBTARGET_ASM_SPEC \
-  "%{!mno-abicalls:%{mplt:-call_nonpic;:-KPIC}}"
+  "%{!mno-abicalls:%{mplt:-call_nonpic;:-KPIC}} " \
+  LINUX_OR_ANDROID_CC ("", ANDROID_ASM_SPEC)
 
 /* The MIPS assembler has different syntax for .set. We set it to
    .dummy to trap any errors.  */
@@ -116,7 +119,7 @@ extern const char *host_detect_local_cpu (int argc, const char **argv);
 #endif
 
 #define LINUX_DRIVER_SELF_SPECS \
-  NO_SHARED_SPECS							\
+  LINUX_OR_ANDROID_CC(NO_SHARED_SPECS, "")                              \
   MARCH_MTUNE_NATIVE_SPECS,						\
   /* -mplt has no effect without -mno-shared.  Simplify later		\
      specs handling by removing a redundant option.  */			\
diff --git a/gcc/config/mips/linux-common.h b/gcc/config/mips/linux-common.h
index ca4ea07..8b9e4b0 100644
--- a/gcc/config/mips/linux-common.h
+++ b/gcc/config/mips/linux-common.h
@@ -35,7 +35,7 @@ along with GCC; see the file COPYING3.  If not see
 #undef  SUBTARGET_CC1_SPEC
 #define SUBTARGET_CC1_SPEC						\
   LINUX_OR_ANDROID_CC (GNU_USER_TARGET_CC1_SPEC,			\
-		       GNU_USER_TARGET_CC1_SPEC " " ANDROID_CC1_SPEC)
+		       GNU_USER_TARGET_CC1_SPEC " " ANDROID_CC1_SPEC("-fpic"))
 
 #undef  CC1PLUS_SPEC
 #define CC1PLUS_SPEC							\
@@ -44,7 +44,7 @@ along with GCC; see the file COPYING3.  If not see
 #undef  LIB_SPEC
 #define LIB_SPEC							\
   LINUX_OR_ANDROID_LD (GNU_USER_TARGET_LIB_SPEC,			\
-		       GNU_USER_TARGET_LIB_SPEC " " ANDROID_LIB_SPEC)
+		       GNU_USER_TARGET_LIB_SPEC_LESS_PTHREAD " " ANDROID_LIB_SPEC)
 
 #undef  STARTFILE_SPEC
 #define STARTFILE_SPEC							\
diff --git a/gcc/config/mips/mips.c b/gcc/config/mips/mips.c
index 252e828..25adea6 100644
--- a/gcc/config/mips/mips.c
+++ b/gcc/config/mips/mips.c
@@ -43,7 +43,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "tm_p.h"
 #include "ggc.h"
 #include "gstab.h"
-#include "hashtab.h"
+#include "hash-table.h"
 #include "debug.h"
 #include "target.h"
 #include "target-def.h"
@@ -15589,30 +15589,43 @@ mips_hash_base (rtx base)
   return hash_rtx (base, GET_MODE (base), &do_not_record_p, NULL, false);
 }
 
+/* Hashtable helpers.  */
+
+struct mips_lo_sum_offset_hasher : typed_free_remove <mips_lo_sum_offset>
+{
+  typedef mips_lo_sum_offset value_type;
+  typedef rtx_def compare_type;
+  static inline hashval_t hash (const value_type *);
+  static inline bool equal (const value_type *, const compare_type *);
+};
+
 /* Hash-table callbacks for mips_lo_sum_offsets.  */
 
-static hashval_t
-mips_lo_sum_offset_hash (const void *entry)
+inline hashval_t
+mips_lo_sum_offset_hasher::hash (const value_type *entry)
 {
-  return mips_hash_base (((const struct mips_lo_sum_offset *) entry)->base);
+  return mips_hash_base (entry->base);
 }
 
-static int
-mips_lo_sum_offset_eq (const void *entry, const void *value)
+inline bool
+mips_lo_sum_offset_hasher::equal (const value_type *entry,
+				  const compare_type *value)
 {
-  return rtx_equal_p (((const struct mips_lo_sum_offset *) entry)->base,
-		      (const_rtx) value);
+  return rtx_equal_p (entry->base, value);
 }
 
+typedef hash_table <mips_lo_sum_offset_hasher> mips_offset_table;
+
 /* Look up symbolic constant X in HTAB, which is a hash table of
    mips_lo_sum_offsets.  If OPTION is NO_INSERT, return true if X can be
    paired with a recorded LO_SUM, otherwise record X in the table.  */
 
 static bool
-mips_lo_sum_offset_lookup (htab_t htab, rtx x, enum insert_option option)
+mips_lo_sum_offset_lookup (mips_offset_table htab, rtx x,
+			   enum insert_option option)
 {
   rtx base, offset;
-  void **slot;
+  mips_lo_sum_offset **slot;
   struct mips_lo_sum_offset *entry;
 
   /* Split X into a base and offset.  */
@@ -15621,7 +15634,7 @@ mips_lo_sum_offset_lookup (htab_t htab, rtx x, enum insert_option option)
     base = UNSPEC_ADDRESS (base);
 
   /* Look up the base in the hash table.  */
-  slot = htab_find_slot_with_hash (htab, base, mips_hash_base (base), option);
+  slot = htab.find_slot_with_hash (base, mips_hash_base (base), option);
   if (slot == NULL)
     return false;
 
@@ -15651,7 +15664,8 @@ static int
 mips_record_lo_sum (rtx *loc, void *data)
 {
   if (GET_CODE (*loc) == LO_SUM)
-    mips_lo_sum_offset_lookup ((htab_t) data, XEXP (*loc, 1), INSERT);
+    mips_lo_sum_offset_lookup (*(mips_offset_table*) data,
+			       XEXP (*loc, 1), INSERT);
   return 0;
 }
 
@@ -15660,7 +15674,7 @@ mips_record_lo_sum (rtx *loc, void *data)
    LO_SUMs in the current function.  */
 
 static bool
-mips_orphaned_high_part_p (htab_t htab, rtx insn)
+mips_orphaned_high_part_p (mips_offset_table htab, rtx insn)
 {
   enum mips_symbol_type type;
   rtx x, set;
@@ -15768,7 +15782,7 @@ mips_reorg_process_insns (void)
 {
   rtx insn, last_insn, subinsn, next_insn, lo_reg, delayed_reg;
   int hilo_delay;
-  htab_t htab;
+  mips_offset_table htab;
 
   /* Force all instructions to be split into their final form.  */
   split_all_insns_noflow ();
@@ -15805,14 +15819,13 @@ mips_reorg_process_insns (void)
   if (TARGET_FIX_VR4130 && !ISA_HAS_MACCHI)
     cfun->machine->all_noreorder_p = false;
 
-  htab = htab_create (37, mips_lo_sum_offset_hash,
-		      mips_lo_sum_offset_eq, free);
+  htab.create (37);
 
   /* Make a first pass over the instructions, recording all the LO_SUMs.  */
   for (insn = get_insns (); insn != 0; insn = NEXT_INSN (insn))
     FOR_EACH_SUBINSN (subinsn, insn)
       if (USEFUL_INSN_P (subinsn))
-	for_each_rtx (&PATTERN (subinsn), mips_record_lo_sum, htab);
+	for_each_rtx (&PATTERN (subinsn), mips_record_lo_sum, &htab);
 
   last_insn = 0;
   hilo_delay = 2;
@@ -15869,7 +15882,7 @@ mips_reorg_process_insns (void)
 	}
     }
 
-  htab_delete (htab);
+  htab.dispose ();
 }
 
 /* Return true if the function has a long branch instruction.  */
diff --git a/gcc/config/mips/mips.h b/gcc/config/mips/mips.h
index 0acce14..798a3cc 100644
--- a/gcc/config/mips/mips.h
+++ b/gcc/config/mips/mips.h
@@ -855,7 +855,7 @@ struct mips_cpu_info {
    FP madd and msub instructions, and the FP recip and recip sqrt
    instructions.  */
 #define ISA_HAS_FP4		((ISA_MIPS4				\
-				  || (ISA_MIPS32R2 && TARGET_FLOAT64)   \
+				  || ISA_MIPS32R2			\
 				  || ISA_MIPS64				\
 				  || ISA_MIPS64R2)			\
 				 && !TARGET_MIPS16)
@@ -886,10 +886,7 @@ struct mips_cpu_info {
 /* ISA has floating-point nmadd and nmsub instructions
    'd = -((a * b) [+-] c)'.  */
 #define ISA_HAS_NMADD4_NMSUB4(MODE)					\
-				((ISA_MIPS4				\
-				  || (ISA_MIPS32R2 && (MODE) == V2SFmode) \
-				  || ISA_MIPS64				\
-				  || ISA_MIPS64R2)			\
+				(ISA_HAS_FP4				\
 				 && (!TARGET_MIPS5400 || TARGET_MAD)	\
 				 && !TARGET_MIPS16)
 
diff --git a/gcc/config/mips/mips.md b/gcc/config/mips/mips.md
index 7aa461d..3ca9d76 100644
--- a/gcc/config/mips/mips.md
+++ b/gcc/config/mips/mips.md
@@ -855,12 +855,10 @@
   [(SF "!ISA_MIPS1") (DF "!ISA_MIPS1") (V2SF "TARGET_SB1")])
 
 ;; This attribute gives the conditions under which RECIP.fmt and RSQRT.fmt
-;; instructions can be used.  The MIPS32 and MIPS64 ISAs say that RECIP.D
-;; and RSQRT.D are unpredictable when doubles are stored in pairs of FPRs,
-;; so for safety's sake, we apply this restriction to all targets.
+;; instructions can be used.
 (define_mode_attr recip_condition
   [(SF "ISA_HAS_FP4")
-   (DF "ISA_HAS_FP4 && TARGET_FLOAT64")
+   (DF "ISA_HAS_FP4")
    (V2SF "TARGET_SB1")])
 
 ;; This code iterator allows signed and unsigned widening multiplications
diff --git a/gcc/config/mips/t-linux-android b/gcc/config/mips/t-linux-android
new file mode 100644
index 0000000..298cad9
--- /dev/null
+++ b/gcc/config/mips/t-linux-android
@@ -0,0 +1,3 @@
+MULTILIB_OPTIONS = mips32r2
+MULTILIB_DIRNAMES = mips-r2
+MULTILIB_EXCLUSIONS :=
diff --git a/gcc/config/sol2.c b/gcc/config/sol2.c
index 33c8c3d..95c7e0f 100644
--- a/gcc/config/sol2.c
+++ b/gcc/config/sol2.c
@@ -29,7 +29,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "tm_p.h"
 #include "diagnostic-core.h"
 #include "ggc.h"
-#include "hashtab.h"
+#include "hash-table.h"
 
 tree solaris_pending_aligns, solaris_pending_inits, solaris_pending_finis;
 
@@ -157,10 +157,6 @@ solaris_assemble_visibility (tree decl, int vis ATTRIBUTE_UNUSED)
 #endif
 }
 
-/* Hash table of group signature symbols.  */
-
-static htab_t solaris_comdat_htab;
-
 /* Group section information entry stored in solaris_comdat_htab.  */
 
 typedef struct comdat_entry
@@ -171,25 +167,34 @@ typedef struct comdat_entry
   const char *sig;
 } comdat_entry;
 
-/* Helper routines for maintaining solaris_comdat_htab.  */
+/* Helpers for maintaining solaris_comdat_htab.  */
 
-static hashval_t
-comdat_hash (const void *p)
+struct comdat_entry_hasher : typed_noop_remove <comdat_entry>
+{
+  typedef comdat_entry value_type;
+  typedef comdat_entry compare_type;
+  static inline hashval_t hash (const value_type *);
+  static inline bool equal (const value_type *, const compare_type *);
+  static inline void remove (value_type *);
+};
+
+inline hashval_t
+comdat_entry_hasher::hash (const value_type *entry)
 {
-  const comdat_entry *entry = (const comdat_entry *) p;
-
   return htab_hash_string (entry->sig);
 }
 
-static int
-comdat_eq (const void *p1, const void *p2)
+inline bool
+comdat_entry_hasher::equal (const value_type *entry1,
+			    const compare_type *entry2)
 {
-  const comdat_entry *entry1 = (const comdat_entry *) p1;
-  const comdat_entry *entry2 = (const comdat_entry *) p2;
-
   return strcmp (entry1->sig, entry2->sig) == 0;
 }
 
+/* Hash table of group signature symbols.  */
+
+static hash_table <comdat_entry_hasher> solaris_comdat_htab;
+
 /* Output assembly to switch to COMDAT group section NAME with attributes
    FLAGS and group signature symbol DECL, using Sun as syntax.  */
 
@@ -229,12 +234,11 @@ solaris_elf_asm_comdat_section (const char *name, unsigned int flags, tree decl)
      identify the missing ones without changing the affected frontents,
      remember the signature symbols and emit those not marked
      TREE_SYMBOL_REFERENCED in solaris_file_end.  */
-  if (solaris_comdat_htab == NULL)
-    solaris_comdat_htab = htab_create_alloc (37, comdat_hash, comdat_eq, NULL,
-					     xcalloc, free);
+  if (!solaris_comdat_htab.is_created ())
+    solaris_comdat_htab.create (37);
 
   entry.sig = signature;
-  slot = (comdat_entry **) htab_find_slot (solaris_comdat_htab, &entry, INSERT);
+  slot = solaris_comdat_htab.find_slot (&entry, INSERT);
 
   if (*slot == NULL)
     {
@@ -250,10 +254,11 @@ solaris_elf_asm_comdat_section (const char *name, unsigned int flags, tree decl)
 
 /* Define unreferenced COMDAT group signature symbol corresponding to SLOT.  */
 
-static int
-solaris_define_comdat_signature (void **slot, void *aux ATTRIBUTE_UNUSED)
+int
+solaris_define_comdat_signature (comdat_entry **slot,
+				 void *aux ATTRIBUTE_UNUSED)
 {
-  comdat_entry *entry = *(comdat_entry **) slot;
+  comdat_entry *entry = *slot;
   tree decl = entry->decl;
 
   if (TREE_CODE (decl) != IDENTIFIER_NODE)
@@ -277,10 +282,10 @@ solaris_define_comdat_signature (void **slot, void *aux ATTRIBUTE_UNUSED)
 void
 solaris_file_end (void)
 {
-  if (solaris_comdat_htab == NULL)
+  if (!solaris_comdat_htab.is_created ())
     return;
 
-  htab_traverse (solaris_comdat_htab, solaris_define_comdat_signature, NULL);
+  solaris_comdat_htab.traverse <void *, solaris_define_comdat_signature> (NULL);
 }
 
 void
diff --git a/gcc/config/t-sol2 b/gcc/config/t-sol2
index 25b8250..142de89 100644
--- a/gcc/config/t-sol2
+++ b/gcc/config/t-sol2
@@ -34,5 +34,5 @@ sol2-stubs.o: $(srcdir)/config/sol2-stubs.c $(CONFIG_H) $(SYSTEM_H) coretypes.h
 
 # Solaris-specific attributes
 sol2.o: $(srcdir)/config/sol2.c $(CONFIG_H) $(SYSTEM_H) coretypes.h \
-  tree.h output.h $(TM_H) $(TARGET_H) $(TM_P_H) $(GGC_H)
+  tree.h output.h $(TM_H) $(TARGET_H) $(TM_P_H) $(GGC_H) $(HASH_TABLE_H)
 	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) $<
diff --git a/gcc/configure b/gcc/configure
index b9e8a8f..827c2f3 100755
--- a/gcc/configure
+++ b/gcc/configure
@@ -21629,9 +21629,11 @@ if test -f $gcc_cv_binutils_srcdir/configure.in \
 	gcc_cv_readelf=../binutils/readelf$build_exeext
 elif test -x readelf$build_exeext; then
 	gcc_cv_readelf=./readelf$build_exeext
+elif ( set dummy $READELF_FOR_TARGET; test -x $2 ); then
+        gcc_cv_readelf="$READELF_FOR_TARGET"
 else
-        # Extract the first word of "readelf", so it can be a program name with args.
-set dummy readelf; ac_word=$2
+        # Extract the first word of "$READELF_FOR_TARGET", so it can be a program name with args.
+set dummy $READELF_FOR_TARGET; ac_word=$2
 { $as_echo "$as_me:${as_lineno-$LINENO}: checking for $ac_word" >&5
 $as_echo_n "checking for $ac_word... " >&6; }
 if test "${ac_cv_path_gcc_cv_readelf+set}" = set; then :
diff --git a/gcc/configure.ac b/gcc/configure.ac
index 8e9626c..1a39e27 100644
--- a/gcc/configure.ac
+++ b/gcc/configure.ac
@@ -2171,8 +2171,10 @@ if test -f $gcc_cv_binutils_srcdir/configure.in \
 	gcc_cv_readelf=../binutils/readelf$build_exeext
 elif test -x readelf$build_exeext; then
 	gcc_cv_readelf=./readelf$build_exeext
+elif ( set dummy $READELF_FOR_TARGET; test -x $[2] ); then
+        gcc_cv_readelf="$READELF_FOR_TARGET"
 else
-        AC_PATH_PROG(gcc_cv_readelf, readelf)
+        AC_PATH_PROG(gcc_cv_readelf, $READELF_FOR_TARGET)
 fi])
 
 AC_MSG_CHECKING(what readelf to use)
diff --git a/gcc/cp/ChangeLog.cfx b/gcc/cp/ChangeLog.cfx
new file mode 100644
index 0000000..2097e93
--- /dev/null
+++ b/gcc/cp/ChangeLog.cfx
@@ -0,0 +1,6 @@
+2013-04-12  Jakub Jelinek  <jakub@redhat.com>
+
+        * error.c (cp_print_error_function,
+        print_instantiation_partial_context_line,
+        maybe_print_constexpr_context): Colorize locus strings.
+
diff --git a/gcc/cp/error.c b/gcc/cp/error.c
index 35ea0df..a3525874 100644
--- a/gcc/cp/error.c
+++ b/gcc/cp/error.c
@@ -3010,14 +3010,14 @@ cp_print_error_function (diagnostic_context *context,
 		    {
 		      if (context->show_column && s.column != 0)
 			pp_printf (context->printer,
-				   _("    inlined from %qs at %s:%d:%d"),
+				   _("    inlined from %qs at %r%s:%d:%d%R"),
 				   cxx_printable_name_translate (fndecl, 2),
-				   s.file, s.line, s.column);
+				   "locus", s.file, s.line, s.column);
 		      else
 			pp_printf (context->printer,
-				   _("    inlined from %qs at %s:%d"),
+				   _("    inlined from %qs at %r%s:%d%R"),
 				   cxx_printable_name_translate (fndecl, 2),
-				   s.file, s.line);
+				   "locus", s.file, s.line);
 
 		    }
 		  else
@@ -3099,11 +3099,11 @@ print_instantiation_partial_context_line (diagnostic_context *context,
   xloc = expand_location (loc);
 
   if (context->show_column)
-    pp_verbatim (context->printer, _("%s:%d:%d:   "),
-		 xloc.file, xloc.line, xloc.column);
+    pp_verbatim (context->printer, _("%r%s:%d:%d:%R   "),
+		 "locus", xloc.file, xloc.line, xloc.column);
   else
-    pp_verbatim (context->printer, _("%s:%d:   "),
-		 xloc.file, xloc.line);
+    pp_verbatim (context->printer, _("%r%s:%d:%R   "),
+		 "locus", xloc.file, xloc.line);
 
   if (t != NULL)
     {
@@ -3177,14 +3177,16 @@ print_instantiation_partial_context (diagnostic_context *context,
 	  xloc = expand_location (loc);
 	  if (context->show_column)
 	    pp_verbatim (context->printer,
-			 _("%s:%d:%d:   [ skipping %d instantiation contexts, "
-			   "use -ftemplate-backtrace-limit=0 to disable ]\n"),
-			 xloc.file, xloc.line, xloc.column, skip);
+			 _("%r%s:%d:%d:%R   [ skipping %d instantiation "
+			   "contexts, use -ftemplate-backtrace-limit=0 to "
+			   "disable ]\n"),
+			 "locus", xloc.file, xloc.line, xloc.column, skip);
 	  else
 	    pp_verbatim (context->printer,
-			 _("%s:%d:   [ skipping %d instantiation contexts, "
-			   "use -ftemplate-backtrace-limit=0 to disable ]\n"),
-			 xloc.file, xloc.line, skip);
+			 _("%r%s:%d:%R   [ skipping %d instantiation "
+			   "contexts, use -ftemplate-backtrace-limit=0 to "
+			   "disable ]\n"),
+			 "locus", xloc.file, xloc.line, skip);
 	  
 	  do {
 	    loc = t->locus;
@@ -3246,12 +3248,12 @@ maybe_print_constexpr_context (diagnostic_context *context)
       const char *s = expr_as_string (t, 0);
       if (context->show_column)
 	pp_verbatim (context->printer,
-		     _("%s:%d:%d:   in constexpr expansion of %qs"),
-		     xloc.file, xloc.line, xloc.column, s);
+		     _("%r%s:%d:%d:%R   in constexpr expansion of %qs"),
+		     "locus", xloc.file, xloc.line, xloc.column, s);
       else
 	pp_verbatim (context->printer,
-		     _("%s:%d:   in constexpr expansion of %qs"),
-		     xloc.file, xloc.line, s);
+		     _("%r%s:%d:%R   in constexpr expansion of %qs"),
+		     "locus", xloc.file, xloc.line, s);
       pp_base_newline (context->printer);
     }
 }
diff --git a/gcc/cp/mangle.c b/gcc/cp/mangle.c
index 10c2e2b..4a230d6 100644
--- a/gcc/cp/mangle.c
+++ b/gcc/cp/mangle.c
@@ -885,7 +885,7 @@ write_unscoped_name (const tree decl)
       /* If not, it should be either in the global namespace, or directly
 	 in a local function scope.  */
       gcc_assert (context == global_namespace
-		  || context != NULL
+		  || context == NULL
 		  || TREE_CODE (context) == FUNCTION_DECL);
 
       write_unqualified_name (decl);
diff --git a/gcc/diagnostic-color.c b/gcc/diagnostic-color.c
new file mode 100644
index 0000000..a1c508a
--- /dev/null
+++ b/gcc/diagnostic-color.c
@@ -0,0 +1,301 @@
+/* Output colorization.
+   Copyright 2011-2013 Free Software Foundation, Inc.
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 51 Franklin Street - Fifth Floor, Boston, MA
+   02110-1301, USA.  */
+
+#include "config.h"
+#include "system.h"
+#include "diagnostic-color.h"
+
+/* Select Graphic Rendition (SGR, "\33[...m") strings.  */
+/* Also Erase in Line (EL) to Right ("\33[K") by default.  */
+/*    Why have EL to Right after SGR?
+	 -- The behavior of line-wrapping when at the bottom of the
+	    terminal screen and at the end of the current line is often
+	    such that a new line is introduced, entirely cleared with
+	    the current background color which may be different from the
+	    default one (see the boolean back_color_erase terminfo(5)
+	    capability), thus scrolling the display by one line.
+	    The end of this new line will stay in this background color
+	    even after reverting to the default background color with
+	    "\33[m', unless it is explicitly cleared again with "\33[K"
+	    (which is the behavior the user would instinctively expect
+	    from the whole thing).  There may be some unavoidable
+	    background-color flicker at the end of this new line because
+	    of this (when timing with the monitor's redraw is just right).
+	 -- The behavior of HT (tab, "\t") is usually the same as that of
+	    Cursor Forward Tabulation (CHT) with a default parameter
+	    of 1 ("\33[I"), i.e., it performs pure movement to the next
+	    tab stop, without any clearing of either content or screen
+	    attributes (including background color); try
+	       printf 'asdfqwerzxcv\rASDF\tZXCV\n'
+	    in a bash(1) shell to demonstrate this.  This is not what the
+	    user would instinctively expect of HT (but is ok for CHT).
+	    The instinctive behavior would include clearing the terminal
+	    cells that are skipped over by HT with blank cells in the
+	    current screen attributes, including background color;
+	    the boolean dest_tabs_magic_smso terminfo(5) capability
+	    indicates this saner behavior for HT, but only some rare
+	    terminals have it (although it also indicates a special
+	    glitch with standout mode in the Teleray terminal for which
+	    it was initially introduced).  The remedy is to add "\33K"
+	    after each SGR sequence, be it START (to fix the behavior
+	    of any HT after that before another SGR) or END (to fix the
+	    behavior of an HT in default background color that would
+	    follow a line-wrapping at the bottom of the screen in another
+	    background color, and to complement doing it after START).
+	    Piping GCC's output through a pager such as less(1) avoids
+	    any HT problems since the pager performs tab expansion.
+
+      Generic disadvantages of this remedy are:
+	 -- Some very rare terminals might support SGR but not EL (nobody
+	    will use "gcc -fdiagnostics-color" on a terminal that does not
+	    support SGR in the first place).
+	 -- Having these extra control sequences might somewhat complicate
+	    the task of any program trying to parse "gcc -fdiagnostics-color"
+	    output in order to extract structuring information from it.
+      A specific disadvantage to doing it after SGR START is:
+	 -- Even more possible background color flicker (when timing
+	    with the monitor's redraw is just right), even when not at the
+	    bottom of the screen.
+      There are no additional disadvantages specific to doing it after
+      SGR END.
+
+      It would be impractical for GCC to become a full-fledged
+      terminal program linked against ncurses or the like, so it will
+      not detect terminfo(5) capabilities.  */
+#define COLOR_SEPARATOR		";"
+#define COLOR_NONE		"00"
+#define COLOR_BOLD		"01"
+#define COLOR_UNDERSCORE	"04"
+#define COLOR_BLINK		"05"
+#define COLOR_REVERSE		"07"
+#define COLOR_FG_BLACK		"30"
+#define COLOR_FG_RED		"31"
+#define COLOR_FG_GREEN		"32"
+#define COLOR_FG_YELLOW		"33"
+#define COLOR_FG_BLUE		"34"
+#define COLOR_FG_MAGENTA	"35"
+#define COLOR_FG_CYAN		"36"
+#define COLOR_FG_WHITE		"37"
+#define COLOR_BG_BLACK		"40"
+#define COLOR_BG_RED		"41"
+#define COLOR_BG_GREEN		"42"
+#define COLOR_BG_YELLOW		"43"
+#define COLOR_BG_BLUE		"44"
+#define COLOR_BG_MAGENTA	"45"
+#define COLOR_BG_CYAN		"46"
+#define COLOR_BG_WHITE		"47"
+#define SGR_START		"\33["
+#define SGR_END			"m\33[K"
+#define SGR_SEQ(str)		SGR_START str SGR_END
+#define SGR_RESET		SGR_SEQ("")
+
+
+/* The context and logic for choosing default --color screen attributes
+   (foreground and background colors, etc.) are the following.
+      -- There are eight basic colors available, each with its own
+	 nominal luminosity to the human eye and foreground/background
+	 codes (black [0 %, 30/40], blue [11 %, 34/44], red [30 %, 31/41],
+	 magenta [41 %, 35/45], green [59 %, 32/42], cyan [70 %, 36/46],
+	 yellow [89 %, 33/43], and white [100 %, 37/47]).
+      -- Sometimes, white as a background is actually implemented using
+	 a shade of light gray, so that a foreground white can be visible
+	 on top of it (but most often not).
+      -- Sometimes, black as a foreground is actually implemented using
+	 a shade of dark gray, so that it can be visible on top of a
+	 background black (but most often not).
+      -- Sometimes, more colors are available, as extensions.
+      -- Other attributes can be selected/deselected (bold [1/22],
+	 underline [4/24], standout/inverse [7/27], blink [5/25], and
+	 invisible/hidden [8/28]).  They are sometimes implemented by
+	 using colors instead of what their names imply; e.g., bold is
+	 often achieved by using brighter colors.  In practice, only bold
+	 is really available to us, underline sometimes being mapped by
+	 the terminal to some strange color choice, and standout best
+	 being left for use by downstream programs such as less(1).
+      -- We cannot assume that any of the extensions or special features
+	 are available for the purpose of choosing defaults for everyone.
+      -- The most prevalent default terminal backgrounds are pure black
+	 and pure white, and are not necessarily the same shades of
+	 those as if they were selected explicitly with SGR sequences.
+	 Some terminals use dark or light pictures as default background,
+	 but those are covered over by an explicit selection of background
+	 color with an SGR sequence; their users will appreciate their
+	 background pictures not be covered like this, if possible.
+      -- Some uses of colors attributes is to make some output items
+	 more understated (e.g., context lines); this cannot be achieved
+	 by changing the background color.
+      -- For these reasons, the GCC color defaults should strive not
+	 to change the background color from its default, unless it's
+	 for a short item that should be highlighted, not understated.
+      -- The GCC foreground color defaults (without an explicitly set
+	 background) should provide enough contrast to be readable on any
+	 terminal with either a black (dark) or white (light) background.
+	 This only leaves red, magenta, green, and cyan (and their bold
+	 counterparts) and possibly bold blue.  */
+/* Default colors. The user can overwrite them using environment
+   variable GCC_COLORS.  */
+struct color_cap
+{
+  const char *name;
+  const char *val;
+  unsigned char name_len;
+  bool free_val;
+};
+
+/* For GCC_COLORS.  */
+static struct color_cap color_dict[] =
+{
+  { "error", SGR_SEQ (COLOR_BOLD COLOR_SEPARATOR COLOR_FG_RED), 5, false },
+  { "warning", SGR_SEQ (COLOR_BOLD COLOR_SEPARATOR COLOR_FG_MAGENTA),
+	       7, false },
+  { "note", SGR_SEQ (COLOR_BOLD COLOR_SEPARATOR COLOR_FG_CYAN), 4, false },
+  { "caret", SGR_SEQ (COLOR_BOLD COLOR_SEPARATOR COLOR_FG_GREEN), 5, false },
+  { "locus", SGR_SEQ (COLOR_BOLD), 5, false },
+  { "quote", SGR_SEQ (COLOR_BOLD), 5, false },
+  { NULL, NULL, 0, false }
+};
+
+const char *
+colorize_start (bool show_color, const char *name, size_t name_len)
+{
+  struct color_cap const *cap;
+
+  if (!show_color)
+    return "";
+
+  for (cap = color_dict; cap->name; cap++)
+    if (cap->name_len == name_len
+	&& memcmp (cap->name, name, name_len) == 0)
+      break;
+  if (cap->name == NULL)
+    return "";
+
+  return cap->val;
+}
+
+const char *
+colorize_stop (bool show_color)
+{
+  return show_color ? SGR_RESET : "";
+}
+
+/* Parse GCC_COLORS.  The default would look like:
+   GCC_COLORS='error=01;31:warning=01;35:note=01;36:caret=01;32:locus=01:quote=01'
+   No character escaping is needed or supported.  */
+static bool
+parse_gcc_colors (void)
+{
+  const char *p, *q, *name, *val;
+  char *b;
+  size_t name_len = 0, val_len = 0;
+
+  p = getenv ("GCC_COLORS"); /* Plural! */
+  if (p == NULL)
+    return true;
+  if (*p == '\0')
+    return false;
+
+  name = q = p;
+  val = NULL;
+  /* From now on, be well-formed or you're gone.  */
+  for (;;)
+    if (*q == ':' || *q == '\0')
+      {
+	struct color_cap *cap;
+
+	if (val)
+	  val_len = q - val;
+	else
+	  name_len = q - name;
+	/* Empty name without val (empty cap)
+	   won't match and will be ignored.  */
+	for (cap = color_dict; cap->name; cap++)
+	  if (cap->name_len == name_len
+	      && memcmp (cap->name, name, name_len) == 0)
+	    break;
+	/* If name unknown, go on for forward compatibility.  */
+	if (cap->val && val)
+	  {
+	    if (cap->free_val)
+	      free (CONST_CAST (char *, cap->val));
+	    b = XNEWVEC (char, val_len + sizeof (SGR_SEQ ("")));
+	    memcpy (b, SGR_START, strlen (SGR_START));
+	    memcpy (b + strlen (SGR_START), val, val_len);
+	    memcpy (b + strlen (SGR_START) + val_len, SGR_END,
+		    sizeof (SGR_END));
+	    cap->val = (const char *) b;
+	    cap->free_val = true;
+	  }
+	if (*q == '\0')
+	  return true;
+	name = ++q;
+	val = NULL;
+      }
+    else if (*q == '=')
+      {
+	if (q == name || val)
+	  return true;
+
+	name_len = q - name;
+	val = ++q; /* Can be the empty string.  */
+      }
+    else if (val == NULL)
+      q++; /* Accumulate name.  */
+    else if (*q == ';' || (*q >= '0' && *q <= '9'))
+      q++; /* Accumulate val.  Protect the terminal from being sent
+	      garbage.  */
+    else
+      return true;
+}
+
+#if defined(_WIN32)
+bool
+colorize_init (diagnostic_color_rule_t)
+{
+  return false;
+}
+#else
+
+/* Return true if we should use color when in auto mode, false otherwise. */
+static bool
+should_colorize (void)
+{
+  char const *t = getenv ("TERM");
+  return t && strcmp (t, "dumb") != 0 && isatty (STDERR_FILENO);
+}
+
+
+bool
+colorize_init (diagnostic_color_rule_t rule)
+{
+  switch (rule)
+    {
+    case DIAGNOSTICS_COLOR_NO:
+      return false;
+    case DIAGNOSTICS_COLOR_YES:
+      return parse_gcc_colors ();
+    case DIAGNOSTICS_COLOR_AUTO:
+      if (should_colorize ())
+	return parse_gcc_colors ();
+      else
+	return false;
+    default:
+      gcc_unreachable ();
+    }
+}
+#endif
diff --git a/gcc/diagnostic-color.h b/gcc/diagnostic-color.h
new file mode 100644
index 0000000..e643e51
--- /dev/null
+++ b/gcc/diagnostic-color.h
@@ -0,0 +1,66 @@
+/* Copyright (C) 2013 Free Software Foundation, Inc.
+   Contributed by Manuel Lopez-Ibanez <manu@gcc.gnu.org>
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 3, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING3.  If not see
+<http://www.gnu.org/licenses/>.  */
+
+/* Based on code from: */
+/* grep.c - main driver file for grep.
+   Copyright (C) 1992, 1997-2002, 2004-2013 Free Software Foundation, Inc.
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 51 Franklin Street - Fifth Floor, Boston, MA
+   02110-1301, USA.
+
+   Written July 1992 by Mike Haertel.  */
+
+#ifndef GCC_DIAGNOSTIC_COLOR_H
+#define GCC_DIAGNOSTIC_COLOR_H
+
+/* How often diagnostics are prefixed by their locations:
+   o DIAGNOSTICS_SHOW_PREFIX_NEVER: never - not yet supported;
+   o DIAGNOSTICS_SHOW_PREFIX_ONCE: emit only once;
+   o DIAGNOSTICS_SHOW_PREFIX_EVERY_LINE: emit each time a physical
+   line is started.  */
+typedef enum
+{
+  DIAGNOSTICS_COLOR_NO       = 0,
+  DIAGNOSTICS_COLOR_YES      = 1,
+  DIAGNOSTICS_COLOR_AUTO     = 2
+} diagnostic_color_rule_t;
+
+const char *colorize_start (bool, const char *, size_t);
+const char *colorize_stop (bool);
+bool colorize_init (diagnostic_color_rule_t);
+
+inline const char *
+colorize_start (bool show_color, const char *name)
+{
+  return colorize_start (show_color, name, strlen (name));
+}
+
+#endif /* ! GCC_DIAGNOSTIC_COLOR_H */
diff --git a/gcc/diagnostic-core.h b/gcc/diagnostic-core.h
index 68ec837..a210782 100644
--- a/gcc/diagnostic-core.h
+++ b/gcc/diagnostic-core.h
@@ -28,7 +28,7 @@ along with GCC; see the file COPYING3.  If not see
 /* Constants used to discriminate diagnostics.  */
 typedef enum
 {
-#define DEFINE_DIAGNOSTIC_KIND(K, msgid) K,
+#define DEFINE_DIAGNOSTIC_KIND(K, msgid, C) K,
 #include "diagnostic.def"
 #undef DEFINE_DIAGNOSTIC_KIND
   DK_LAST_DIAGNOSTIC_KIND,
diff --git a/gcc/diagnostic.c b/gcc/diagnostic.c
index a365c60..46986ca 100644
--- a/gcc/diagnostic.c
+++ b/gcc/diagnostic.c
@@ -31,6 +31,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "intl.h"
 #include "backtrace.h"
 #include "diagnostic.h"
+#include "diagnostic-color.h"
 
 #define pedantic_warning_kind(DC)			\
   ((DC)->pedantic_errors ? DK_ERROR : DK_WARNING)
@@ -53,7 +54,6 @@ const char *progname;
 /* A diagnostic_context surrogate for stderr.  */
 static diagnostic_context global_diagnostic_context;
 diagnostic_context *global_dc = &global_diagnostic_context;
-
 
 /* Return a malloc'd string containing MSG formatted a la printf.  The
    caller is responsible for freeing the memory.  */
@@ -210,12 +210,31 @@ diagnostic_build_prefix (diagnostic_context *context,
 			 const diagnostic_info *diagnostic)
 {
   static const char *const diagnostic_kind_text[] = {
-#define DEFINE_DIAGNOSTIC_KIND(K, T) (T),
+#define DEFINE_DIAGNOSTIC_KIND(K, T, C) (T),
 #include "diagnostic.def"
 #undef DEFINE_DIAGNOSTIC_KIND
     "must-not-happen"
   };
+  static const char *const diagnostic_kind_color[] = {
+#define DEFINE_DIAGNOSTIC_KIND(K, T, C) (C),
+#include "diagnostic.def"
+#undef DEFINE_DIAGNOSTIC_KIND
+    NULL
+  };
   const char *text = _(diagnostic_kind_text[diagnostic->kind]);
+  const char *text_cs = "", *text_ce = "";
+  const char *locus_cs, *locus_ce;
+  pretty_printer *pp = context->printer;
+
+  if (diagnostic_kind_color[diagnostic->kind])
+    {
+      text_cs = colorize_start (pp_show_color (pp),
+				diagnostic_kind_color[diagnostic->kind]);
+      text_ce = colorize_stop (pp_show_color (pp));
+    }
+  locus_cs = colorize_start (pp_show_color (pp), "locus");
+  locus_ce = colorize_stop (pp_show_color (pp));
+
   expanded_location s = expand_location_to_spelling_point (diagnostic->location);
   if (diagnostic->override_column)
     s.column = diagnostic->override_column;
@@ -223,10 +242,13 @@ diagnostic_build_prefix (diagnostic_context *context,
 
   return
     (s.file == NULL
-     ? build_message_string ("%s: %s", progname, text)
+     ? build_message_string ("%s%s:%s %s%s%s", locus_cs, progname, locus_ce,
+			     text_cs, text, text_ce)
      : context->show_column
-     ? build_message_string ("%s:%d:%d: %s", s.file, s.line, s.column, text)
-     : build_message_string ("%s:%d: %s", s.file, s.line, text));
+     ? build_message_string ("%s%s:%d:%d:%s %s%s%s", locus_cs, s.file, s.line,
+			     s.column, locus_ce, text_cs, text, text_ce)
+     : build_message_string ("%s%s:%d:%s %s%s%s", locus_cs, s.file, s.line, locus_ce,
+			     text_cs, text, text_ce));
 }
 
 /* If LINE is longer than MAX_WIDTH, and COLUMN is not smaller than
@@ -262,7 +284,7 @@ diagnostic_show_locus (diagnostic_context * context,
   expanded_location s;
   int max_width;
   const char *saved_prefix;
-
+  const char *caret_cs, *caret_ce;
 
   if (!context->show_caret
       || diagnostic->location <= BUILTINS_LOCATION
@@ -290,9 +312,13 @@ diagnostic_show_locus (diagnostic_context * context,
       line++;
     }
   pp_newline (context->printer);
+  caret_cs = colorize_start (pp_show_color (context->printer), "caret");
+  caret_ce = colorize_stop (pp_show_color (context->printer));
+
   /* pp_printf does not implement %*c.  */
-  buffer = XALLOCAVEC (char, s.column + 3);
-  snprintf (buffer, s.column + 3, " %*c", s.column, '^');
+  size_t len = s.column + 3 + strlen (caret_cs) + strlen (caret_ce);
+  buffer = XALLOCAVEC (char, len);
+  snprintf (buffer, len, "%s %*c%s", caret_cs, s.column, '^', caret_ce);
   pp_string (context->printer, buffer);
   pp_set_prefix (context->printer, saved_prefix);
 }
diff --git a/gcc/diagnostic.def b/gcc/diagnostic.def
index 53179e4..2f1e365 100644
--- a/gcc/diagnostic.def
+++ b/gcc/diagnostic.def
@@ -22,24 +22,26 @@ along with GCC; see the file COPYING3.  If not see
    kind specified.  I.e. they're uninitialized.  Within the diagnostic
    machinery, this kind also means "don't change the existing kind",
    meaning "no change is specified".  */
-DEFINE_DIAGNOSTIC_KIND (DK_UNSPECIFIED, "")
+DEFINE_DIAGNOSTIC_KIND (DK_UNSPECIFIED, "", NULL)
 
 /* If a diagnostic is set to DK_IGNORED, it won't get reported at all.
    This is used by the diagnostic machinery when it wants to disable a
    diagnostic without disabling the option which causes it.  */
-DEFINE_DIAGNOSTIC_KIND (DK_IGNORED, "")
+DEFINE_DIAGNOSTIC_KIND (DK_IGNORED, "", NULL)
 
 /* The remainder are real diagnostic types.  */
-DEFINE_DIAGNOSTIC_KIND (DK_FATAL, "fatal error: ")
-DEFINE_DIAGNOSTIC_KIND (DK_ICE, "internal compiler error: ")
-DEFINE_DIAGNOSTIC_KIND (DK_ERROR, "error: ")
-DEFINE_DIAGNOSTIC_KIND (DK_SORRY, "sorry, unimplemented: ")
-DEFINE_DIAGNOSTIC_KIND (DK_WARNING, "warning: ")
-DEFINE_DIAGNOSTIC_KIND (DK_ANACHRONISM, "anachronism: ")
-DEFINE_DIAGNOSTIC_KIND (DK_NOTE, "note: ")
-DEFINE_DIAGNOSTIC_KIND (DK_DEBUG, "debug: ")
+DEFINE_DIAGNOSTIC_KIND (DK_FATAL, "fatal error: ", "error")
+DEFINE_DIAGNOSTIC_KIND (DK_ICE, "internal compiler error: ", "error")
+DEFINE_DIAGNOSTIC_KIND (DK_ERROR, "error: ", "error")
+DEFINE_DIAGNOSTIC_KIND (DK_SORRY, "sorry, unimplemented: ", "error")
+DEFINE_DIAGNOSTIC_KIND (DK_WARNING, "warning: ", "warning")
+DEFINE_DIAGNOSTIC_KIND (DK_ANACHRONISM, "anachronism: ", "warning")
+DEFINE_DIAGNOSTIC_KIND (DK_NOTE, "note: ", "note")
+DEFINE_DIAGNOSTIC_KIND (DK_DEBUG, "debug: ", "note")
 /* These two would be re-classified as DK_WARNING or DK_ERROR, so the
 prefix does not matter.  */
-DEFINE_DIAGNOSTIC_KIND (DK_PEDWARN, "pedwarn: ")
-DEFINE_DIAGNOSTIC_KIND (DK_PERMERROR, "permerror: ")
-
+DEFINE_DIAGNOSTIC_KIND (DK_PEDWARN, "pedwarn: ", NULL)
+DEFINE_DIAGNOSTIC_KIND (DK_PERMERROR, "permerror: ", NULL)
+/* This one is just for counting DK_WARNING promoted to DK_ERROR
+   due to -Werror and -Werror=warning.  */
+DEFINE_DIAGNOSTIC_KIND (DK_WERROR, "error: ", NULL)
diff --git a/gcc/doc/invoke.texi b/gcc/doc/invoke.texi
index 3b0ab91..6e6d478 100644
--- a/gcc/doc/invoke.texi
+++ b/gcc/doc/invoke.texi
@@ -226,6 +226,7 @@ Objective-C and Objective-C++ Dialects}.
 @xref{Language Independent Options,,Options to Control Diagnostic Messages Formatting}.
 @gccoptlist{-fmessage-length=@var{n}  @gol
 -fdiagnostics-show-location=@r{[}once@r{|}every-line@r{]}  @gol
+-fdiagnostics-color=@r{[}auto@r{|}never@r{|}always@r{]}  @gol
 -fno-diagnostics-show-option -fno-diagnostics-show-caret}
 
 @item Warning Options
@@ -510,7 +511,9 @@ Objective-C and Objective-C++ Dialects}.
 -mtp=@var{name} -mtls-dialect=@var{dialect} @gol
 -mword-relocations @gol
 -mfix-cortex-m3-ldrd @gol
--munaligned-access}
+-munaligned-access @gol
+-mneon-for-64bits @gol
+-mrestrict-it}
 
 @emph{AVR Options}
 @gccoptlist{-mmcu=@var{mcu} -maccumulate-args -mbranch-cost=@var{cost} @gol
@@ -2953,6 +2956,77 @@ messages reporter to emit the same source location information (as
 prefix) for physical lines that result from the process of breaking
 a message which is too long to fit on a single line.
 
+@item -fdiagnostics-color[=@var{WHEN}]
+@itemx -fno-diagnostics-color
+@opindex fdiagnostics-color
+@cindex highlight, color, colour
+@vindex GCC_COLORS @r{environment variable}
+Use color in diagnostics.  @var{WHEN} is @samp{never}, @samp{always},
+or @samp{auto}.  The default is @samp{never} if @env{GCC_COLORS} environment
+variable isn't present in the environment, and @samp{auto} otherwise.
+@samp{auto} means to use color only when the standard error is a terminal.
+The forms @option{-fdiagnostics-color} and @option{-fno-diagnostics-color} are
+aliases for @option{-fdiagnostics-color=always} and
+@option{-fdiagnostics-color=never}, respectively.
+
+The colors are defined by the environment variable @env{GCC_COLORS}.
+Its value is a colon-separated list of capabilities and Select Graphic
+Rendition (SGR) substrings. SGR commands are interpreted by the
+terminal or terminal emulator.  (See the section in the documentation
+of your text terminal for permitted values and their meanings as
+character attributes.)  These substring values are integers in decimal
+representation and can be concatenated with semicolons.
+Common values to concatenate include
+@samp{1} for bold,
+@samp{4} for underline,
+@samp{5} for blink,
+@samp{7} for inverse,
+@samp{39} for default foreground color,
+@samp{30} to @samp{37} for foreground colors,
+@samp{90} to @samp{97} for 16-color mode foreground colors,
+@samp{38;5;0} to @samp{38;5;255}
+for 88-color and 256-color modes foreground colors,
+@samp{49} for default background color,
+@samp{40} to @samp{47} for background colors,
+@samp{100} to @samp{107} for 16-color mode background colors,
+and @samp{48;5;0} to @samp{48;5;255}
+for 88-color and 256-color modes background colors.
+
+The default @env{GCC_COLORS} is
+@samp{error=01;31:warning=01;35:note=01;36:caret=01;32:locus=01:quote=01}
+where @samp{01;31} is bold red, @samp{01;35} is bold magenta,
+@samp{01;36} is bold cyan, @samp{01;32} is bold green and
+@samp{01} is bold. Setting @env{GCC_COLORS} to the empty
+string disables colors.
+Supported capabilities are as follows.
+
+@table @code
+@item error=
+@vindex error GCC_COLORS @r{capability}
+SGR substring for error: markers.
+
+@item warning=
+@vindex warning GCC_COLORS @r{capability}
+SGR substring for warning: markers.
+
+@item note=
+@vindex note GCC_COLORS @r{capability}
+SGR substring for note: markers.
+
+@item caret=
+@vindex caret GCC_COLORS @r{capability}
+SGR substring for caret line.
+
+@item locus=
+@vindex locus GCC_COLORS @r{capability}
+SGR substring for location information, @samp{file:line} or
+@samp{file:line:column} etc.
+
+@item quote=
+@vindex quote GCC_COLORS @r{capability}
+SGR substring for information printed within quotes.
+@end table
+
 @item -fno-diagnostics-show-option
 @opindex fno-diagnostics-show-option
 @opindex fdiagnostics-show-option
@@ -8436,6 +8510,9 @@ Use the @command{bfd} linker instead of the default linker.
 @item -fuse-ld=gold
 Use the @command{gold} linker instead of the default linker.
 
+@item -fuse-ld=mcld
+Use the @command{mcld} linker instead of the default linker.
+
 @item -fcprop-registers
 @opindex fcprop-registers
 After register allocation and post-register allocation instruction splitting,
@@ -11264,7 +11341,7 @@ assembly code.  Permissible names are: @samp{arm2}, @samp{arm250},
 @samp{arm1156t2-s}, @samp{arm1156t2f-s}, @samp{arm1176jz-s}, @samp{arm1176jzf-s},
 @samp{cortex-a5}, @samp{cortex-a7}, @samp{cortex-a8}, @samp{cortex-a9}, 
 @samp{cortex-a15}, @samp{cortex-r4}, @samp{cortex-r4f}, @samp{cortex-r5},
-@samp{cortex-m4}, @samp{cortex-m3},
+@samp{cortex-r7}, @samp{cortex-m4}, @samp{cortex-m3},
 @samp{cortex-m1},
 @samp{cortex-m0},
 @samp{cortex-m0plus},
@@ -11527,6 +11604,17 @@ setting of this option.  If unaligned access is enabled then the
 preprocessor symbol @code{__ARM_FEATURE_UNALIGNED} will also be
 defined.
 
+@item -mneon-for-64bits
+@opindex mneon-for-64bits
+Enables using Neon to handle scalar 64-bits operations. This is
+disabled by default since the cost of moving data from core registers
+to Neon is high.
+
+@item -mrestrict-it
+@opindex mrestrict-it
+Restricts generation of IT blocks to conform to the rules of ARMv8.
+IT blocks can only contain a single 16-bit instruction from a select
+set of instructions. This option is on by default for ARMv8 Thumb mode.
 @end table
 
 @node AVR Options
diff --git a/gcc/dwarf2out.c b/gcc/dwarf2out.c
index 77771c0..2bf53a1 100644
--- a/gcc/dwarf2out.c
+++ b/gcc/dwarf2out.c
@@ -18803,6 +18803,7 @@ gen_producer_string (void)
       case OPT_fdiagnostics_show_location_:
       case OPT_fdiagnostics_show_option:
       case OPT_fdiagnostics_show_caret:
+      case OPT_fdiagnostics_color_:
       case OPT_fverbose_asm:
       case OPT____:
       case OPT__sysroot_:
diff --git a/gcc/gcc.c b/gcc/gcc.c
index fea7394..e16f72e 100644
--- a/gcc/gcc.c
+++ b/gcc/gcc.c
@@ -537,7 +537,7 @@ proper position among the other output files.  */
    shared library ordering, and we keep the wrapper function in
    libgcc.  This is not yet a real spec, though it could become one;
    it is currently just stuffed into LINK_SPEC.  FIXME: This wrapping
-   only works with GNU ld and gold.  FIXME: This is incompatible with
+   only works with GNU ld, gold and mcld.  FIXME: This is incompatible with
    -fmudflap when linking statically, which wants to do its own
    wrapping.  */
 #define STACK_SPLIT_SPEC " %{fsplit-stack: --wrap=pthread_create}"
diff --git a/gcc/gimplify.c b/gcc/gimplify.c
index e711928..9416963 100644
--- a/gcc/gimplify.c
+++ b/gcc/gimplify.c
@@ -2229,6 +2229,15 @@ gimplify_compound_lval (tree *expr_p, gimple_seq *pre_p, gimple_seq *post_p,
 	  if (TREE_OPERAND (t, 3) == NULL_TREE)
 	    {
 	      tree elmt_type = TREE_TYPE (TREE_TYPE (TREE_OPERAND (t, 0)));
+	      /* FIXME google - In some edge cases, ELMT_TYPE may
+		 not have been laid out.  This causes an ICE later
+		 (PR 55245).  We call layout_type if ELMT_TYPE is not
+		 yet complete, but this is not where this bug should
+		 be fixed.  The FE should have laid out all the types
+		 before gimplification.  When a proper fix for PR
+		 55245 is available, remove this.  */
+	      if (!COMPLETE_TYPE_P (elmt_type))
+		layout_type (elmt_type);
 	      tree elmt_size = unshare_expr (array_ref_element_size (t));
 	      tree factor = size_int (TYPE_ALIGN_UNIT (elmt_type));
 
diff --git a/gcc/langhooks.c b/gcc/langhooks.c
index 3a22d6b..70af8da 100644
--- a/gcc/langhooks.c
+++ b/gcc/langhooks.c
@@ -452,14 +452,14 @@ lhd_print_error_function (diagnostic_context *context, const char *file,
 		    {
 		      if (context->show_column)
 			pp_printf (context->printer,
-				   _("    inlined from %qs at %s:%d:%d"),
+				   _("    inlined from %qs at %r%s:%d:%d%R"),
 				   identifier_to_locale (lang_hooks.decl_printable_name (fndecl, 2)),
-				   s.file, s.line, s.column);
+				   "locus", s.file, s.line, s.column);
 		      else
 			pp_printf (context->printer,
-				   _("    inlined from %qs at %s:%d"),
+				   _("    inlined from %qs at %r%s:%d%R"),
 				   identifier_to_locale (lang_hooks.decl_printable_name (fndecl, 2)),
-				   s.file, s.line);
+				   "locus", s.file, s.line);
 
 		    }
 		  else
diff --git a/gcc/opts.c b/gcc/opts.c
index 45b12fe..7ae1e00 100644
--- a/gcc/opts.c
+++ b/gcc/opts.c
@@ -30,6 +30,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "flags.h"
 #include "params.h"
 #include "diagnostic.h"
+#include "diagnostic-color.h"
 #include "opts-diagnostic.h"
 #include "insn-attr-common.h"
 #include "common/common-target.h"
@@ -1497,6 +1498,11 @@ common_handle_option (struct gcc_options *opts,
       dc->show_caret = value;
       break;
 
+    case OPT_fdiagnostics_color_:
+      pp_show_color (dc->printer)
+	= colorize_init ((diagnostic_color_rule_t) value);
+      break;
+
     case OPT_fdiagnostics_show_option:
       dc->show_option_requested = value;
       break;
diff --git a/gcc/pretty-print.c b/gcc/pretty-print.c
index 4c45e51..fe46464 100644
--- a/gcc/pretty-print.c
+++ b/gcc/pretty-print.c
@@ -23,6 +23,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "coretypes.h"
 #include "intl.h"
 #include "pretty-print.h"
+#include "diagnostic-color.h"
 
 #if HAVE_ICONV
 #include <iconv.h>
@@ -226,6 +227,8 @@ pp_base_indent (pretty_printer *pp)
    %c: character.
    %s: string.
    %p: pointer.
+   %r: if pp_show_color(pp), switch to color identified by const char *.
+   %R: if pp_show_color(pp), reset color.
    %m: strerror(text->err_no) - does not consume a value from args_ptr.
    %%: '%'.
    %<: opening quote.
@@ -300,18 +303,37 @@ pp_base_format (pretty_printer *pp, text_info *text)
 	  continue;
 
 	case '<':
-	  obstack_grow (&buffer->chunk_obstack,
-			open_quote, strlen (open_quote));
-	  p++;
-	  continue;
+	  {
+	    obstack_grow (&buffer->chunk_obstack,
+			  open_quote, strlen (open_quote));
+	    const char *colorstr
+	      = colorize_start (pp_show_color (pp), "quote");
+	    obstack_grow (&buffer->chunk_obstack, colorstr, strlen (colorstr));
+	    p++;
+	    continue;
+	  }
 
 	case '>':
+	  {
+	    const char *colorstr = colorize_stop (pp_show_color (pp));
+	    obstack_grow (&buffer->chunk_obstack, colorstr, strlen (colorstr));
+	  }
+	  /* FALLTHRU */
 	case '\'':
 	  obstack_grow (&buffer->chunk_obstack,
 			close_quote, strlen (close_quote));
 	  p++;
 	  continue;
 
+	case 'R':
+	  {
+	    const char *colorstr = colorize_stop (pp_show_color (pp));
+	    obstack_grow (&buffer->chunk_obstack, colorstr,
+			  strlen (colorstr));
+	    p++;
+	    continue;
+	  }
+
 	case 'm':
 	  {
 	    const char *errstr = xstrerror (text->err_no);
@@ -466,10 +488,19 @@ pp_base_format (pretty_printer *pp, text_info *text)
       gcc_assert (!wide || precision == 0);
 
       if (quote)
-	pp_string (pp, open_quote);
+	{
+	  pp_string (pp, open_quote);
+	  pp_string (pp, colorize_start (pp_show_color (pp), "quote"));
+	}
 
       switch (*p)
 	{
+	case 'r':
+	  pp_string (pp, colorize_start (pp_show_color (pp),
+					 va_arg (*text->args_ptr,
+						 const char *)));
+	  break;
+
 	case 'c':
 	  pp_character (pp, va_arg (*text->args_ptr, int));
 	  break;
@@ -563,7 +594,10 @@ pp_base_format (pretty_printer *pp, text_info *text)
 	}
 
       if (quote)
-	pp_string (pp, close_quote);
+	{
+	  pp_string (pp, colorize_stop (pp_show_color (pp)));
+	  pp_string (pp, close_quote);
+	}
 
       obstack_1grow (&buffer->chunk_obstack, '\0');
       *formatters[argno] = XOBFINISH (&buffer->chunk_obstack, const char *);
diff --git a/gcc/pretty-print.h b/gcc/pretty-print.h
index 56d2d3e..13bb2de 100644
--- a/gcc/pretty-print.h
+++ b/gcc/pretty-print.h
@@ -151,6 +151,9 @@ typedef bool (*printer_fn) (pretty_printer *, text_info *, const char *,
    output.  */
 #define pp_translate_identifiers(PP) pp_base (PP)->translate_identifiers
 
+/* True if colors should be shown.  */
+#define pp_show_color(PP) pp_base (PP)->show_color
+
 /* The data structure that contains the bare minimum required to do
    proper pretty-printing.  Clients may derived from this structure
    and add additional fields they need.  */
@@ -194,6 +197,9 @@ struct pretty_print_info
   /* Nonzero means identifiers are translated to the locale character
      set on output.  */
   bool translate_identifiers;
+
+  /* Nonzero means that text should be colorized.  */
+  bool show_color;
 };
 
 #define pp_set_line_maximum_length(PP, L) \
diff --git a/gcc/testsuite/ChangeLog b/gcc/testsuite/ChangeLog
index 4cdd5b0..1ec5f27 100644
--- a/gcc/testsuite/ChangeLog
+++ b/gcc/testsuite/ChangeLog
@@ -1,3 +1,9 @@
+2013-07-10  Janis Johnson  <janisjo@codesourcery.com>
+
+	* gcc.target/powerpc/20020118-1.c: Force 128-bit stack alignment
+	for EABI targets.
+	* gcc.c-torture/execute/nest-align-1.x: New.
+
 2013-07-08  Janis Johnson  <janisjo@codesourcery.com>
 
 	* gcc.target/powerpc/ppc-spe64-1.c: Update expected error message.
diff --git a/gcc/testsuite/ChangeLog.cfx b/gcc/testsuite/ChangeLog.cfx
new file mode 100644
index 0000000..7f3217e
--- /dev/null
+++ b/gcc/testsuite/ChangeLog.cfx
@@ -0,0 +1,112 @@
+This file documents backports from trunk only
+
+2013-06-07  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        PR target/56315
+        * gcc.target/arm/xordi3-opt.c: New test.
+
+2013-05-31  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        PR target/56315
+        * gcc.target/arm/iordi3-opt.c: New test.
+
+2013-05-30  Zhenqiang Chen  <zhenqiang.chen@linaro.org>
+
+        * gcc.dg/shrink-wrap-alloca.c: New added.
+        * gcc.dg/shrink-wrap-pretend.c: New added.
+        * gcc.dg/shrink-wrap-sibcall.c: New added.
+
+2013-05-23  Christian Bruel  <christian.bruel@st.com>
+
+        PR debug/57351
+        * config/arm/arm.c (arm_dwarf_register_span): Do not use dbx number.
+
+2013-05-16  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * gcc.target/arm/unaligned-memcpy-2.c: Adjust expected output.
+        * gcc.target/arm/unaligned-memcpy-3.c: Likewise.
+        * gcc.target/arm/unaligned-memcpy-4.c: Likewise.
+
+2013-05-15  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>
+
+        PR target/19599
+        * gcc.target/arm/pr40887.c: Adjust testcase.
+        * gcc.target/arm/pr19599.c: New test.
+
+2013-05-07  Christophe Lyon  <christophe.lyon@linaro.org>
+
+        * lib/target-supports.exp (check_effective_target_hw): New
+        function.
+        * c-c++-common/asan/clone-test-1.c: Call
+        check_effective_target_hw.
+        * c-c++-common/asan/rlimit-mmap-test-1.c: Likewise.
+        * c-c++-common/asan/heap-overflow-1.c: Update regexps to accept
+        possible decorations.
+        * c-c++-common/asan/null-deref-1.c: Likewise.
+        * c-c++-common/asan/stack-overflow-1.c: Likewise.
+        * c-c++-common/asan/strncpy-overflow-1.c: Likewise.
+        * c-c++-common/asan/use-after-free-1.c: Likewise.
+        * g++.dg/asan/deep-thread-stack-1.C: Likewise.
+        * g++.dg/asan/large-func-test-1.C: Likewise.
+
+2013-04-26  Jakub Jelinek  <jakub@redhat.com>
+
+        * lib/prune.exp: Add -fdiagnostics-color=never to TEST_ALWAYS_FLAGS.
+        * lib/c-compat.exp (compat-use-alt-compiler, compat_setup_dfp): Handle
+        -fdiagnostics-color=never option similarly to
+        -fno-diagnostics-show-caret option.
+
+2013-04-15  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * gcc.target/arm/anddi3-opt.c: New test.
+        * gcc.target/arm/anddi3-opt2.c: Likewise.
+
+2013-04-15  Joey Ye  <joey.ye@arm.com>
+
+        * gcc.target/arm/thumb1-far-jump-1.c: New test.
+        * gcc.target/arm/thumb1-far-jump-2.c: New test.
+
+2013-04-09  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * gcc.target/arm/minmax_minus.c: New test.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * gcc.target/arm/peep-ldrd-1.c: New test.
+        * gcc.target/arm/peep-strd-1.c: Likewise.
+
+2013-04-05  Greta Yorsh  <Greta.Yorsh@arm.com>
+
+        * gcc.target/arm/negdi-1.c: New test.
+        * gcc.target/arm/negdi-2.c: Likewise.
+        * gcc.target/arm/negdi-3.c: Likewise.
+        * gcc.target/arm/negdi-4.c: Likewise.
+
+2013-04-03  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        PR target/56809
+        * gcc.dg/pr56809.c: New testcase.
+
+2013-03-25  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>
+
+        * gcc.target/arm/vseleqdf.c: New test.
+        * gcc.target/arm/vseleqsf.c: Likewise.
+        * gcc.target/arm/vselgedf.c: Likewise.
+        * gcc.target/arm/vselgesf.c: Likewise.
+        * gcc.target/arm/vselgtdf.c: Likewise.
+        * gcc.target/arm/vselgtsf.c: Likewise.
+        * gcc.target/arm/vselledf.c: Likewise.
+        * gcc.target/arm/vsellesf.c: Likewise.
+        * gcc.target/arm/vselltdf.c: Likewise.
+        * gcc.target/arm/vselltsf.c: Likewise.
+        * gcc.target/arm/vselnedf.c: Likewise.
+        * gcc.target/arm/vselnesf.c: Likewise.
+        * gcc.target/arm/vselvcdf.c: Likewise.
+        * gcc.target/arm/vselvcsf.c: Likewise.
+        * gcc.target/arm/vselvsdf.c: Likewise.
+        * gcc.target/arm/vselvssf.c: Likewise.
+
+2013-03-21  Christophe Lyon  <christophe.lyon@linaro.org>
+
+        * gcc.target/arm/neon-for-64bits-1.c: New tests.
+        * gcc.target/arm/neon-for-64bits-2.c: Likewise.
diff --git a/gcc/testsuite/c-c++-common/asan/clone-test-1.c b/gcc/testsuite/c-c++-common/asan/clone-test-1.c
index d9acc0d..fd187aa 100644
--- a/gcc/testsuite/c-c++-common/asan/clone-test-1.c
+++ b/gcc/testsuite/c-c++-common/asan/clone-test-1.c
@@ -3,6 +3,7 @@
 
 /* { dg-do run { target { *-*-linux* } } } */
 /* { dg-require-effective-target clone } */
+/* { dg-require-effective-target hw } */
 /* { dg-options "-D_GNU_SOURCE" } */
 
 #include <stdio.h>
diff --git a/gcc/testsuite/c-c++-common/asan/heap-overflow-1.c b/gcc/testsuite/c-c++-common/asan/heap-overflow-1.c
index 43d47a3..996909d 100644
--- a/gcc/testsuite/c-c++-common/asan/heap-overflow-1.c
+++ b/gcc/testsuite/c-c++-common/asan/heap-overflow-1.c
@@ -25,7 +25,7 @@ int main(int argc, char **argv) {
 
 /* { dg-output "READ of size 1 at 0x\[0-9a-f\]+ thread T0.*(\n|\r\n|\r)" } */
 /* { dg-output "    #0 0x\[0-9a-f\]+ (in _*main (\[^\n\r]*heap-overflow-1.c:21|\[^\n\r]*:0)|\[(\]).*(\n|\r\n|\r)" } */
-/* { dg-output "0x\[0-9a-f\]+ is located 0 bytes to the right of 10-byte region\[^\n\r]*(\n|\r\n|\r)" } */
-/* { dg-output "allocated by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" } */
+/* { dg-output "\[^\n\r]*0x\[0-9a-f\]+ is located 0 bytes to the right of 10-byte region\[^\n\r]*(\n|\r\n|\r)" } */
+/* { dg-output "\[^\n\r]*allocated by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #0 0x\[0-9a-f\]+ (in _*(interceptor_|)malloc|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #1 0x\[0-9a-f\]+ (in _*main (\[^\n\r]*heap-overflow-1.c:19|\[^\n\r]*:0)|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
diff --git a/gcc/testsuite/c-c++-common/asan/null-deref-1.c b/gcc/testsuite/c-c++-common/asan/null-deref-1.c
index 2eee986..14ec514 100644
--- a/gcc/testsuite/c-c++-common/asan/null-deref-1.c
+++ b/gcc/testsuite/c-c++-common/asan/null-deref-1.c
@@ -18,6 +18,6 @@ int main()
 
 /* { dg-output "ERROR: AddressSanitizer:? SEGV on unknown address\[^\n\r]*" } */
 /* { dg-output "0x\[0-9a-f\]+ \[^\n\r]*pc 0x\[0-9a-f\]+\[^\n\r]*(\n|\r\n|\r)" } */
-/* { dg-output "AddressSanitizer can not provide additional info.*(\n|\r\n|\r)" } */
+/* { dg-output "\[^\n\r]*AddressSanitizer can not provide additional info.*(\n|\r\n|\r)" } */
 /* { dg-output "    #0 0x\[0-9a-f\]+ (in \[^\n\r]*NullDeref\[^\n\r]* (\[^\n\r]*null-deref-1.c:10|\[^\n\r]*:0)|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #1 0x\[0-9a-f\]+ (in _*main (\[^\n\r]*null-deref-1.c:15|\[^\n\r]*:0)|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
diff --git a/gcc/testsuite/c-c++-common/asan/rlimit-mmap-test-1.c b/gcc/testsuite/c-c++-common/asan/rlimit-mmap-test-1.c
index 0b3d2ae..9dbbc85 100644
--- a/gcc/testsuite/c-c++-common/asan/rlimit-mmap-test-1.c
+++ b/gcc/testsuite/c-c++-common/asan/rlimit-mmap-test-1.c
@@ -2,6 +2,7 @@
 
 /* { dg-do run { target setrlimit } } */
 /* { dg-skip-if "" { *-*-* } { "*" } { "-O0" } } */
+/* { dg-require-effective-target hw } */
 /* { dg-shouldfail "asan" } */
 
 #include <stdlib.h>
diff --git a/gcc/testsuite/c-c++-common/asan/stack-overflow-1.c b/gcc/testsuite/c-c++-common/asan/stack-overflow-1.c
index 790aa5e..5f56356 100644
--- a/gcc/testsuite/c-c++-common/asan/stack-overflow-1.c
+++ b/gcc/testsuite/c-c++-common/asan/stack-overflow-1.c
@@ -19,4 +19,4 @@ int main() {
 
 /* { dg-output "READ of size 1 at 0x\[0-9a-f\]+ thread T0\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #0 0x\[0-9a-f\]+ (in _*main (\[^\n\r]*stack-overflow-1.c:16|\[^\n\r]*:0)|\[(\]).*(\n|\r\n|\r)" } */
-/* { dg-output "Address 0x\[0-9a-f\]+ is\[^\n\r]*frame <main>" } */
+/* { dg-output "\[^\n\r]*Address 0x\[0-9a-f\]+ is\[^\n\r]*frame <main>" } */
diff --git a/gcc/testsuite/c-c++-common/asan/strncpy-overflow-1.c b/gcc/testsuite/c-c++-common/asan/strncpy-overflow-1.c
index 10b3ad7..3ed9fd6 100644
--- a/gcc/testsuite/c-c++-common/asan/strncpy-overflow-1.c
+++ b/gcc/testsuite/c-c++-common/asan/strncpy-overflow-1.c
@@ -15,7 +15,7 @@ int main(int argc, char **argv) {
 /* { dg-output "WRITE of size \[0-9\]* at 0x\[0-9a-f\]+ thread T0\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #0 0x\[0-9a-f\]+ (in _*(interceptor_|)strncpy|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #1 0x\[0-9a-f\]+ (in _*main (\[^\n\r]*strncpy-overflow-1.c:11|\[^\n\r]*:0)|\[(\]).*(\n|\r\n|\r)" } */
-/* { dg-output "0x\[0-9a-f\]+ is located 0 bytes to the right of 9-byte region\[^\n\r]*(\n|\r\n|\r)" } */
-/* { dg-output "allocated by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" } */
+/* { dg-output "\[^\n\r]*0x\[0-9a-f\]+ is located 0 bytes to the right of 9-byte region\[^\n\r]*(\n|\r\n|\r)" } */
+/* { dg-output "\[^\n\r]*allocated by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #0 0x\[0-9a-f\]+ (in _*(interceptor_|)malloc|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #1 0x\[0-9a-f\]+ (in _*main (\[^\n\r]*strncpy-overflow-1.c:10|\[^\n\r]*:0)|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
diff --git a/gcc/testsuite/c-c++-common/asan/use-after-free-1.c b/gcc/testsuite/c-c++-common/asan/use-after-free-1.c
index 939feeb..25e9be8 100644
--- a/gcc/testsuite/c-c++-common/asan/use-after-free-1.c
+++ b/gcc/testsuite/c-c++-common/asan/use-after-free-1.c
@@ -11,12 +11,12 @@ int main() {
 
 /* { dg-output "ERROR: AddressSanitizer:? heap-use-after-free on address\[^\n\r]*" } */
 /* { dg-output "0x\[0-9a-f\]+ at pc 0x\[0-9a-f\]+ bp 0x\[0-9a-f\]+ sp 0x\[0-9a-f\]+\[^\n\r]*(\n|\r\n|\r)" } */
-/* { dg-output "READ of size 1 at 0x\[0-9a-f\]+ thread T0\[^\n\r]*(\n|\r\n|\r)" } */
+/* { dg-output "\[^\n\r]*READ of size 1 at 0x\[0-9a-f\]+ thread T0\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #0 0x\[0-9a-f\]+ (in _*main (\[^\n\r]*use-after-free-1.c:9|\[^\n\r]*:0)|\[(\]).*(\n|\r\n|\r)" } */
-/* { dg-output "0x\[0-9a-f\]+ is located 5 bytes inside of 10-byte region .0x\[0-9a-f\]+,0x\[0-9a-f\]+\[^\n\r]*(\n|\r\n|\r)" } */
-/* { dg-output "freed by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" } */
+/* { dg-output "\[^\n\r]*0x\[0-9a-f\]+ is located 5 bytes inside of 10-byte region .0x\[0-9a-f\]+,0x\[0-9a-f\]+\[^\n\r]*(\n|\r\n|\r)" } */
+/* { dg-output "\[^\n\r]*freed by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #0 0x\[0-9a-f\]+ (in _*(interceptor_|)free|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #1 0x\[0-9a-f\]+ (in _*main (\[^\n\r]*use-after-free-1.c:8|\[^\n\r]*:0)|\[(\]).*(\n|\r\n|\r)" } */
-/* { dg-output "previously allocated by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" } */
+/* { dg-output "\[^\n\r]*previously allocated by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #0 0x\[0-9a-f\]+ (in _*(interceptor_|)malloc|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
 /* { dg-output "    #1 0x\[0-9a-f\]+ (in _*main (\[^\n\r]*use-after-free-1.c:7|\[^\n\r]*:0)|\[(\])\[^\n\r]*(\n|\r\n|\r)" } */
diff --git a/gcc/testsuite/g++.dg/asan/deep-thread-stack-1.C b/gcc/testsuite/g++.dg/asan/deep-thread-stack-1.C
index 12d8a7a..d5d85c4 100644
--- a/gcc/testsuite/g++.dg/asan/deep-thread-stack-1.C
+++ b/gcc/testsuite/g++.dg/asan/deep-thread-stack-1.C
@@ -45,9 +45,9 @@ int main(int argc, char *argv[]) {
 }
 
 // { dg-output "ERROR: AddressSanitizer: heap-use-after-free.*(\n|\r\n|\r)" }
-// { dg-output "WRITE of size 4 at 0x\[0-9a-f\]+ thread T(\[0-9\]+).*(\n|\r\n|\r)" }
-// { dg-output "freed by thread T(\[0-9\]+) here:.*(\n|\r\n|\r)" }
-// { dg-output "previously allocated by thread T(\[0-9\]+) here:.*(\n|\r\n|\r)" }
+// { dg-output "\[^\n\r]*WRITE of size 4 at 0x\[0-9a-f\]+ thread T(\[0-9\]+).*(\n|\r\n|\r)" }
+// { dg-output "\[^\n\r]*freed by thread T(\[0-9\]+) here:.*(\n|\r\n|\r)" }
+// { dg-output "\[^\n\r]*previously allocated by thread T(\[0-9\]+) here:.*(\n|\r\n|\r)" }
 // { dg-output "Thread T\\2 created by T(\[0-9\]+) here:.*(\n|\r\n|\r)" }
 // { dg-output "Thread T\\8 created by T0 here:.*(\n|\r\n|\r)" }
 // { dg-output "Thread T\\4 created by T(\[0-9\]+) here:.*(\n|\r\n|\r)" }
diff --git a/gcc/testsuite/g++.dg/asan/large-func-test-1.C b/gcc/testsuite/g++.dg/asan/large-func-test-1.C
index 32808e7..9344c3b 100644
--- a/gcc/testsuite/g++.dg/asan/large-func-test-1.C
+++ b/gcc/testsuite/g++.dg/asan/large-func-test-1.C
@@ -37,9 +37,9 @@ int main() {
 
 // { dg-output "ERROR: AddressSanitizer:? heap-buffer-overflow on address\[^\n\r]*" }
 // { dg-output "0x\[0-9a-f\]+ at pc 0x\[0-9a-f\]+ bp 0x\[0-9a-f\]+ sp 0x\[0-9a-f\]+\[^\n\r]*(\n|\r\n|\r)" }
-// { dg-output "READ of size 4 at 0x\[0-9a-f\]+ thread T0\[^\n\r]*(\n|\r\n|\r)" }
+// { dg-output "\[^\n\r]*READ of size 4 at 0x\[0-9a-f\]+ thread T0\[^\n\r]*(\n|\r\n|\r)" }
 // { dg-output "    #0 0x\[0-9a-f\]+ (in \[^\n\r]*LargeFunction\[^\n\r]*(large-func-test-1.C:18|\[^\n\r]*:0)|\[(\]).*(\n|\r\n|\r)" }
-// { dg-output "0x\[0-9a-f\]+ is located 44 bytes to the right of 400-byte region.*(\n|\r\n|\r)" }
-// { dg-output "allocated by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" }
+// { dg-output "\[^\n\r]*0x\[0-9a-f\]+ is located 44 bytes to the right of 400-byte region.*(\n|\r\n|\r)" }
+// { dg-output "\[^\n\r]*allocated by thread T0 here:\[^\n\r]*(\n|\r\n|\r)" }
 // { dg-output "    #0( 0x\[0-9a-f\]+ (in _*(interceptor_|)malloc|\[(\])\[^\n\r]*(\n|\r\n|\r)" }
 // { dg-output "    #1|) 0x\[0-9a-f\]+ (in (operator new|_*_Zn\[aw\]\[mj\])|\[(\])\[^\n\r]*(\n|\r\n|\r)" }
diff --git a/gcc/testsuite/gcc.dg/debug/pr57351.c b/gcc/testsuite/gcc.dg/debug/pr57351.c
new file mode 100644
index 0000000..972f3e9
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/debug/pr57351.c
@@ -0,0 +1,54 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_neon }  */
+/* { dg-options "-std=c99 -Os -g -march=armv7-a" } */
+/* { dg-add-options arm_neon } */
+
+typedef unsigned int size_t;
+typedef int ptrdiff_t;
+typedef signed char int8_t ;
+typedef signed long long int64_t;
+typedef int8_t GFC_INTEGER_1;
+typedef GFC_INTEGER_1 GFC_LOGICAL_1;
+typedef int64_t GFC_INTEGER_8;
+typedef GFC_INTEGER_8 GFC_LOGICAL_8;
+typedef ptrdiff_t index_type;
+typedef struct descriptor_dimension
+{
+  index_type lower_bound;
+  index_type _ubound;
+}
+descriptor_dimension;
+typedef struct { GFC_LOGICAL_1 *base_addr; size_t offset; index_type dtype; descriptor_dimension dim[7];} gfc_array_l1;
+typedef struct { GFC_LOGICAL_8 *base_addr; size_t offset; index_type dtype; descriptor_dimension dim[7];} gfc_array_l8;
+void
+all_l8 (gfc_array_l8 * const restrict retarray,
+ gfc_array_l1 * const restrict array,
+ const index_type * const restrict pdim)
+{
+  GFC_LOGICAL_8 * restrict dest;
+  index_type n;
+  index_type len;
+  index_type delta;
+  index_type dim;
+  dim = (*pdim) - 1;
+  len = ((array)->dim[dim]._ubound + 1 - (array)->dim[dim].lower_bound);
+  for (n = 0; n < dim; n++)
+    {
+      const GFC_LOGICAL_1 * restrict src;
+      GFC_LOGICAL_8 result;
+      {
+  result = 1;
+   {
+     for (n = 0; n < len; n++, src += delta)
+       {
+  if (! *src)
+    {
+      result = 0;
+      break;
+    }
+          }
+     *dest = result;
+   }
+      }
+    }
+}
diff --git a/gcc/testsuite/gcc.dg/pr56809.c b/gcc/testsuite/gcc.dg/pr56809.c
new file mode 100644
index 0000000..3f1f311
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/pr56809.c
@@ -0,0 +1,32 @@
+/* PR target/56809 */
+/* { dg-do compile } */
+/* { dg-options "-Os" }  */
+
+int
+foo (int mode, int i)
+{
+  int x;
+
+  switch (mode)
+    {
+    case 0:
+      x = i + 1;
+      break;
+    case 1:
+      x = i / 2;
+      break;
+    case 2:
+      x = i * 3;
+      break;
+    case 3:
+      x = i + 3;
+      break;
+    case 4:
+      x = i + 5;
+      break;
+    default:
+      x = i - 1;
+    }
+
+  return x;
+}
diff --git a/gcc/testsuite/gcc.dg/shrink-wrap-alloca.c b/gcc/testsuite/gcc.dg/shrink-wrap-alloca.c
new file mode 100644
index 0000000..9e69ca1
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/shrink-wrap-alloca.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -g" } */
+
+extern int * alloca (int);
+
+int *p;
+
+void
+test (int a)
+{
+  if (a > 0)
+    p = alloca (4);
+}
diff --git a/gcc/testsuite/gcc.dg/shrink-wrap-pretend.c b/gcc/testsuite/gcc.dg/shrink-wrap-pretend.c
new file mode 100644
index 0000000..6e20ca1
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/shrink-wrap-pretend.c
@@ -0,0 +1,36 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -g" } */
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <stdarg.h>
+
+#define DEBUG_BUFFER_SIZE 80
+int unifi_debug = 5;
+
+void
+unifi_trace (void* ospriv, int level, const char *fmt, ...)
+{
+   static char s[DEBUG_BUFFER_SIZE];
+   va_list args;
+   unsigned int len;
+
+   if (!ospriv)
+     return;
+
+   if (unifi_debug >= level)
+     {
+       va_start (args, fmt);
+       len = vsnprintf (&(s)[0], (DEBUG_BUFFER_SIZE), fmt, args);
+       va_end (args);
+
+       if (len >= DEBUG_BUFFER_SIZE)
+	 {
+	   (s)[DEBUG_BUFFER_SIZE - 2] = '\n';
+	   (s)[DEBUG_BUFFER_SIZE - 1] = 0;
+	 }
+
+       printf ("%s", s);
+     }
+}
+
diff --git a/gcc/testsuite/gcc.dg/shrink-wrap-sibcall.c b/gcc/testsuite/gcc.dg/shrink-wrap-sibcall.c
new file mode 100644
index 0000000..193bec2
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/shrink-wrap-sibcall.c
@@ -0,0 +1,26 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -g" } */
+
+unsigned char a, b, d, f, g;
+
+int test (void);
+
+int
+baz (int c)
+{
+  if (c == 0) return test ();
+  if (b & 1)
+    {
+      g = 0;
+      int e = (a & 0x0f) - (g & 0x0f);
+
+      if (!a)  b |= 0x80;
+      a = e + test ();
+     f = g/5 + a*3879 + b *2985;
+    }
+   else
+   {
+     f = g + a*39879 + b *25;
+   }
+  return test ();
+}
diff --git a/gcc/testsuite/gcc.target/arm/anddi3-opt.c b/gcc/testsuite/gcc.target/arm/anddi3-opt.c
new file mode 100644
index 0000000..cd0d083
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/anddi3-opt.c
@@ -0,0 +1,11 @@
+/* { dg-do compile } */
+/* { dg-options "-O1" } */
+
+unsigned long long
+muld (unsigned long long X, unsigned long long Y)
+{
+  unsigned long long mask = 0xffffffffull;
+  return (X & mask) * (Y & mask);
+}
+
+/* { dg-final { scan-assembler-not "and\[\\t \]+.+,\[\\t \]*.+,\[\\t \]*.+" } } */
diff --git a/gcc/testsuite/gcc.target/arm/anddi3-opt2.c b/gcc/testsuite/gcc.target/arm/anddi3-opt2.c
new file mode 100644
index 0000000..efe71f4
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/anddi3-opt2.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-options "-O1" } */
+
+long long muld(long long X, long long Y)
+{
+  return X & ~1;
+}
+
+/* { dg-final { scan-assembler-not "and\[\\t \]+.+,\[\\t \]*.+,\[\\t \]*.+" } } */
diff --git a/gcc/testsuite/gcc.target/arm/iordi3-opt.c b/gcc/testsuite/gcc.target/arm/iordi3-opt.c
new file mode 100644
index 0000000..b3f465b
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/iordi3-opt.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-options "-O1" } */
+
+unsigned long long or64 (unsigned long long input)
+{
+    return input | 0x200000004ULL;
+}
+
+/* { dg-final { scan-assembler-not "mov\[\\t \]+.+,\[\\t \]*.+" } } */
diff --git a/gcc/testsuite/gcc.target/arm/minmax_minus.c b/gcc/testsuite/gcc.target/arm/minmax_minus.c
new file mode 100644
index 0000000..050c847
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/minmax_minus.c
@@ -0,0 +1,12 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+
+#define MAX(a, b) (a > b ? a : b)
+int
+foo (int a, int b, int c)
+{
+  return c - MAX (a, b);
+}
+
+/* { dg-final { scan-assembler "rsbge" } } */
+/* { dg-final { scan-assembler "rsblt" } } */
diff --git a/gcc/testsuite/gcc.target/arm/negdi-1.c b/gcc/testsuite/gcc.target/arm/negdi-1.c
new file mode 100644
index 0000000..c9bef04
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/negdi-1.c
@@ -0,0 +1,17 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm32 } */
+/* { dg-options "-O2" } */
+
+signed long long extendsidi_negsi (signed int x)
+{
+  return -x;
+}
+
+/*
+Expected output:
+	rsb	r0, r0, #0
+	mov	r1, r0, asr #31
+*/
+/* { dg-final { scan-assembler-times "rsb" 1 { target { arm_nothumb } } } } */
+/* { dg-final { scan-assembler-times "negs\\t" 1 { target { ! { arm_nothumb } } } } } */
+/* { dg-final { scan-assembler-times "asr" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/negdi-2.c b/gcc/testsuite/gcc.target/arm/negdi-2.c
new file mode 100644
index 0000000..96bbcab
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/negdi-2.c
@@ -0,0 +1,16 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm32 } */
+/* { dg-options "-O2" } */
+
+signed long long zero_extendsidi_negsi (unsigned int x)
+{
+  return -x;
+}
+/*
+Expected output:
+	rsb	r0, r0, #0
+	mov	r1, #0
+*/
+/* { dg-final { scan-assembler-times "rsb\\tr0, r0, #0" 1 { target { arm_nothumb } } } } */
+/* { dg-final { scan-assembler-times "negs\\tr0, r0" 1 { target { ! arm_nothumb } } } } */
+/* { dg-final { scan-assembler-times "mov" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/negdi-3.c b/gcc/testsuite/gcc.target/arm/negdi-3.c
new file mode 100644
index 0000000..76ddf49
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/negdi-3.c
@@ -0,0 +1,17 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm32 } */
+/* { dg-options "-O2" } */
+
+signed long long negdi_zero_extendsidi (unsigned int x)
+{
+  return -((signed long long) x);
+}
+/*
+Expected output:
+        rsbs    r0, r0, #0
+        sbc     r1, r1, r1
+*/
+/* { dg-final { scan-assembler-times "rsb" 1 } } */
+/* { dg-final { scan-assembler-times "sbc" 1 } } */
+/* { dg-final { scan-assembler-times "mov" 0 } } */
+/* { dg-final { scan-assembler-times "rsc" 0 } } */
diff --git a/gcc/testsuite/gcc.target/arm/negdi-4.c b/gcc/testsuite/gcc.target/arm/negdi-4.c
new file mode 100644
index 0000000..dc3deaa
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/negdi-4.c
@@ -0,0 +1,16 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm32 } */
+/* { dg-options "-O2" } */
+
+signed long long negdi_extendsidi (signed int x)
+{
+  return -((signed long long) x);
+}
+/*
+Expected output:
+        rsbs    r0, r0, #0
+        mov     r1, r0, asr #31
+*/
+/* { dg-final { scan-assembler-times "rsb" 1 } } */
+/* { dg-final { scan-assembler-times "asr" 1 } } */
+/* { dg-final { scan-assembler-times "rsc" 0 } } */
diff --git a/gcc/testsuite/gcc.target/arm/neon-for-64bits-1.c b/gcc/testsuite/gcc.target/arm/neon-for-64bits-1.c
new file mode 100644
index 0000000..a2a4103
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/neon-for-64bits-1.c
@@ -0,0 +1,54 @@
+/* Check that Neon is *not* used by default to handle 64-bits scalar
+   operations.  */
+
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_neon_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_neon } */
+
+typedef long long i64;
+typedef unsigned long long u64;
+typedef unsigned int u32;
+typedef int i32;
+
+/* Unary operators */
+#define UNARY_OP(name, op) \
+  void unary_##name(u64 *a, u64 *b) { *a = op (*b + 0x1234567812345678ULL) ; }
+
+/* Binary operators */
+#define BINARY_OP(name, op) \
+  void binary_##name(u64 *a, u64 *b, u64 *c) { *a = *b op *c ; }
+
+/* Unsigned shift */
+#define SHIFT_U(name, op, amount) \
+  void ushift_##name(u64 *a, u64 *b, int c) { *a = *b op amount; }
+
+/* Signed shift */
+#define SHIFT_S(name, op, amount) \
+  void sshift_##name(i64 *a, i64 *b, int c) { *a = *b op amount; }
+
+UNARY_OP(not, ~)
+
+BINARY_OP(add, +)
+BINARY_OP(sub, -)
+BINARY_OP(and, &)
+BINARY_OP(or, |)
+BINARY_OP(xor, ^)
+
+SHIFT_U(right1, >>, 1)
+SHIFT_U(right2, >>, 2)
+SHIFT_U(right5, >>, 5)
+SHIFT_U(rightn, >>, c)
+
+SHIFT_S(right1, >>, 1)
+SHIFT_S(right2, >>, 2)
+SHIFT_S(right5, >>, 5)
+SHIFT_S(rightn, >>, c)
+
+/* { dg-final {scan-assembler-times "vmvn" 0} }  */
+/* { dg-final {scan-assembler-times "vadd" 0} }  */
+/* { dg-final {scan-assembler-times "vsub" 0} }  */
+/* { dg-final {scan-assembler-times "vand" 0} }  */
+/* { dg-final {scan-assembler-times "vorr" 0} }  */
+/* { dg-final {scan-assembler-times "veor" 0} }  */
+/* { dg-final {scan-assembler-times "vshr" 0} }  */
diff --git a/gcc/testsuite/gcc.target/arm/neon-for-64bits-2.c b/gcc/testsuite/gcc.target/arm/neon-for-64bits-2.c
new file mode 100644
index 0000000..035bfb7
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/neon-for-64bits-2.c
@@ -0,0 +1,57 @@
+/* Check that Neon is used to handle 64-bits scalar operations.  */
+
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_neon_ok } */
+/* { dg-options "-O2 -mneon-for-64bits" } */
+/* { dg-add-options arm_neon } */
+
+typedef long long i64;
+typedef unsigned long long u64;
+typedef unsigned int u32;
+typedef int i32;
+
+/* Unary operators */
+#define UNARY_OP(name, op) \
+  void unary_##name(u64 *a, u64 *b) { *a = op (*b + 0x1234567812345678ULL) ; }
+
+/* Binary operators */
+#define BINARY_OP(name, op) \
+  void binary_##name(u64 *a, u64 *b, u64 *c) { *a = *b op *c ; }
+
+/* Unsigned shift */
+#define SHIFT_U(name, op, amount) \
+  void ushift_##name(u64 *a, u64 *b, int c) { *a = *b op amount; }
+
+/* Signed shift */
+#define SHIFT_S(name, op, amount) \
+  void sshift_##name(i64 *a, i64 *b, int c) { *a = *b op amount; }
+
+UNARY_OP(not, ~)
+
+BINARY_OP(add, +)
+BINARY_OP(sub, -)
+BINARY_OP(and, &)
+BINARY_OP(or, |)
+BINARY_OP(xor, ^)
+
+SHIFT_U(right1, >>, 1)
+SHIFT_U(right2, >>, 2)
+SHIFT_U(right5, >>, 5)
+SHIFT_U(rightn, >>, c)
+
+SHIFT_S(right1, >>, 1)
+SHIFT_S(right2, >>, 2)
+SHIFT_S(right5, >>, 5)
+SHIFT_S(rightn, >>, c)
+
+/* { dg-final {scan-assembler-times "vmvn" 1} }  */
+/* Two vadd: 1 in unary_not, 1 in binary_add */
+/* { dg-final {scan-assembler-times "vadd" 2} }  */
+/* { dg-final {scan-assembler-times "vsub" 1} }  */
+/* { dg-final {scan-assembler-times "vand" 1} }  */
+/* { dg-final {scan-assembler-times "vorr" 1} }  */
+/* { dg-final {scan-assembler-times "veor" 1} }  */
+/* 6 vshr for right shifts by constant, and variable right shift uses
+   vshl with a negative amount in register.  */
+/* { dg-final {scan-assembler-times "vshr" 6} }  */
+/* { dg-final {scan-assembler-times "vshl" 2} }  */
diff --git a/gcc/testsuite/gcc.target/arm/peep-ldrd-1.c b/gcc/testsuite/gcc.target/arm/peep-ldrd-1.c
new file mode 100644
index 0000000..eb2b86e
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/peep-ldrd-1.c
@@ -0,0 +1,11 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_prefer_ldrd_strd } */
+/* { dg-options "-O2" }  */
+int foo(int a, int b, int* p, int *q)
+{
+  a = p[2] + p[3];
+  *q = a;
+  *p = a;
+  return a;
+}
+/* { dg-final { scan-assembler "ldrd" } } */
diff --git a/gcc/testsuite/gcc.target/arm/peep-strd-1.c b/gcc/testsuite/gcc.target/arm/peep-strd-1.c
new file mode 100644
index 0000000..bd33076
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/peep-strd-1.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_prefer_ldrd_strd } */
+/* { dg-options "-O2" }  */
+void foo(int a, int b, int* p)
+{
+  p[2] = a;
+  p[3] = b;
+}
+/* { dg-final { scan-assembler "strd" } } */
diff --git a/gcc/testsuite/gcc.target/arm/pr19599.c b/gcc/testsuite/gcc.target/arm/pr19599.c
new file mode 100644
index 0000000..e3e066c
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/pr19599.c
@@ -0,0 +1,10 @@
+/* { dg-skip-if "need at least armv5te" { *-*-* } { "-march=armv[234]*" } { "" } } */
+/* { dg-options "-O2 -march=armv5te -marm" }  */
+/* { dg-final { scan-assembler "bx" } } */
+
+int (*indirect_func)();
+
+int indirect_call()
+{
+  return indirect_func();
+}
diff --git a/gcc/testsuite/gcc.target/arm/pr40887.c b/gcc/testsuite/gcc.target/arm/pr40887.c
index 0b5e873..5cabe3a 100644
--- a/gcc/testsuite/gcc.target/arm/pr40887.c
+++ b/gcc/testsuite/gcc.target/arm/pr40887.c
@@ -2,9 +2,9 @@
 /* { dg-options "-O2 -march=armv5te" }  */
 /* { dg-final { scan-assembler "blx" } } */
 
-int (*indirect_func)();
+int (*indirect_func)(int x);
 
 int indirect_call()
 {
-    return indirect_func();
+  return indirect_func(20) + indirect_func (40);
 }
diff --git a/gcc/testsuite/gcc.target/arm/thumb1-far-jump-1.c b/gcc/testsuite/gcc.target/arm/thumb1-far-jump-1.c
new file mode 100644
index 0000000..eb16d2f
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/thumb1-far-jump-1.c
@@ -0,0 +1,34 @@
+/* Check for thumb1 far jump. Shouldn't save lr for small leaf functions
+ * even with a branch in it.  */
+/* { dg-options "-Os" } */
+/* { dg-skip-if "" { ! { arm_thumb1 } } } */
+
+void f()
+{
+  for (;;);
+}
+
+volatile int g;
+void f2(int i)
+{
+  if (i) g=0;
+}
+
+void f3(int i)
+{
+  if (i) {
+    g=0;
+    g=1;
+    g=2;
+    g=3;
+    g=4;
+    g=5;
+    g=6;
+    g=7;
+    g=8;
+    g=9;
+  }
+}
+
+/* { dg-final { scan-assembler-not "push.*lr" } } */
+
diff --git a/gcc/testsuite/gcc.target/arm/thumb1-far-jump-2.c b/gcc/testsuite/gcc.target/arm/thumb1-far-jump-2.c
new file mode 100644
index 0000000..c6878f8
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/thumb1-far-jump-2.c
@@ -0,0 +1,57 @@
+/* Check for thumb1 far jump. This is the extreme case that far jump
+ * will be used with minimum number of instructions. By passing this case
+ * it means the heuristic of saving lr for far jump meets the most extreme
+ * requirement.  */
+/* { dg-options "-Os" } */
+/* { dg-skip-if "" { ! { arm_thumb1 } } } */
+
+volatile register r4 asm("r4");
+void f3(int i)
+{
+#define GO(n) \
+  extern volatile int g_##n; \
+  r4=(int)&g_##n;
+
+#define GO8(n) \
+  GO(n##_0) \
+  GO(n##_1) \
+  GO(n##_2) \
+  GO(n##_3) \
+  GO(n##_4) \
+  GO(n##_5) \
+  GO(n##_6) \
+  GO(n##_7)
+
+#define GO64(n) \
+  GO8(n##_0) \
+  GO8(n##_1) \
+  GO8(n##_2) \
+  GO8(n##_3) \
+  GO8(n##_4) \
+  GO8(n##_5) \
+  GO8(n##_6) \
+  GO8(n##_7) \
+
+#define GO498(n) \
+  GO64(n##_0) \
+  GO64(n##_1) \
+  GO64(n##_2) \
+  GO64(n##_3) \
+  GO64(n##_4) \
+  GO64(n##_5) \
+  GO64(n##_6) \
+  GO8(n##_0) \
+  GO8(n##_1) \
+  GO8(n##_2) \
+  GO8(n##_3) \
+  GO8(n##_4) \
+  GO8(n##_5) \
+  GO(n##_0) \
+  GO(n##_1) \
+
+  if (i) {
+    GO498(0);
+  }
+}
+
+/* { dg-final { scan-assembler "push.*lr" } } */
diff --git a/gcc/testsuite/gcc.target/arm/unaligned-memcpy-2.c b/gcc/testsuite/gcc.target/arm/unaligned-memcpy-2.c
index c7d24c9..f7bc2f4 100644
--- a/gcc/testsuite/gcc.target/arm/unaligned-memcpy-2.c
+++ b/gcc/testsuite/gcc.target/arm/unaligned-memcpy-2.c
@@ -14,7 +14,10 @@ void aligned_dest (char *src)
 /* Expect a multi-word store for the main part of the copy, but subword
    loads/stores for the remainder.  */
 
-/* { dg-final { scan-assembler-times "stmia" 1 } } */
+/* { dg-final { scan-assembler-times "ldmia" 0 } } */
+/* { dg-final { scan-assembler-times "ldrd" 0 } } */
+/* { dg-final { scan-assembler-times "stmia" 1 { target { ! { arm_prefer_ldrd_strd } } } } } */
+/* { dg-final { scan-assembler-times "strd" 1 { target { arm_prefer_ldrd_strd } } } } */
 /* { dg-final { scan-assembler-times "ldrh" 1 } } */
 /* { dg-final { scan-assembler-times "strh" 1 } } */
 /* { dg-final { scan-assembler-times "ldrb" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/unaligned-memcpy-3.c b/gcc/testsuite/gcc.target/arm/unaligned-memcpy-3.c
index 5f04137..9e2d164 100644
--- a/gcc/testsuite/gcc.target/arm/unaligned-memcpy-3.c
+++ b/gcc/testsuite/gcc.target/arm/unaligned-memcpy-3.c
@@ -14,8 +14,11 @@ void aligned_src (char *dest)
 /* Expect a multi-word load for the main part of the copy, but subword
    loads/stores for the remainder.  */
 
-/* { dg-final { scan-assembler-times "ldmia" 1 } } */
-/* { dg-final { scan-assembler-times "ldrh" 1 } } */
+/* { dg-final { scan-assembler-times "ldmia" 1 { target { ! { arm_prefer_ldrd_strd } } } } } */
+/* { dg-final { scan-assembler-times "ldrd" 1 { target { arm_prefer_ldrd_strd } } } } */
+/* { dg-final { scan-assembler-times "strd" 0 } } */
+/* { dg-final { scan-assembler-times "stm" 0 } } */
+/* { dg-final { scan-assembler-times "ldrh" 1 { target { ! { arm_prefer_ldrd_strd } } } } } */
 /* { dg-final { scan-assembler-times "strh" 1 } } */
-/* { dg-final { scan-assembler-times "ldrb" 1 } } */
+/* { dg-final { scan-assembler-times "ldrb" 1 { target { ! { arm_prefer_ldrd_strd } } } } } */
 /* { dg-final { scan-assembler-times "strb" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/unaligned-memcpy-4.c b/gcc/testsuite/gcc.target/arm/unaligned-memcpy-4.c
index 9995708..4708c51 100644
--- a/gcc/testsuite/gcc.target/arm/unaligned-memcpy-4.c
+++ b/gcc/testsuite/gcc.target/arm/unaligned-memcpy-4.c
@@ -14,5 +14,9 @@ void aligned_both (void)
 
 /* We know both src and dest to be aligned: expect multiword loads/stores.  */
 
-/* { dg-final { scan-assembler-times "ldmia" 1 } } */
-/* { dg-final { scan-assembler-times "stmia" 1 } } */
+/* { dg-final { scan-assembler-times "ldmia" 1 { target { ! { arm_prefer_ldrd_strd } } } } } */
+/* { dg-final { scan-assembler-times "stmia" 1 { target { ! { arm_prefer_ldrd_strd } } } } } */
+/* { dg-final { scan-assembler "ldrd" { target { arm_prefer_ldrd_strd } } } } */
+/* { dg-final { scan-assembler-times "ldm" 0 { target { arm_prefer_ldrd_strd } } } } */
+/* { dg-final { scan-assembler "strd" { target { arm_prefer_ldrd_strd } } } } */
+/* { dg-final { scan-assembler-times "stm" 0 { target { arm_prefer_ldrd_strd } } } } */
diff --git a/gcc/testsuite/gcc.target/arm/vseleqdf.c b/gcc/testsuite/gcc.target/arm/vseleqdf.c
new file mode 100644
index 0000000..86e147b
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vseleqdf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+double
+foo (double x, double y)
+{
+  volatile int i = 0;
+  return i == 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vseleq.f64\td\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vseleqsf.c b/gcc/testsuite/gcc.target/arm/vseleqsf.c
new file mode 100644
index 0000000..120f44b
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vseleqsf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+float
+foo (float x, float y)
+{
+  volatile int i = 0;
+  return i == 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vseleq.f32\ts\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselgedf.c b/gcc/testsuite/gcc.target/arm/vselgedf.c
new file mode 100644
index 0000000..cea08d1
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselgedf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+double
+foo (double x, double y)
+{
+  volatile int i = 0;
+  return i >= 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselge.f64\td\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselgesf.c b/gcc/testsuite/gcc.target/arm/vselgesf.c
new file mode 100644
index 0000000..86f2a04
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselgesf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+float
+foo (float x, float y)
+{
+  volatile int i = 0;
+  return i >= 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselge.f32\ts\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselgtdf.c b/gcc/testsuite/gcc.target/arm/vselgtdf.c
new file mode 100644
index 0000000..2c4a6ba
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselgtdf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+double
+foo (double x, double y)
+{
+  volatile int i = 0;
+  return i > 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselgt.f64\td\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselgtsf.c b/gcc/testsuite/gcc.target/arm/vselgtsf.c
new file mode 100644
index 0000000..388e74c
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselgtsf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+float
+foo (float x, float y)
+{
+  volatile int i = 0;
+  return i > 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselgt.f32\ts\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselledf.c b/gcc/testsuite/gcc.target/arm/vselledf.c
new file mode 100644
index 0000000..088dc04
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselledf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+double
+foo (double x, double y)
+{
+  volatile int i = 0;
+  return i <= 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselgt.f64\td\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vsellesf.c b/gcc/testsuite/gcc.target/arm/vsellesf.c
new file mode 100644
index 0000000..d0afdbc
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vsellesf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+float
+foo (float x, float y)
+{
+  volatile int i = 0;
+  return i <= 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselgt.f32\ts\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselltdf.c b/gcc/testsuite/gcc.target/arm/vselltdf.c
new file mode 100644
index 0000000..fbcb9ea
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselltdf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+double
+foo (double x, double y)
+{
+  volatile int i = 0;
+  return i < 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselge.f64\td\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselltsf.c b/gcc/testsuite/gcc.target/arm/vselltsf.c
new file mode 100644
index 0000000..959dab7
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselltsf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+float
+foo (float x, float y)
+{
+  volatile int i = 0;
+  return i < 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselge.f32\ts\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselnedf.c b/gcc/testsuite/gcc.target/arm/vselnedf.c
new file mode 100644
index 0000000..cf67f29
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselnedf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+double
+foo (double x, double y)
+{
+  volatile int i = 0;
+  return i != 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vseleq.f64\td\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselnesf.c b/gcc/testsuite/gcc.target/arm/vselnesf.c
new file mode 100644
index 0000000..2e16423
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselnesf.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+float
+foo (float x, float y)
+{
+  volatile int i = 0;
+  return i != 0 ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vseleq.f32\ts\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselvcdf.c b/gcc/testsuite/gcc.target/arm/vselvcdf.c
new file mode 100644
index 0000000..7f30270
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselvcdf.c
@@ -0,0 +1,12 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+double
+foo (double x, double y)
+{
+  return !__builtin_isunordered (x, y) ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselvs.f64\td\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselvcsf.c b/gcc/testsuite/gcc.target/arm/vselvcsf.c
new file mode 100644
index 0000000..1bb7369
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselvcsf.c
@@ -0,0 +1,12 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+float
+foo (float x, float y)
+{
+  return !__builtin_isunordered (x, y) ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselvs.f32\ts\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselvsdf.c b/gcc/testsuite/gcc.target/arm/vselvsdf.c
new file mode 100644
index 0000000..83ad5bf
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselvsdf.c
@@ -0,0 +1,12 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+double
+foo (double x, double y)
+{
+  return __builtin_isunordered (x, y) ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselvs.f64\td\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/vselvssf.c b/gcc/testsuite/gcc.target/arm/vselvssf.c
new file mode 100644
index 0000000..7d76289
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/vselvssf.c
@@ -0,0 +1,12 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target arm_v8_vfp_ok } */
+/* { dg-options "-O2" } */
+/* { dg-add-options arm_v8_vfp } */
+
+float
+foo (float x, float y)
+{
+  return __builtin_isunordered (x, y) ? x : y;
+}
+
+/* { dg-final { scan-assembler-times "vselvs.f32\ts\[0-9\]+" 1 } } */
diff --git a/gcc/testsuite/gcc.target/arm/xordi3-opt.c b/gcc/testsuite/gcc.target/arm/xordi3-opt.c
new file mode 100644
index 0000000..7e031c3
--- /dev/null
+++ b/gcc/testsuite/gcc.target/arm/xordi3-opt.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-options "-O1" } */
+
+unsigned long long xor64 (unsigned long long input)
+{
+    return input ^ 0x200000004ULL;
+}
+
+/* { dg-final { scan-assembler-not "mov\[\\t \]+.+,\[\\t \]*.+" } } */
diff --git a/gcc/testsuite/lib/c-compat.exp b/gcc/testsuite/lib/c-compat.exp
index 58eaf4d..b42545d 100644
--- a/gcc/testsuite/lib/c-compat.exp
+++ b/gcc/testsuite/lib/c-compat.exp
@@ -34,7 +34,7 @@ load_lib target-supports.exp
 # 
 proc compat-use-alt-compiler { } {
     global GCC_UNDER_TEST ALT_CC_UNDER_TEST
-    global compat_same_alt compat_alt_caret
+    global compat_same_alt compat_alt_caret compat_alt_color
     global TEST_ALWAYS_FLAGS
 
     # We don't need to do this if the alternate compiler is actually
@@ -44,6 +44,9 @@ proc compat-use-alt-compiler { } {
 	if { $compat_alt_caret == 0 } then {
 	    regsub -- "-fno-diagnostics-show-caret" $TEST_ALWAYS_FLAGS "" TEST_ALWAYS_FLAGS
 	}
+	if { $compat_alt_color == 0 } then {
+	    regsub -- "-fdiagnostics-color=never" $TEST_ALWAYS_FLAGS "" TEST_ALWAYS_FLAGS
+	}
     }
 }
 
@@ -70,9 +73,11 @@ proc compat_setup_dfp { } {
     global compat_same_alt
     global compat_have_dfp
     global compat_alt_caret
+    global compat_alt_color
     global TEST_ALWAYS_FLAGS compat_save_TEST_ALWAYS_FLAGS
 
     set compat_alt_caret 0
+    set compat_alt_color 0
     set compat_save_TEST_ALWAYS_FLAGS $TEST_ALWAYS_FLAGS
 
     verbose "compat_setup_dfp: $compat_use_alt $compat_same_alt" 2
@@ -88,6 +93,10 @@ proc compat_setup_dfp { } {
 		int dummy; } "-fno-diagnostics-show-caret"] != 0 } {
 	    set compat_alt_caret 1
 	}
+	if { [check_no_compiler_messages_nocache compat_alt_has_color object {
+		int dummy; } "-fdiagnostics-color=never"] != 0 } {
+	    set compat_alt_color 1
+	}
 	compat-use-tst-compiler
     }
 
diff --git a/gcc/testsuite/lib/prune.exp b/gcc/testsuite/lib/prune.exp
index c110fc6..7890608 100644
--- a/gcc/testsuite/lib/prune.exp
+++ b/gcc/testsuite/lib/prune.exp
@@ -19,7 +19,7 @@
 if ![info exists TEST_ALWAYS_FLAGS] {
     set TEST_ALWAYS_FLAGS ""
 }
-set TEST_ALWAYS_FLAGS "-fno-diagnostics-show-caret $TEST_ALWAYS_FLAGS"
+set TEST_ALWAYS_FLAGS "-fno-diagnostics-show-caret -fdiagnostics-color=never $TEST_ALWAYS_FLAGS"
 
 proc prune_gcc_output { text } {
     #send_user "Before:$text\n"
diff --git a/gcc/testsuite/lib/target-supports.exp b/gcc/testsuite/lib/target-supports.exp
index a146f17..c4f8b9b 100644
--- a/gcc/testsuite/lib/target-supports.exp
+++ b/gcc/testsuite/lib/target-supports.exp
@@ -4591,6 +4591,33 @@ proc check_effective_target_simulator { } {
     return 0
 }
 
+# Return 1 if programs are intended to be run on hardware rather than
+# on a simulator
+
+proc check_effective_target_hw { } {
+
+    # All "src/sim" simulators set this one.
+    if [board_info target exists is_simulator] {
+	if [board_info target is_simulator] {
+	  return 0
+	} else {
+	  return 1
+	}
+    }
+
+    # The "sid" simulators don't set that one, but at least they set
+    # this one.
+    if [board_info target exists slow_simulator] {
+	if [board_info target slow_simulator] {
+	  return 0
+	} else {
+	  return 1
+	}
+    }
+
+    return 1
+}
+
 # Return 1 if the target is a VxWorks kernel.
 
 proc check_effective_target_vxworks_kernel { } {
diff --git a/gcc/toplev.c b/gcc/toplev.c
index 7bced04..be81437 100644
--- a/gcc/toplev.c
+++ b/gcc/toplev.c
@@ -74,6 +74,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "gimple.h"
 #include "tree-ssa-alias.h"
 #include "plugin.h"
+#include "diagnostic-color.h"
 
 #if defined(DBX_DEBUGGING_INFO) || defined(XCOFF_DEBUGGING_INFO)
 #include "dbxout.h"
@@ -1209,6 +1210,13 @@ process_options (void)
 
   maximum_field_alignment = initial_max_fld_align * BITS_PER_UNIT;
 
+  /* Default to -fdiagnostics-color=auto if GCC_COLORS is in the environment,
+     otherwise default to -fdiagnostics-color=never.  */
+  if (!global_options_set.x_flag_diagnostics_show_color
+      && getenv ("GCC_COLORS"))
+    pp_show_color (global_dc->printer)
+      = colorize_init (DIAGNOSTICS_COLOR_AUTO);
+
   /* Allow the front end to perform consistency checks and do further
      initialization based on the command line options.  This hook also
      sets the original filename if appropriate (e.g. foo.i -> foo.c)
diff --git a/libgcc/Makefile.in b/libgcc/Makefile.in
index 990cd49..ba1a975 100644
--- a/libgcc/Makefile.in
+++ b/libgcc/Makefile.in
@@ -365,10 +365,20 @@ ifeq ($(enable_shared),yes)
   endif
 endif
 
+ifneq ($(enable_shared),yes)
+# Some prebuilt libraries for Android link libc.so before libgcc.a, and they
+# rely on libgcc.a to provide those symbols with default visibility to resolve
+# them eventually. The linker order has been fixed in JB maintain releases but
+# may take a while to trickle down to partners to refresh their prebuilt
+# libraries. Therefore we need to maintain the same visibility as older GCC
+# for now.
+vis_hide =
+else
 # For -fvisibility=hidden.  We need both a -fvisibility=hidden on
 # the command line, and a #define to prevent libgcc2.h etc from
 # overriding that with #pragmas.
 vis_hide = @vis_hide@
+endif
 
 ifneq (,$(vis_hide))
 
diff --git a/libgcc/config.host b/libgcc/config.host
index 67257b8..c15701f 100644
--- a/libgcc/config.host
+++ b/libgcc/config.host
@@ -285,6 +285,11 @@ aarch64*-*-elf)
 	tmake_file="${tmake_file} ${cpu_type}/t-aarch64"
 	tmake_file="${tmake_file} ${cpu_type}/t-softfp t-softfp"
 	;;
+aarch64*-*-linux*-android*)
+	#md_unwind_header=aarch64/linux-unwind.h  # disable this for now since bionic isn't 64-bit ready yet
+	tmake_file="${tmake_file} ${cpu_type}/t-aarch64"
+	tmake_file="${tmake_file} ${cpu_type}/t-softfp t-softfp"
+	;;
 aarch64*-*-linux*)
 	md_unwind_header=aarch64/linux-unwind.h
 	tmake_file="${tmake_file} ${cpu_type}/t-aarch64"
diff --git a/libgcc/config/arm/linux-atomic-64bit.c b/libgcc/config/arm/linux-atomic-64bit.c
index 7aa8dfc..1f82472 100644
--- a/libgcc/config/arm/linux-atomic-64bit.c
+++ b/libgcc/config/arm/linux-atomic-64bit.c
@@ -56,7 +56,11 @@ static void __check_for_sync8_kernelhelper (void)
 	 for the user - I'm not sure I can rely on much else being
 	 available at this point, so do the same as generic-morestack.c
 	 write () and abort ().  */
+#if !defined(__ANDROID__)
       __write (2 /* stderr.  */, err, sizeof (err));
+#else
+      write (2 /* stderr.  */, err, sizeof (err));
+#endif
       abort ();
     }
 };
diff --git a/libgomp/config/linux/futex.h b/libgomp/config/linux/futex.h
index fecaa9f..676b2db 100644
--- a/libgomp/config/linux/futex.h
+++ b/libgomp/config/linux/futex.h
@@ -38,6 +38,10 @@
 
 #pragma GCC visibility pop
 
+#if !defined(SYS_futex)
+#define SYS_futex __NR_futex
+#endif
+
 static inline void
 futex_wait (int *addr, int val)
 {
diff --git a/libgomp/config/linux/mips/futex.h b/libgomp/config/linux/mips/futex.h
index fa5aa26..3140336 100644
--- a/libgomp/config/linux/mips/futex.h
+++ b/libgomp/config/linux/mips/futex.h
@@ -25,6 +25,11 @@
 /* Provide target-specific access to the futex system call.  */
 
 #include <sys/syscall.h>
+
+#if !defined(SYS_futex)
+#define SYS_futex __NR_futex
+#endif
+
 #define FUTEX_WAIT 0
 #define FUTEX_WAKE 1
 
diff --git a/libgomp/config/linux/proc.c b/libgomp/config/linux/proc.c
index cbb773e..4572308 100644
--- a/libgomp/config/linux/proc.c
+++ b/libgomp/config/linux/proc.c
@@ -30,8 +30,11 @@
 #endif
 #include "libgomp.h"
 #include "proc.h"
-#include <stdlib.h>
 #include <unistd.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <fcntl.h>
+#include <errno.h>
 #ifdef HAVE_GETLOADAVG
 # ifdef HAVE_SYS_LOADAVG_H
 #  include <sys/loadavg.h>
@@ -63,6 +66,186 @@ gomp_cpuset_popcount (cpu_set_t *cpusetp)
 }
 #endif
 
+/* Read the content of a file.
+ * Return the length of the data, or -1 on error. Does *not*
+ * zero-terminate the content. Will not read more
+ * than 'buffsize' bytes.
+ */
+static int
+read_file(const char*  pathname, char*  buffer, size_t  buffsize)
+{
+    int  fd, len;
+
+    fd = open(pathname, O_RDONLY);
+    if (fd < 0)
+        return -1;
+
+    do {
+        len = read(fd, buffer, buffsize);
+    } while (len < 0 && errno == EINTR);
+
+    close(fd);
+
+    return len;
+}
+
+
+/* Parse a decimal integer starting from 'input', but not going further
+ * than 'limit'. Return the value into '*result'.
+ *
+ * NOTE: Does not skip over leading spaces, or deal with sign characters.
+ * NOTE: Ignores overflows.
+ *
+ * The function returns NULL in case of error (bad format), or the new
+ * position after the decimal number in case of success (which will always
+ * be <= 'limit').
+ */
+static const char*
+parse_decimal(const char* input, const char* limit, int* result)
+{
+    const char* p = input;
+    int val = 0;
+    while (p < limit) {
+        int d = (*p - '0');
+        if ((unsigned)d >= 10U)
+            break;
+        val = val*10 + d;
+        p++;
+    }
+    if (p == input)
+        return NULL;
+
+    *result = val;
+    return p;
+}
+
+
+/* This data type is used to represent a CPU list / mask, as read
+ * from sysfs on Linux. See http://www.kernel.org/doc/Documentation/cputopology.txt
+ */
+typedef struct {
+    int mask;
+} cpuList;
+
+/* Returns Actual CPUs (total installed CPUs) */
+static int
+cpuList_count (cpuList* list) {
+	return list->mask ;
+}
+
+/* Parse a textual list of cpus and store the result inside a cpuList object.
+ * Input format is the following:
+ * - comma-separated list of items (no spaces)
+ * - each item is either a single decimal number (cpu index), or a range made
+ *   of two numbers separated by a single dash (-). Ranges are inclusive.
+ * Examples:
+ *           0
+ *           2,4-127,128-143
+ *           0-1
+ */
+static void
+cpuList_parse (cpuList* list, const char* line, int line_len)
+{
+    const char* p = line;
+    const char* end = p + line_len;
+    const char* q;
+
+    /* NOTE: the input line coming from sysfs typically contains a
+    * trailing newline, so take care of it in the code below
+     */
+    while (p < end && *p != '\n')
+    {
+        int val, start_value, end_value;
+
+        /* Find the end of current item, and put it into 'q' */
+        q = memchr(p, ',', end-p);
+        if (q == NULL) {
+            q = end;
+        }
+
+        /* Get first value */
+        p = parse_decimal(p, q, &start_value);
+        if (p == NULL)
+            goto BAD_FORMAT;
+
+        end_value = start_value;
+
+        /* If we're not at the end of the item, expect a dash and
+         * and integer; extract end value.
+         */
+        if (p < q && *p == '-') {
+            p = parse_decimal(p+1, q, &end_value);
+            if (p == NULL)
+                goto BAD_FORMAT;
+        }
+
+        /* Set CPU list */
+        for (val = start_value; val <= end_value; val++) {
+            list->mask++;
+        }
+
+        /* Jump to next item */
+        p = q;
+        if (p < end)
+            p++;
+    }
+
+BAD_FORMAT:
+    ;
+}
+
+
+/* Read a CPU list from one sysfs file
+ * The below is CPU related sys interface by CPU topologoy.
+ */
+static void
+cpuList_read_from (cpuList* list, const char* filename)
+{
+    char file[64];
+    int filelen;
+
+    list->mask = 0;
+
+    filelen = read_file(filename, file, sizeof file);
+    if (filelen < 0) {
+        fprintf(stderr,"Could not read %s: %s\n", filename, strerror(errno));
+        return;
+    }
+
+    cpuList_parse(list, file, filelen);
+}
+
+
+/* Probe the number of actual CPUs on devices (e.g. Android devices) using
+ * CPU-Hotplug and CPU-DVFS to optimize battery life.
+ * Return the number of CPUs present on a given device.
+ * See http://www.kernel.org/doc/Documentation/cputopology.txt
+ */
+static int
+sc_nprocessors_actu ()
+{
+    char buffer[256];
+    int buffer_len;
+    int cpuCount = 1;
+    cpuList cpus_present[1];
+    char file_name[64] = "/sys/devices/system/cpu/present";
+
+    buffer_len = read_file(file_name, buffer, sizeof buffer);
+
+    if (buffer_len < 0)  /* should not happen */ {
+        fprintf(stderr,"Could not find %s: %s\n", file_name, strerror(errno));
+        return 1;
+    }
+
+    /* Count the CPU cores, the value may be 0 for single-core CPUs */
+    cpuList_read_from(cpus_present, file_name);
+    cpuCount = cpuList_count(cpus_present);
+    if (cpuCount == 0) {
+        cpuCount = 1;
+    }
+    return cpuCount;
+}
+
 /* At startup, determine the default number of threads.  It would seem
    this should be related to the number of cpus online.  */
 
@@ -81,7 +264,9 @@ gomp_init_num_threads (void)
       return;
     }
 #endif
-#ifdef _SC_NPROCESSORS_ONLN
+#if defined(__ANDROID__)
+  gomp_global_icv.nthreads_var = sc_nprocessors_actu ();
+#elif defined(_SC_NPROCESSORS_ONLN)
   gomp_global_icv.nthreads_var = sysconf (_SC_NPROCESSORS_ONLN);
 #endif
 }
@@ -113,7 +298,9 @@ get_num_procs (void)
       return gomp_available_cpus;
     }
 #endif
-#ifdef _SC_NPROCESSORS_ONLN
+#if defined(__ANDROID__)
+  return sc_nprocessors_actu ();
+#elif defined(_SC_NPROCESSORS_ONLN)
   return sysconf (_SC_NPROCESSORS_ONLN);
 #else
   return gomp_icv (false)->nthreads_var;
diff --git a/libgomp/configure b/libgomp/configure
index 238b1af..b48979b 100755
--- a/libgomp/configure
+++ b/libgomp/configure
@@ -15022,7 +15022,54 @@ _ACEOF
 if ac_fn_c_try_link "$LINENO"; then :
   XPCFLAGS=" -Wc,-pthread"
 else
-  CFLAGS="$save_CFLAGS" LIBS="-lpthread $LIBS"
+  echo "$as_me: failed program was:" >&5
+sed 's/^/| /' conftest.$ac_ext >&5
+
+CFLAGS="$save_CFLAGS" LIBS="$LIBS"
+  cat >conftest.$ac_ext <<_ACEOF
+/* confdefs.h.  */
+_ACEOF
+cat confdefs.h >>conftest.$ac_ext
+cat >>conftest.$ac_ext <<_ACEOF
+/* end confdefs.h.  */
+#include <pthread.h>
+     void *g(void *d) { return NULL; }
+int
+main ()
+{
+pthread_t t; pthread_create(&t,NULL,g,NULL);
+  ;
+  return 0;
+}
+_ACEOF
+rm -f conftest.$ac_objext conftest$ac_exeext
+if { (eval echo "$as_me:$LINENO: \"$ac_link\"") >&5
+  (eval $ac_link) 2>conftest.er1
+  ac_status=$?
+  grep -v '^ *+' conftest.er1 >conftest.err
+  rm -f conftest.er1
+  cat conftest.err >&5
+  echo "$as_me:$LINENO: \$? = $ac_status" >&5
+  (exit $ac_status); } &&
+	 { ac_try='test -z "$ac_c_werror_flag"
+			 || test ! -s conftest.err'
+  { (eval echo "$as_me:$LINENO: \"$ac_try\"") >&5
+  (eval $ac_try) 2>&5
+  ac_status=$?
+  echo "$as_me:$LINENO: \$? = $ac_status" >&5
+  (exit $ac_status); }; } &&
+	 { ac_try='test -s conftest$ac_exeext'
+  { (eval echo "$as_me:$LINENO: \"$ac_try\"") >&5
+  (eval $ac_try) 2>&5
+  ac_status=$?
+  echo "$as_me:$LINENO: \$? = $ac_status" >&5
+  (exit $ac_status); }; }; then
+  :
+else
+  echo "$as_me: failed program was:" >&5
+sed 's/^/| /' conftest.$ac_ext >&5
+
+CFLAGS="$save_CFLAGS" LIBS="-lpthread $LIBS"
   cat confdefs.h - <<_ACEOF >conftest.$ac_ext
 /* end confdefs.h.  */
 #include <pthread.h>
@@ -15045,6 +15092,9 @@ rm -f core conftest.err conftest.$ac_objext \
 fi
 rm -f core conftest.err conftest.$ac_objext \
     conftest$ac_exeext conftest.$ac_ext
+fi
+rm -f core conftest.err conftest.$ac_objext \
+    conftest$ac_exeext conftest.$ac_ext
 
 # Check for functions needed.
 for ac_func in getloadavg clock_gettime strtoull
@@ -15099,6 +15149,12 @@ case "$target" in
 /* end confdefs.h.  */
 #include <sys/syscall.h>
 	   int lk;
+#if !defined(SYS_gettid)
+#define SYS_gettid __NR_gettid
+#endif
+#if !defined(SYS_futex)
+#define SYS_futex __NR_futex
+#endif
 int
 main ()
 {
@@ -15151,6 +15207,12 @@ rm -f core conftest.err conftest.$ac_objext \
 /* end confdefs.h.  */
 #include <sys/syscall.h>
 	   int lk;
+#if !defined(SYS_gettid)
+#define SYS_gettid __NR_gettid
+#endif
+#if !defined(SYS_futex)
+#define SYS_futex __NR_futex
+#endif
 int
 main ()
 {
diff --git a/libgomp/configure.ac b/libgomp/configure.ac
index d87ed29..292db2a 100644
--- a/libgomp/configure.ac
+++ b/libgomp/configure.ac
@@ -184,6 +184,13 @@ AC_LINK_IFELSE(
    void *g(void *d) { return NULL; }],
   [pthread_t t; pthread_create(&t,NULL,g,NULL);])],
  [XPCFLAGS=" -Wc,-pthread"],
+ [CFLAGS="$save_CFLAGS" LIBS="$LIBS"
+  AC_LINK_IFELSE(
+   [AC_LANG_PROGRAM(
+    [#include <pthread.h>
+     void *g(void *d) { return NULL; }],
+    [pthread_t t; pthread_create(&t,NULL,g,NULL);])],
+   [],
  [CFLAGS="$save_CFLAGS" LIBS="-lpthread $LIBS"
   AC_LINK_IFELSE(
    [AC_LANG_PROGRAM(
@@ -191,7 +198,7 @@ AC_LINK_IFELSE(
      void *g(void *d) { return NULL; }],
     [pthread_t t; pthread_create(&t,NULL,g,NULL);])],
    [],
-   [AC_MSG_ERROR([Pthreads are required to build libgomp])])])
+   [AC_MSG_ERROR([Pthreads are required to build libgomp])])])])
 
 # Check for functions needed.
 AC_CHECK_FUNCS(getloadavg clock_gettime strtoull)
diff --git a/libgomp/env.c b/libgomp/env.c
index 65cbba8..68b92f2 100644
--- a/libgomp/env.c
+++ b/libgomp/env.c
@@ -43,6 +43,7 @@
 #endif
 #include <limits.h>
 #include <errno.h>
+#include <asm/page.h>
 
 #ifndef HAVE_STRTOULL
 # define strtoull(ptr, eptr, base) strtoul (ptr, eptr, base)
diff --git a/libsanitizer/ChangeLog.cfx b/libsanitizer/ChangeLog.cfx
new file mode 100644
index 0000000..7776e42
--- /dev/null
+++ b/libsanitizer/ChangeLog.cfx
@@ -0,0 +1,5 @@
+This file documents backports from trunk only
+
+2013-05-07  Christophe Lyon  <christophe.lyon@linaro.org>
+
+        * configure.tgt: Add ARM pattern.
diff --git a/libsanitizer/configure.tgt b/libsanitizer/configure.tgt
index 265da01..bdfc22e 100644
--- a/libsanitizer/configure.tgt
+++ b/libsanitizer/configure.tgt
@@ -29,6 +29,8 @@ case "${target}" in
 	;;
   sparc*-*-linux*)
 	;;
+  arm*-*-linux*)
+	;;
   x86_64-*-darwin[1]* | i?86-*-darwin[1]*)
 	TSAN_SUPPORTED=no
 	;;
diff --git a/libstdc++-v3/config/locale/generic/c_locale.cc b/libstdc++-v3/config/locale/generic/c_locale.cc
index 0d309a5..b4dcea9 100644
--- a/libstdc++-v3/config/locale/generic/c_locale.cc
+++ b/libstdc++-v3/config/locale/generic/c_locale.cc
@@ -51,10 +51,14 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     {
       // Assumes __s formatted for "C" locale.
       char* __old = setlocale(LC_ALL, 0);
-      const size_t __len = strlen(__old) + 1;
-      char* __sav = new char[__len];
-      memcpy(__sav, __old, __len);
-      setlocale(LC_ALL, "C");
+      char* __sav = 0;
+      if (__old)
+        {
+          const size_t __len = strlen(__old) + 1;
+          __sav = new char[__len];
+          memcpy(__sav, __old, __len);
+          setlocale(LC_ALL, "C");
+        }
       char* __sanity;
       bool __overflow = false;
 
@@ -116,10 +120,14 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     {
       // Assumes __s formatted for "C" locale.
       char* __old = setlocale(LC_ALL, 0);
-      const size_t __len = strlen(__old) + 1;
-      char* __sav = new char[__len];
-      memcpy(__sav, __old, __len);
-      setlocale(LC_ALL, "C");
+      char* __sav = 0;
+      if (__old)
+        {
+          const size_t __len = strlen(__old) + 1;
+          __sav = new char[__len];
+          memcpy(__sav, __old, __len);
+          setlocale(LC_ALL, "C");
+        }
       char* __sanity;
 
 #if !__DBL_HAS_INFINITY__
@@ -161,10 +169,14 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     {
       // Assumes __s formatted for "C" locale.
       char* __old = setlocale(LC_ALL, 0);
-      const size_t __len = strlen(__old) + 1;
-      char* __sav = new char[__len];
-      memcpy(__sav, __old, __len);
-      setlocale(LC_ALL, "C");
+      char* __sav = 0;
+      if (__old)
+        {
+          const size_t __len = strlen(__old) + 1;
+          __sav = new char[__len];
+          memcpy(__sav, __old, __len);
+          setlocale(LC_ALL, "C");
+        }
 
 #if !__LDBL_HAS_INFINITY__
       errno = 0;
diff --git a/libstdc++-v3/config/locale/generic/c_locale.h b/libstdc++-v3/config/locale/generic/c_locale.h
index b5fd989..08f59e4 100644
--- a/libstdc++-v3/config/locale/generic/c_locale.h
+++ b/libstdc++-v3/config/locale/generic/c_locale.h
@@ -59,7 +59,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   {
     char* __old = std::setlocale(LC_NUMERIC, 0);
     char* __sav = 0;
-    if (__builtin_strcmp(__old, "C"))
+    if (__old && __builtin_strcmp(__old, "C"))
       {
 	const size_t __len = __builtin_strlen(__old) + 1;
 	__sav = new char[__len];
diff --git a/libstdc++-v3/config/locale/generic/time_members.cc b/libstdc++-v3/config/locale/generic/time_members.cc
index 056e4fd..4e32cab 100644
--- a/libstdc++-v3/config/locale/generic/time_members.cc
+++ b/libstdc++-v3/config/locale/generic/time_members.cc
@@ -44,10 +44,14 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 	   const tm* __tm) const throw()
     {
       char* __old = setlocale(LC_ALL, 0);
-      const size_t __llen = strlen(__old) + 1;
-      char* __sav = new char[__llen];
-      memcpy(__sav, __old, __llen);
-      setlocale(LC_ALL, _M_name_timepunct);
+      char* __sav = 0;
+      if (__old)
+        {
+          const size_t __llen = strlen(__old) + 1;
+          __sav = new char[__llen];
+          memcpy(__sav, __old, __llen);
+          setlocale(LC_ALL, _M_name_timepunct);
+        }
       const size_t __len = strftime(__s, __maxlen, __format, __tm);
       setlocale(LC_ALL, __sav);
       delete [] __sav;
@@ -129,10 +133,14 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 	   const tm* __tm) const throw()
     {
       char* __old = setlocale(LC_ALL, 0);
-      const size_t __llen = strlen(__old) + 1;
-      char* __sav = new char[__llen];
-      memcpy(__sav, __old, __llen);
-      setlocale(LC_ALL, _M_name_timepunct);
+      char* __sav = 0;
+      if (__old)
+        {
+          const size_t __llen = strlen(__old) + 1;
+          __sav = new char[__llen];
+          memcpy(__sav, __old, __llen);
+          setlocale(LC_ALL, _M_name_timepunct);
+        }
       const size_t __len = wcsftime(__s, __maxlen, __format, __tm);
       setlocale(LC_ALL, __sav);
       delete [] __sav;
diff --git a/libstdc++-v3/configure b/libstdc++-v3/configure
index 57452f7..a43fa2b 100755
--- a/libstdc++-v3/configure
+++ b/libstdc++-v3/configure
@@ -70841,6 +70841,12 @@ cat confdefs.h - <<_ACEOF >conftest.$ac_ext
 /* end confdefs.h.  */
 #include <sys/syscall.h>
 	   int lk;
+#if !defined(SYS_gettid)
+#define SYS_gettid __NR_gettid
+#endif
+#if !defined(SYS_futex)
+#define SYS_futex __NR_futex
+#endif
 int
 main ()
 {
@@ -70899,6 +70905,12 @@ cat confdefs.h - <<_ACEOF >conftest.$ac_ext
 /* end confdefs.h.  */
 #include <sys/syscall.h>
 	   int lk;
+#if !defined(SYS_gettid)
+#define SYS_gettid __NR_gettid
+#endif
+#if !defined(SYS_futex)
+#define SYS_futex __NR_futex
+#endif
 int
 main ()
 {
@@ -72306,7 +72318,7 @@ $as_echo_n "checking for gthreads library... " >&6; }
 
   cat confdefs.h - <<_ACEOF >conftest.$ac_ext
 /* end confdefs.h.  */
-#include "gthr.h"
+#include "gthr-$target_thread_file.h"
 int
 main ()
 {
diff --git a/libstdc++-v3/include/ext/atomicity.h b/libstdc++-v3/include/ext/atomicity.h
index 6367026..13003ba 100644
--- a/libstdc++-v3/include/ext/atomicity.h
+++ b/libstdc++-v3/include/ext/atomicity.h
@@ -41,7 +41,8 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   // To abstract locking primitives across all thread policies, use:
   // __exchange_and_add_dispatch
   // __atomic_add_dispatch
-#ifdef _GLIBCXX_ATOMIC_BUILTINS
+#if defined(_GLIBCXX_ATOMIC_BUILTINS) && (!defined(__clang__) || defined(__i386__))
+  // NOTE: clang arm/mips can't compile the following two library calls yet.
   static inline _Atomic_word 
   __exchange_and_add(volatile _Atomic_word* __mem, int __val)
   { return __atomic_fetch_add(__mem, __val, __ATOMIC_ACQ_REL); }
diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index 334b8d0..b5f8c79 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -264,7 +264,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     struct __is_floating_point_helper<long double>
     : public true_type { };
 
-#if !defined(__STRICT_ANSI__) && defined(_GLIBCXX_USE_FLOAT128)
+#if !defined(__STRICT_ANSI__) && defined(_GLIBCXX_USE_FLOAT128) && !defined(__clang__)
   template<>
     struct __is_floating_point_helper<__float128>
     : public true_type { };
@@ -1806,7 +1806,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     struct __common_type_impl
     : private __do_common_type_impl
     {
-      typedef decltype(_S_test<_Tp, _Up>(0)) type;
+      typedef typename decay<decltype(_S_test<_Tp, _Up>(0))>::type type;
     };
 
   struct __do_member_type_wrapper
diff --git a/libstdc++-v3/libsupc++/eh_arm.cc b/libstdc++-v3/libsupc++/eh_arm.cc
index a91405e..03c157b 100644
--- a/libstdc++-v3/libsupc++/eh_arm.cc
+++ b/libstdc++-v3/libsupc++/eh_arm.cc
@@ -29,6 +29,16 @@
 
 using namespace __cxxabiv1;
 
+// The GCC command-line option "-fvisibility=hidden" apparently fails to hide
+// the visibility of the inline assembly function "__cxa_end_cleanup".
+// We need to keep the visibility of the __cxa_* functions coherent otherwise
+// linking eh_arm.o to resolve __cxa_end_cleanup (eg needed by -frtti
+// -fexceptions) will disappoint the linker by exposing __cxa_type_match and
+// __cxa_begin_cleanup (eg needed by __aeabi_idiv from libgcc.a).
+// Therefore as a simple workaround we just force the visibility to default for
+// all these __cxa functions in this module.
+
+#pragma GCC visibility push(default)
 
 // Given the thrown type THROW_TYPE, exception object UE_HEADER and a
 // type CATCH_TYPE to compare against, return whether or not there is
@@ -224,4 +234,6 @@ asm ("  .pushsection .text.__cxa_end_cleanup\n"
 #endif
 #endif
 
+#pragma GCC visibility pop
+
 #endif
diff --git a/libstdc++-v3/libsupc++/eh_globals.cc b/libstdc++-v3/libsupc++/eh_globals.cc
index 5d4ad64..3c28cf9 100644
--- a/libstdc++-v3/libsupc++/eh_globals.cc
+++ b/libstdc++-v3/libsupc++/eh_globals.cc
@@ -100,6 +100,14 @@ struct __eh_globals_init
 
   ~__eh_globals_init()
   {
+    /* Work-around for an Android-specific bug, where this destructor
+     * is called with a NULL object pointer. This is due to a bug in the
+     * __cxa_finalize() implementation that was only fixed in 2.2.
+     */
+#ifdef __ANDROID__
+    if (this == NULL)
+        return;
+#endif
     if (_M_init)
       __gthread_key_delete(_M_key);
     _M_init = false;
diff --git a/libstdc++-v3/libsupc++/guard.cc b/libstdc++-v3/libsupc++/guard.cc
index c509fa7..983fcf0 100644
--- a/libstdc++-v3/libsupc++/guard.cc
+++ b/libstdc++-v3/libsupc++/guard.cc
@@ -33,7 +33,12 @@
 #if defined(__GTHREADS) && defined(__GTHREAD_HAS_COND) \
   && (ATOMIC_INT_LOCK_FREE > 1) && defined(_GLIBCXX_HAVE_LINUX_FUTEX)
 # include <climits>
+#if defined(__ANDROID__)
+# include <sys/syscall.h>
+# define SYS_futex __NR_futex
+#else
 # include <syscall.h>
+#endif
 # include <unistd.h>
 # define _GLIBCXX_USE_FUTEX
 # define _GLIBCXX_FUTEX_WAIT 0
diff --git a/libstdc++-v3/src/Makefile.am b/libstdc++-v3/src/Makefile.am
index 092fd1b..07c4160 100644
--- a/libstdc++-v3/src/Makefile.am
+++ b/libstdc++-v3/src/Makefile.am
@@ -68,7 +68,7 @@ libstdc___la_DEPENDENCIES = \
 	$(top_builddir)/src/c++11/libc++11convenience.la
 
 libstdc___la_LDFLAGS = \
-	-version-info $(libtool_VERSION) ${version_arg} -lm
+	-avoid-version ${version_arg} -lm
 
 libstdc___la_LINK = $(CXXLINK) $(libstdc___la_LDFLAGS)
 
diff --git a/libstdc++-v3/src/Makefile.in b/libstdc++-v3/src/Makefile.in
index a7b3404..9721ebb 100644
--- a/libstdc++-v3/src/Makefile.in
+++ b/libstdc++-v3/src/Makefile.in
@@ -368,7 +368,7 @@ libstdc___la_DEPENDENCIES = \
 	$(top_builddir)/src/c++11/libc++11convenience.la
 
 libstdc___la_LDFLAGS = \
-	-version-info $(libtool_VERSION) ${version_arg} -lm
+	-avoid-version ${version_arg} -lm
 
 libstdc___la_LINK = $(CXXLINK) $(libstdc___la_LDFLAGS)
 
